---
title: "Workshop 7: Linear and generalized linear mixed models (LMM and GLMM)"
subtitle: "QCBS R Workshop Series"
author: "Québec Centre for Biodiversity Science"
output:
  xaringan::moon_reader:
    includes:
      in_header: qcbsR-header.html
    lib_dir: assets
    seal: true
    css: ["default", "qcbsR.css", "qcbsR-fonts.css"]
    nature:
      beforeInit: "qcbsR-macros.js"
      highlightLines: true
      highlightStyle: github
---

```{r setup, echo = FALSE}
knitr::opts_chunk$set(
  comment = "#",
  collapse = TRUE,
  warning = FALSE,
  message = FALSE,
  cache = TRUE,
  fig.width = 6, fig.height = 6,
  fig.retina = 3,
  fig.align = 'center'
)

options(repos = structure(c(CRAN="http://cran.r-project.org")))

mypar = list(mar = c(3,3,1,0.5), mgp = c(1.6, 0.3, 0), tck = -.02)
```

class: inverse, center, middle

```{r install_pkgs, message=FALSE, warning=FALSE, include=FALSE, results=0}
# Standard procedure to check and install packages and their dependencies, if needed.

list.of.packages <- c("ggplot2", 
                      "lme4", 
                      "MuMIn", 
                      "MASS", 
                      "vcdExtra", 
                      "bbmle", 
                      "DescTools")

new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]

if(length(new.packages) > 0) {
  install.packages(new.packages, dependencies = TRUE) 
  print(paste0("The following package was installed:", new.packages)) 
} else if(length(new.packages) == 0) {
    print("All packages were already installed previously")
  }

# Load all required libraries at once
lapply(list.of.packages, require, character.only = TRUE, quietly = TRUE)
```

# About this workshop

[![badge](https://img.shields.io/static/v1?style=for-the-badge&label=repo&message=dev&color=6f42c1&logo=github)](https://github.com/QCBSRworkshops/workshop07)
[![badge](https://img.shields.io/static/v1?style=for-the-badge&label=wiki&message=07&logo=wikipedia)](https://wiki.qcbs.ca/r_workshop6)
[![badge](https://img.shields.io/static/v1?style=for-the-badge&label=Slides&message=07&color=red&logo=html5)](https://qcbsrworkshops.github.io/workshop07/workshop07-en/workshop07-en.html)
[![badge](https://img.shields.io/static/v1?style=for-the-badge&label=Slides&message=07&color=red&logo=adobe-acrobat-reader)](https://qcbsrworkshops.github.io/workshop07/workshop07-en/workshop07-en.pdf)
[![badge](https://img.shields.io/static/v1?style=for-the-badge&label=script&message=07&color=2a50b8&logo=r)](https://qcbsrworkshops.github.io/workshop07/workshop07-en/workshop07-en.R)


---

# About this workshop

<br>

Throughout this workshop, there will be a series of **challenges** that you can recognize by this rubix cube.

.center[
![:scale 25%](images/rubicub.png)
]

<br>

**During these challenges, don't hesitate to collaborate!**

---


# Required packages

* [ggplot2](https://cran.r-project.org/package=ggplot2)
* [lme4](https://cran.r-project.org/package=lme4)
* [MuMIn](https://cran.r-project.org/package=MuMIn)
* [MASS](https://cran.r-project.org/package=MASS)
* [vcdExtra](https://cran.r-project.org/package=vcdExtra)
* [bbmle](https://cran.r-project.org/package=bbmle)
* [DescTools](https://cran.r-project.org/package=DescTools)

<br>
To install them from CRAN, do :

```{r eval = FALSE}
install.packages(c("ggplot2", 
                   "lme4", 
                   "MuMIn", 
                   'MASS', 
                   'vcdExtra', 
                   'bbmle', 
                   'DescTools'))
```

---

# Learning objectives

**1.** Describe what are (generalized) mixed effects models

**2.** Identify situations in which the use of mixed effects is appropriate

**3.** Implement basic linear mixed models (LMM) with `R`

**4.** Execute basic generalized linear mixed models (GLMM) with `R`

**5.** Validate, interpret and visualize mixed models with `R`

---
# Research question

.alert[**Does fish trophic position increase with fish size?**
]

To answer this question, we use a dataset where body length was measured in 3 different fish species with 10 individuals sampled per species across 6 different lakes.

.center[ ![:scale 75%](images/fig_1_qcbs_wiki.png) ]


---
exclude: true
# 1. Why choose mixed models?

Introduction to the example dataset

.center[ ![:scale 75%](images/fig_1_qcbs_wiki.png) ]

.comment[**Q: Does fish trophic position increase with fish size for all three fish species?**
]


---
# Challenge 1 ![:cube]()

**Get acquainted with the dataset**

**1.** Open the workshop script in `R`

**2.** Open the example dataset in `R`

**3.** Reproduce the plots 1 to 3 from the script. Observe the plots and try to get a sense of what you see

---
# Solution ![:cube]()

<br>

```{r, echo = FALSE}
library(ggplot2)
fish.data <- read.csv('data/qcbs_w7_data.csv', stringsAsFactors = TRUE)

# simple theme
fig <- theme_bw() + theme(panel.grid.minor = element_blank(), 
                          panel.grid.major = element_blank(), 
                          panel.background = element_blank()) +
                    theme(strip.background = element_blank(), 
                          strip.text.y = element_text()) + 
                    theme(legend.background = element_blank()) +
                    theme(legend.key = element_blank()) + 
                    theme(panel.border = element_rect(colour = "black", fill = NA))

plot <- ggplot(aes(Fish_Length, Trophic_Pos), data = fish.data)

# Plot 1 - All data
plot + geom_point() + xlab("Length (mm)") + ylab("Trophic Position") + labs(title = "All Data") + fig
```


---
# Solution ![:cube]()

<br>

```{r, echo = FALSE}
# Plot 2 - By species
plot + geom_point() + facet_wrap(~ Fish_Species) + xlab("Length (mm)") + ylab("Trophic Position") +
   labs(title="By Species") + fig
```

---
# Solution ![:cube]()

<br>

```{r, echo= FALSE}
# Plot 3 – By lake
plot + geom_point() + facet_wrap(~ Lake) + xlab("Length (mm)") + ylab("Trophic Position") +
   labs(title="By Lake") + fig
```


---
# Group discussion ![:cube]()

**Do we expect an increase in trophic position with length in the exact same way for : **
* all species?
* all lakes?

<br>

--

**How might these relationships differ?**


---
# Why choose mixed models?

### Ecological and biological data can be complex!

* Hierarchical structure in the data

* Many covariates and grouping factors

* Unbalanced study/experimental design


---
exclude: true
# 1. Why choose mixed models?

Ecological and biological data can be complex!

* Inherent structure to data

* Many covariates and grouping factors

* Small sample size

???

Note: _MFF: Not sure that mixed models help when the sample size is small. Also, I think that saying the data has a hierarchical structure makes more sense in the context of mixed models_


---
# Why choose mixed models?

### How could we analyze this data?

--

<br>

**Option 1. Separate**

- Run separate analyses for each species in each lake

<br>

**Option 2. Lump**

- Run one analysis ignoring lake and species


---
# Why choose mixed models?

.pull-left[![](images/fig_5_w5.png) ]

.pull-right[
**Option 1. Separate**

We could run seprate analyses for each species :

* Estimate 6 intercepts and 6 slopes for each species (i.e. 6 lakes)

* Sample size *n* = 10 for each analysis (i.e. 10 fish/species/lake)

* Low chance of detecting an effect due to small *n*
]


---
# Why choose mixed models?

.pull-left[![](images/fig_6_w5.png)]

.pull-right[
**Option 2. Lump**
* Big sample size!

* What about pseudoreplication? (fish within a lake and within a species might be correlated)

* A lot of noise in the data! Some of it might be due to **differences** among **species** and **lakes**
]

---
# Why choose mixed models?

For **our question**, we only want to know if there is a **general effect of body length on the trophic position**.
<br>
<br>

However :

* **this relationship might differ** slightly among **species** due to unmeasured biological processes (e.g. growth rate) or among **lakes** due to unmeasured environmental variables

* We need to **control** for these potential effects

--

<br>

LMMs enable us to **lump and separate the analysis**. They :

1. Estimate slope and intercept parameters for each species and lake (**separating**) but estimate fewer parameters than classical regression.

2. Use all the data available (**lumping**) while accounting for pseudoreplication by controlling for differences among lakes and species.


---
# Why choose mixed models?

### Fixed vs Random Effects

We frequently encounter the terms 'fixed' and 'random' effects in the LMM literature.

There are many possible ways to introduce them and we chose to present those we think are easier to apply when doing your analyses.


---
# Why choose mixed models?

### Fixed effects : deterministic processes

Data comes from : 
* all possible levels of a factor (**qualitative variable**)
* a predictor (**quantitative variable**)

<br>

We wish to make conclusions about the levels of the factor or about the relationship between the response variable and the predictor.


---
# Why choose mixed models?

### Random effects : stochastic processes

* Only **qualitative variables** = random factor

* Data includes only a random sample of all possible factor levels, all of interest

* Enable us to structure the error process


---
# Why choose mixed models?

### How do LMMs work?
<br>

**A.** Intercepts and/or slopes are allowed to vary according to a given factor (**random effect**) (e.g. by lake and/or species)

<br>

**B.** Intercepts, slopes and their confidence intervals are adjusted to **take the data structure into account**


---
# Random effects : enabling differences in intercepts and/or slopes among grouping levels

.pull-left[![](images/fig_7_w5.png)]
.pull-right[![](images/fig_9_w5.png)]
<br>

* It is assumed that the intercepts/slopes come from a normal distribution
* The model estimates a general intercept and/or slope with a standard deviation for each random effect (i.e. the normal distribution)
<br><br>

This avoids estimating an intercept and a slope for each species (+2 parameters per specie) = **saves degrees of freedom** (less parameter estimation is needed)


---
exclude: true
# Random intercept

<br>

<p>
<img style="float: right; width:50%;margin: 1%" src="images/fig_7_w5.png">

It is assumed that the intercepts come from a normal distribution

Only need to estimate the mean and standard deviation of the normal distribution instead of 3 intercepts, i.e. one for each species</p>

<br>

.comment[Note that the more levels your factor has, the more accurately the mean and standard deviation of the normal distribution will be estimated. Three levels may be a little low, but easier to visualize!]

---
exclude:true
# Random intercept

<br>

<p>
<img style="float: right; width:50%;margin: 1%" src="images/fig_8_w5.png">
Same principle for lakes

Estimate 2 parameters (mean and standard deviation) instead of 6 intercepts.

This saves degrees of freedom (less parameter estimation is needed)
</p>


---
exclude: true
# Random slope


<br>

<p>
<img style="float: right; width:50%;margin: 1%" src="images/fig_9_w5.png">
The same principle applies to slopes that vary according to a given factor, just more difficult to visualize

As for intercepts, only the mean and standard deviation of the slopes are estimated instead of three distinct slopes.
</p>


---
# Taking the data structure into account
<br>
**What happens if the sample size for a specific factor level is small? (e.g. low $n$ for a specific specie)**

If a certain species or lake is poorly represented in the data, the model will give more weight to the pooled model to estimate the intercept and/or slope of that species or lake (i.e. shrinkage).

Ideally, you should have a minimum of $n$=3 for any specific factor level.

.center[![:scale 50%](images/fig_12_w5.png) ]


---
# Taking the data structure into account
<br>
**How to assess the impact of a random effect on the model?**

* The confidence intervals for the **general** intercepts and slopes are adjusted to account for pseudo-replication based on the **intraclass correlation coefficient (ICC)**

* The ICC describes the proportion of variance in the response variable that is attributed to a specific random effect :

$$ICC = \frac{\sigma_{\alpha}^2}{\sigma_{\alpha}^2 + \sigma_{\varepsilon}^2}$$

The ICC is calculated as the **ratio** of variance between the random effect (ex. ordonnées à l'origine des espèces) and the total variance.

Thus, the ICC informs us on the **extent** to which the average trophic position (i.e. intercepts) **varies** among species or lakes.

???

Note: _Tell the audience that mathematical notations may vary according to the article/book and according to how the model equation was written._


---
# Taking the data structure into account


.pull-left[
**High ICC**

![:scale 90%](images/ICCplot2_qcbs.png)

The % of variance (ICC) is high because **species differ strongly** in their average trophic position.

The confidence intervals for the general intercept and slope are high.
]

.pull-right[
**Low ICC**

![:scale 85%](images/ICCplot_qcbs.png)

The % of variance (ICC) is low because **species differ poorly** in their average trophic position.

The confidence intervals for the general intercept and slope are small.
]


---
exclude: true
# Taking the data structure into account


.pull-left[
**High ICC**

![](images/fig_10_w5.png)

the points coming from the same lake are treated as a single observation because they are very correlated

![:faic](arrow-right) small effective sample size and large confidence intervals for slope and intercept.
]

.pull-right[
**Low ICC**

![](images/fig_11_w5.png)

the points coming from the same lake are treated independently because little correlated

![:faic](arrow-right) large effective sample size and small confidence intervals for slope and intercept.
]


---
# Challenge 2 ![:cube]()

<br>

**How will the ICC and the confidence intervals be affected in these two scenarios?**

**Q1.** Fish trophic positions do not vary among lakes

<br>

**Q2.** Fish trophic positions are similar within lakes but different among lakes

---
# Solution ![:cube]()

**Q1.** Fish trophic positions do not vary among lakes

.alert[A1. Low ICC, small confidence intervals]

<br>

--

**Q2.** Fish trophic positions are similar within lakes but different among lakes

.alert[A2. High ICC, large confidence intervals]
<br><br><br><br><br>
--

**For more details on the ICC** : <br>
Nakagawa and Schielzeth (2013)
https://doi.org/10.1111/j.1469-185X.2010.00141.x
Nakagawa *et al.* (2017) 
https://doi.org/10.1098/rsif.2017.0213


---
# How to implement mixed models in R?

<img style="float: right; width:40%;margin: 1%" src="images/lego.jpg">

###### **Step 1.** *A priori* model building and data exploration

<br>

**Step 2.** Code potential models and model selection

<br>

**Step 3.** Model validation

<br>

**Step 4.** Model interpretation and visualization

---
# Step 1. *A priori* model building

**What we know *a priori*:**

* We want to determine if the trophic position can be predicted by body length, while taking into account the variation between species and lakes

* So we want a model that looks like this:

$$PT_{ijk} \sim Length_i + Lake_j + Species_k + \epsilon_{ijk}$$

---
# Step 1. Data exploration

**Does the data have the right structure?**

```{r}
fish.data <- read.csv('data/qcbs_w7_data.csv')
str(fish.data)
```

It is recommended to clean up your working space (`rm.list()`) before building a model.

---
# Step 1. Data exploration

**Look at the distribution of samples for each factor:**

```{r}
table(fish.data[ , c("Lake", "Fish_Species")])
```

This dataset is perfectly balanced, but **mixed models can be used to analyze unbalanced experimental plans**, as it is often the case in ecology!

---
# Step 1. Data exploration

**Look at the distribution of continuous variables:**

```{r, fig.width=10, fig.height=4}
par(mfrow = c(1, 2), mar = c(4, 4, 1, 1))
hist(fish.data$Fish_Length, xlab = "Length (mm)", main = "")
hist(fish.data$Trophic_Pos, xlab = "Trophic position", main = "")
```

Major deviations could cause heteroscedasticity problems. If necessary, make transformations. In this case, **the data seems OK**.

---
# Step 1. Data exploration

**Check for collinearity between your explanatory variables**

The problem with collinear predictors is simply that they explain the same thing, so their effect on the response variable will be confounded in the model.

In this example, there is no risk of collinearity with only one continuous variable. If you had another continuous variable (`Var2`), one simple way to check for collinearity is:

```{r, eval = FALSE}
plot(fish.data)

cor(var1, var2)
```

Here an [example of collinearity](https://yetanotheriteration.netlify.app/2018/01/high-collinearity-effect-in-regressions/).

---
# Challenge 3 ![:cube]()

What additional measures could we have taken in the field that could have been strongly correlated with body length?

--

> An example is fish body mass - this variable is strongly correlated with fish length. Therefore, we do not want to include these two variables in the same model.


---
# Step 1. Data exploration

**Consider the scale of your data**

* If two variables in the same model have very different scales, the mixed model will likely returns a `convergence error` when trying to compute the parameters.

* The <a href="https://fr.wikipedia.org/wiki/Cote_Z_(statistiques)">Z-correction</a> standardizes the variables and solve this problem (function `scale()` in `R`):

$$z = \frac{x-mean(x)}{standard.deviation(x)}$$
---
# Step 1.  Data exploration

**Consider the scale of your data**

* Body length ![:faic](arrow-right) Long scale

* Trophic position ![:faic](arrow-right) Short scale

---
# Step 1.  Data exploration

**Consider the scale of your data**

Because our data have very different scales of variation, we apply the **Z-correction**

```{r}
# Standardized length, "by hand"
fish.data$Z_Length <- (fish.data$Fish_Length - mean(fish.data$Fish_Length)) / 
                      sd(fish.data$Fish_Length)

# Standardized trophic position, with the function scale
fish.data$Z_TP     <- scale(fish.data$Trophic_Pos)

```

---
# Step 1.  Data exploration

To find out if a mixed model is needed for your data, you need to determine whether it is important to consider the random effects that might influence the relationship you are interested in (in our case, lake and species)

**We can do it by :**

1. Creating a linear model without random effect

2. Calculating the residuals of this linear model

3. Plot the residuals against the levels of the potential random factors

---
# Step 1. Data exploration

Create a linear model without random effects
```{r}
lm.test <- lm(Z_TP ~ Z_Length, data = fish.data)
```

Calculate residuals of this linear model
```{r}
lm.test.resid <- rstandard(lm.test)
```

---
# Step 1. Data exploration

Plot the residuals against the levels of the potential random factors

```{r, fig.width = 10, fig.height = 5, eval = FALSE}
par(mfrow = c(1, 2))

plot(lm.test.resid ~ as.factor(fish.data$Fish_Species),
     xlab = "Species", ylab = "Standardized residuals")

abline(0, 0, lty = 2)

plot(lm.test.resid ~ as.factor(fish.data$Lake),
     xlab = "Lake", ylab = "Standardized residuals")

abline(0, 0, lty = 2)
```

---
# Step 1. Data exploration

Plot the residuals against the levels of the potential random factors

```{r, fig.width = 10, fig.height = 5, echo = FALSE}
par(mfrow = c(1, 2), mar = c(4, 4, 1, 1))
plot(lm.test.resid ~ as.factor(fish.data$Fish_Species),
     xlab = "Species", ylab = "Standardized residuals")
abline(0, 0, lty = 2)
plot(lm.test.resid ~ as.factor(fish.data$Lake),
     xlab = "Lake", ylab = "Standardized residuals")
abline(0, 0, lty = 2)
```

.alert[These patterns suggest that there is residual variance that could be explained by these factors, so they should be included in the model.]

---
# How to implement an LMM in R?

<img style = "float: right; width:40%;margin: 1%" src = "images/lego.jpg">

**Step 1. ** *A priori* model building and data exploration

<br>

###### **Step 2.** Code potential models and model selection

<br>

**Step 3.** Model validation

<br>

**Step 4 -** Model interpretation and visualization

---
# Step 2. Code potential models

**Translate this model...**

$$PT_{ijk} \sim Length_i + Lake_j + Species_k + \epsilon_{ijk}$$

**... in R code**

```{r, include = FALSE}
library(lme4)
```

```{r, eval = FALSE}
library(lme4)
lmer(Z_TP ~ Z_Length + (1 | Lake) + (1 | Fish_Species),
     data = fish.data, REML = TRUE)
```

--

* `lmer` ![:faic](arrow-right)"linear mixed model" function from `lme4` package
* `(1 | Lake)` ![:faic](arrow-right) indicate varying intercepts among lakes
* `REML = TRUE` ![:faic](arrow-right) estimation method

---
# Note on estimation methods

REML (*Restricted Maximum Likelihood*) is the default method in `lmer` (see `?lmer`).

The *Maximum Likelihood* (ML) method underestimate model variances by a factor of $(n-k)/n$, where $k$ is the number of fixed effects. 

The REML method corrects for this bias.

See this [article](https://towardsdatascience.com/maximum-likelihood-ml-vs-reml-78cf79bef2cf) for more information on the difference between ML and REML. 

---
# Note on estimation methods

**Remember that you should use :** 

* **REML** to compare models with **nested random effects** and the same fixed effect structure

* **ML** to compare models with **nested fixed effects** and the same random effect structure

* **ML** to compare models **with and without random effects**

---
# Step 2. Code potential models

**What if we want the slopes to vary?**

.center[
![](images/fig_22_w5.png)
]

---
# Step 2. Code potential models

**Different structures for the model :**

- `(1 | Lake)` random effect by lake at the intrecept
- `(1 + Z_Length | Lake)` random effect by lake at the intercept and slope in response to the body length (NB: (`Z_Length | Lake)` gives the same random structure)
- `(-1 + Z_Length | Lake)` to have only the random effect at the slope
- `(1 | Lake) + (1 | Species)`  for crossed random effects
- `(1 | Lake:Fish_Species)` for the interaction between 2 random effects

- If your dataset includes nested random effects, you could use `/` to specify them, e.g. `(1 | factor1 / factor2)` if `factor2` is nested in `factor1` ([see ![:faic](stack-exchange)](https://stats.stackexchange.com/questions/228800/crossed-vs-nested-random-effects-how-do-they-differ-and-how-are-they-specified))

---
# Challenge 4 ![:cube]()

Re-write the following code so that the **slopes** of the relationship between trophic position and body length **vary by lake and species**:

```{r}
lmer(Z_TP ~ Z_Length + (1 | Lake) + (1 | Fish_Species),
     data = fish.data, REML = TRUE)
```

---
# Solution ![:cube]()

```{r}
lmer(Z_TP ~ Z_Length + (1 + Z_Length | Lake) + (1 + Z_Length | Fish_Species),
     data = fish.data, REML = TRUE)
```


---
# Step 2. Model selection

* To determine if you have built the best mixed model based on your prior knowledge, you should compare this *a priori* model to other alternative models.

* With the dataset you are working on, there are several alternative models that might better fit your data.

---
# Challenge 5 ![:cube]()

Make a list of 7 alternative models that could be compared to this one:

```{r, eval= FALSE}
lmer(Z_TP ~ Z_Length + (1 | Lake) + (1 | Fish_Species),
     data = fish.data, REML = TRUE)
```

.comment[Note: If we had different fixed effects between the models or a model without random effects, we would have to specify `REML = FALSE` to compare with likelihood methods like AIC.]

---
# Solution ![:cube]()

We first will also build the **basic linear model** `lm()` because it is always useful to see the variation in the AICc values.

```{r}
M0 <- lm(Z_TP ~ Z_Length, data = fish.data)
```

However, to compare this model to the LMMs, it is important to .alert[change the estimation method to ML (`REML=FALSE`)] because `lm()` does not use the same estimation method as `lmer()`.

---
# Solution ![:cube]()

```{r}
# Linear model with no random effects
M0 <- lm(Z_TP ~ Z_Length, data = fish.data)
# Full model with varying intercepts
M1 <- lmer(Z_TP ~ Z_Length + (1 | Fish_Species) + (1 | Lake), 
           data = fish.data, REML = FALSE)
# Full model with varying intercepts and slopes
M2 <- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Fish_Species) + (1 + Z_Length | Lake),
           data = fish.data, REML = FALSE)
# No Lake, varying intercepts only
M3 <- lmer(Z_TP ~ Z_Length + (1 | Fish_Species), data = fish.data, REML = FALSE)
# No Species, varying intercepts only
M4 <- lmer(Z_TP ~ Z_Length + (1 | Lake), data = fish.data, REML = FALSE)
# No Lake, varying intercepts and slopes
M5 <- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Fish_Species), 
           data = fish.data, REML = FALSE)
# No Species, varying intercepts and slopes
M6 <- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Lake), data = fish.data, REML = FALSE)
# Full model with varying intercepts and slopes only varying by lake
M7 <- lmer(Z_TP ~ Z_Length + (1 | Fish_Species) + (1 + Z_Length | Lake),
           data = fish.data, REML = FALSE)
# Full model with varying intercepts and slopes only varying by species
M8 <- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Fish_Species) + (1 | Lake),
           data = fish.data, REML = FALSE)
```

---
# Solution ![:cube]()

When fitting LMMs with `lmer()`, you may encounter some errors or warnings such as: 

* `boundary (singular) fit: see ?isSingular`, see [this discussion ![:faic](stack-exchange)](https://stats.stackexchange.com/questions/378939/dealing-with-singular-fit-in-mixed-models)

* `Model failed to converge with max|grad| ...`, see [this discussion ![:faic](stack-exchange)](https://stats.stackexchange.com/questions/242109/model-failed-to-converge-warning-in-lmer)

Here a [list](https://rdrr.io/cran/lme4/man/troubleshooting.html) of possible problems and how to troubleshoot them.

---
# Step 2. Model selection

* Now that we have a list of potential models, we want to compare them to each other to select the one(s) with the highest predictive power given the data.

* Models can be compared by using the `AICc` function from the` MuMIn` package.

* The Akaike Information Criterion (AIC) is a **measure of model quality** that can be used to compare models.

* `AICc` corrects for bias created by small sample sizes.

---
# Step 2. Model selection

To find the AICc value of a model, use:

```{r}
library(MuMIn)
MuMIn::AICc(M1)
```

---
# Step 2. Model selection

To group all AICc values into a single table, use:
```{r}
AIC.table  <- MuMIn::model.sel(M0, M1, M2, M3, M4, M5, M6, M7, M8)
(AIC.table <- AIC.table[ , c("df", "logLik", "AICc", "delta")])
```

* `df` is the degree of freedom
* `logLik` is the loglikelihood
* `delta` is the AICc difference with the lowest value

We only displayed part of the results returned by the function `model.sel()`, see `?model.sel` for more information.

---
# Step 2. Model selection

What do these AICc values mean?

```{r}
AIC.table 

```

* The model with the smallest AICc has the highest predictive power.

* Some suggest that if models are within 2 AICc units of each other then they are equally plausible.

* Let's take a closer look at M8 and M2. We can exclude other model because they have such higher AICc.

---
# Step 2. Model selection

```{r}
M8 <- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Fish_Species) + (1 | Lake),
           data = fish.data, REML = TRUE)

M2 <- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Fish_Species) + (1 + Z_Length | Lake),
           data = fish.data, REML = TRUE)

MuMIn::model.sel(M2,M8)[ , c("df", "logLik", "AICc", "delta")]
```

Model `M8` seems to be the best among all models that we tested.

Note that we use now REML (i.e. `REML = TRUE`) as we are comparing two models with nested random effects and the same fixed effect structure.

---
# Step 2. Model selection

What is the structure of the best model?

```{r, eval = FALSE}
M8 <- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Fish_Species) + (1 | Lake),
           data = data, REML = FALSE)
```

Both the intercepts and slopes of the relationship between trophic position and length may vary by fish species, but only the intercepts may vary by lake.

.pull-left[![](images/fig_9_w5.png)]
.pull-right[![](images/fig_8_w5.png)]

---
# Step 2. Model selection

Once the best model is selected, the estimation method must be reset to `REML = TRUE`.

```{r}
M8 <- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Fish_Species) + (1 | Lake),
           data = fish.data, REML = TRUE)
```

---
exclude: true

# Challenge 6 ![:cube]()

Take 2 minutes with your neighbour to draw out the model structure of M2.

Biologically, how does it differ from M8?

Why is it not surprising that it's AICc value was 2nd best?

```{r, eval = FALSE}
M8 <- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Fish_Species) + (1 | Lake),
           data = fish.data, REML = TRUE)

M2 <- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Fish_Species) + (1 + Z_Length | Lake),
           data = fish.data, REML = TRUE)
```

---
exclude: true

# Solution


**Group discussion...**

--
exclude: true

.alert[M2] The trophic position is a function of length and both the intercept and the effect of length on trophic position can vary by fish species and lake.

  * .small[the intrinsic factors of species and lakes cause the relationship between trophic position and length to differ (i.e. both slopes and intercepts) (i.e. slopes and intercepts)]


.alert[M8] The trophic position is a function of length and both the intercept and the effect of length on trophic position can vary by fish species but only the intercept can vary by lake (not the slope of trophic position on length).

  * .small[intrinsic factors of species alone cause this relationship to differ (i.e. slopes) and that on average trophic positions might be higher or lower in one lake versus another (i.e. intercepts).]


---
# How to implement an LMM in R?

<img style="float: right; width:40%;margin: 1%" src="images/lego.jpg">

**Step 1. ** *A priori* model building and data exploration

<br>

**Step 2.** Code potential models and model selection

<br>

###### **Step 3.** Model validation

<br>

**Step 4 -** Model interpretation and visualization

---
# Step 3. Model validation

**You must verify that the model follows all the basic assumptions :**

<br>

**3.1 Check the homogeneity of the variance**
  - Plot predicted values vs residual values

<br>

**3.2 Check the independence of the model residuals**
  - Plot residuals vs each covariate of the model
  - Plot residuals vs each covariate not included in the model

<br>

**3.3 Check the normality of the model residuals**
  - Histogram of residuals


---
# Step 3. Model validation

**3.1 Check the homogeneity of the variance**

```{r, fig.width=4.5, fig.height=4.5, echo = -1}
par(mar=c(4,4,.5,.5))
plot(resid(M8) ~ fitted(M8), 
     xlab = 'Predicted values', 
     ylab = 'Normalized residuals')
abline(h = 0, lty = 2)
```

Homogeneous dispersion of the residuals ![:faic](arrow-right) the assumption is respected!

---
# Step 3. Model validation

**3.1 Check the homogeneity of the variance**

.center[
![](images/resid-plots.gif)
]

---
# Step 3. Model validation

**3.2 Check the independence of the model residuals with each covariate**

```{r, fig.width=11, fig.height=4.5, eval = FALSE}
par(mfrow = c(1,3), mar=c(4,4,.5,.5))

plot(resid(M8) ~ fish.data$Z_Length, 
     xlab = "Length", ylab = "Normalized residuals")
abline(h = 0, lty = 2)

boxplot(resid(M8) ~ Fish_Species, data = fish.data, 
        xlab = "Species", ylab = "Normalized residuals")
abline(h = 0, lty = 2)

boxplot(resid(M8) ~ Lake, data = fish.data, 
        xlab = "Lakes", ylab = "Normalized residuals")
abline(h = 0, lty = 2)
```

---
# Step 3. Model validation

**3.2 Check the independence of the model residuals with each covariate**

```{r, fig.width=12, fig.height=4.5, echo = FALSE}
par(mfrow = c(1,3), mar=c(4,4,.5,.5), cex.lab = 1.5)
plot(resid(M8) ~ fish.data$Z_Length, xlab = "Length", ylab = "Normalized residuals")
abline(h = 0, lty = 2)
boxplot(resid(M8) ~ Fish_Species, data = fish.data, xlab = "Species", ylab = "")
abline(h = 0, lty = 2)
boxplot(resid(M8) ~ Lake, data = fish.data, xlab = "Lakes", ylab = "")
abline(h = 0, lty = 2)
```

Homogeneous dispersion of the residuals around 0 ![:faic](arrow-right) no pattern of residuals depending on the variable, the assumption is respected!

.comment[Note: The clusters are due to the data structure, where fish of only 5 size classes (large, small, and three groups in between) were captured.]

---
# Step 3. Model validation

**3.2 Check the independence of the model residuals with each covariate**

- Plot residuals vs each covariate not included in the model

  - If you observe patterns in these plots, you will know that there is variation in your dataset that could be explained by these covariates. You should consider including them in your model.

  - Because we have included all the measured variables in our model, we can not do this step.

---
# Step 3. Model validation

**3.3 Check the normality of the model residuals**

* Residuals following a normal distribution indicate that the model is not biased

```{r, fig.height=5, fig.width=5}
hist(resid(M8))
```

---
# How to implement an LMM in R?

<img style="float: right; width:40%;margin: 1%" src="images/lego.jpg">

**Step 1:** *A priori* model building and data exploration

<br>

**Step 2:** Code potential models and model selection

<br>

**Step 3:** Model validation

<br>

###### **Step 4:** Model interpretation and visualization

---
# Step 4. Interpretation and visualization

```{r}
(summ_M8 <- summary(M8))
```

---
# Step 4. Interpretation and visualization

    # Random effects:
    #  Groups       Name        Variance Std.Dev. Corr
    #  Lake         (Intercept) 0.20500  0.4528
    #  Fish_Species (Intercept) 0.86621  0.9307
    #               Z_Length    0.02464  0.1570   1.00
    #  Residual                 0.05040  0.2245

- `Groups`: grouping factors
- `Name`:
  - `(Intercept)` for the intercepts,
  - or the name of the variable on which the random slope is estimated (`Z_length` in this example)
- `Variance` the variance of the estimated effect (`Std.Dev.` is the standard deviation of this estimate)
- `Corr` the correlation between the random interpet and the random slope for a given grouping factor (see [this dicussion ![:faic](stack-exchange)](https://stats.stackexchange.com/questions/320978/understanding-and-coding-random-intercept-correlation-lmer))

---
# Step 4. Interpretation and visualization

    # Fixed effects:
    #              Estimate Std. Error t value
    # (Intercept) -0.000906   0.568493  -0.002
    # Z_Length     0.422270   0.092170   4.581

This part presents the fixed effect estimates. The value of the t statistics [(Student test)](https://en.wikipedia.org/wiki/T-statistic) is shown **without the p-value** (it is a decision from the package authors, see why in [this discussion](https://stats.stackexchange.com/questions/185360/t-value-associated-with-nlme-lme4)).

This statistics could be used as it is. You could also calculate the 95% confidence interval (CI) with this equation:

$$ CI = Estimate \pm 1.96*Std.Error $$

If 0 is in the interval, then the parameter is not significantly different from zero at a threshold of $\alpha$ = 0.05.

---
# Step 4. Interpretation and visualization

**Some useful functions**

- `coef(M8)` and `ranef(M8)` return random effects of model M8

- `coef(summary(M8))` returns fixed effects

- `sigma(M8)` returns standard deviation of residuals

- `fitted(M8)` returns predicted values by the model

- `residuals(M8)` returns residuals

---
exclude: true

# Step 4. Interpretation and visualization

.center[
![](images/fig_30_w5.png)
]

<br>

.center[
![](images/fig_31_w5.png)
]

If the 95% confidence interval of the slope ($slope ± SE * 1.96$) includes zero, the slope (here = 0.4223), and therefore the effect of length on trophic position, is not significantly different from zero at the threshold $\alpha$ = 0.05.

---
# Challenge 6 ![:cube]()


1. What is the slope and confidence interval of the Z_Length variable in the M8 model?

2. Is the slope of Z_Length significantly different from 0?

---
# Solution ![:cube]()

1. What is the slope and confidence interval of the Z_Length variable in the M8 model?

  - slope = 0.422;

  - CI upper limit = 0.4223 + 0.09*1.96 = 0.5987

  - CI lower limit = 0.4223 - 0.09*1.96 = 0.2459

2. Is the slope of Z_Length significantly different from 0?

  - Yes, because the CI [0.2459, 0.5987] does not include 0

---
# Challenge 7 ![:cube]()

It is possible to visualize graphically the different intercepts and slopes of the model to better interpret the results

Take 2 minutes to think about different ways to represent the results of M8.

*Hint: consider the different "levels" of the model*

---
# Solution ![:cube]()

a) Figure with all data grouped

b) Figure by species

c) Figure by lake

---
# Solution ![:cube]()

To produce these figures, we need:

- The coefficients of the full model that are in the model summary

```{r}
summ_M8$coefficients
```
- Intercept = $`r summ_M8$coefficients[1,1]`$
- Slope = $`r summ_M8$coefficients[2,1]`$

---
# Solution ![:cube]()

To produce these figures, we need:

- The coefficients for each level of the model, which can be obtained with the `coef` function

```{r}
coef(M8)
```

---
# Solution ![:cube]()

a) Figure with all data grouped
```{r, eval = FALSE}
library(ggplot2)

# Create a simplified ggplot theme
fig <- theme_bw() +
        theme(panel.grid.minor=element_blank(),
              panel.grid.major=element_blank(),
              panel.background=element_blank()) +
        theme(strip.background=element_blank(),
              strip.text.y = element_text()) +
        theme(legend.background=element_blank()) +
        theme(legend.key=element_blank()) +
        theme(panel.border = element_rect(colour="black", fill=NA))

plot <- ggplot(aes(Z_Length, Z_TP), data = fish.data)
Plot_AllData <- plot + geom_point() +
                  xlab("Length (mm)") + 
                  ylab("Trophic position") +
                  labs(title = "All data") + fig

Plot_AllData + geom_abline(intercept = summ_M8$coefficients[1,1], 
                           slope     = summ_M8$coefficients[2,1])
```

---
# Solution ![:cube]()

a) Figure with all data grouped
```{r, echo = FALSE}
plot <- ggplot(aes(Z_Length, Z_TP), data = fish.data)
Plot_AllData <- plot + geom_point() +
  xlab("Length (mm)") + ylab("Trophic position") +
  labs(title = "All data") + fig

Plot_AllData + geom_abline(intercept = -0.0009059, slope = 0.4222697)
```

---
# Solution ![:cube]()

b) Figure by species

```{r, eval = FALSE}
# create a table with the coefs to facilitate their manipulation
Lake.coef              <- coef(M8)$Lake
colnames(Lake.coef)    <- c("Intercept", "Slope")
Species.coef           <- coef(M8)$Fish_Species
colnames(Species.coef) <- c("Intercept", "Slope")

Plot_BySpecies <- plot + 
                    geom_point(aes(colour = factor(Fish_Species)), size = 4) +
                    xlab("Length (mm)") + ylab("Trophic position") +
                    labs(title = "By species") + fig

# Add regression lines for each species
Plot_BySpecies +
  geom_abline(intercept = Species.coef[1,1], 
              slope     = Species.coef[1,2], col = "coral2") +
  geom_abline(intercept = Species.coef[2,1], 
              slope     = Species.coef[2,2], col = "green4") +
  geom_abline(intercept = Species.coef[3,1], 
              slope     = Species.coef[3,2], col = "blue1")

```

---
# Solution ![:cube]()

b) Figure by species

```{r, echo = F, fig.width=8}
Lake.coef              <- as.data.frame(coef(M8)$Lake)
colnames(Lake.coef)    <- c("Intercept", "Slope")
Species.coef           <- as.data.frame(coef(M8)$Fish_Species)
colnames(Species.coef) <- c("Intercept", "Slope")

Plot_BySpecies<-plot + geom_point(aes(colour = factor(Fish_Species)), size = 4) +
  xlab("Length (mm)") + ylab("Trophic position") +
  labs(title = "By species") + fig

# Add regression lines for each species
Plot_BySpecies +
  geom_abline(intercept = Species.coef[1,1], slope = Species.coef[1,2], col = "coral2") +
  geom_abline(intercept = Species.coef[2,1], slope = Species.coef[2,2], col = "green4") +
  geom_abline(intercept = Species.coef[3,1], slope = Species.coef[3,2], col = "blue1")

```

---
# Solution ![:cube]()

c) Figure by lake

```{r, eval= FALSE}
Plot_ByLake <- plot + 
                geom_point(aes(colour = factor(Lake)), size = 4) +
                xlab("Length (mm)") + ylab("Trophic Position") +
                labs(title = "By Lake") + fig

# Add in regression lines with the intercepts specific to each lake
Plot_ByLake +
  geom_abline(intercept = Lake.coef[1,1], 
              slope     = Lake.coef[1,2], col = "coral2") +
  geom_abline(intercept = Lake.coef[2,1], 
              slope     = Lake.coef[2,2], col = "khaki4") +
  geom_abline(intercept = Lake.coef[3,1], 
              slope     = Lake.coef[3,2], col = "green4") +
  geom_abline(intercept = Lake.coef[4,1], 
              slope     = Lake.coef[4,2], col = "darkgoldenrod") +
  geom_abline(intercept = Lake.coef[5,1], 
              slope     = Lake.coef[5,2], col = "royalblue1") +
  geom_abline(intercept = Lake.coef[6,1], 
              slope     = Lake.coef[6,2], col = "magenta3")

```

---
# Solution ![:cube]()

c) Figure by lake
```{r, echo = F, fig.width=8}
Plot_ByLake<-plot + geom_point(aes(colour = factor(Lake)), size = 4) +
  xlab("Length (mm)") + ylab("Trophic position") +
  labs(title = "par lac") + fig

# Plot the data color coded by lake
Plot_ByLake +
  geom_abline(intercept = Lake.coef[1,1], slope = Lake.coef[1,2], col = "coral2") +
  geom_abline(intercept = Lake.coef[2,1], slope = Lake.coef[2,2], col="khaki4") +
  geom_abline(intercept = Lake.coef[3,1], slope = Lake.coef[3,2], col="green4") +
  geom_abline(intercept = Lake.coef[4,1], slope = Lake.coef[4,2], col="darkgoldenrod") +
  geom_abline(intercept = Lake.coef[5,1], slope = Lake.coef[5,2], col="royalblue1") +
  geom_abline(intercept = Lake.coef[6,1], slope = Lake.coef[6,2], col="magenta3")

```

---

exclude: true

# Mixed model and ecological data

Mixed models are very useful for taking into account the complex structure of ecological data while not loosing too many degrees of freedom

.center[
![](images/fig_1_qcbs_wiki.png)
]

---
# Challenge 8 ![:cube]()

**Situation:**

* You have inventoried species richness **in 1000 quadrats** that are within **10 different sites** which are also within **10 different forests**.

* You also **measured productivity** in each **quadrat**.

* You want to know if productivity is a good predictor of biodiversity

.alert[What mixed model could you use for this dataset?]

---
# Solution!![:cube]()

```{r, eval = FALSE}
lmer(Biodiv ~ Productivity + (1 | Forest / Site))
```

Here the random effects are nested (i.e. Sites within forest) and not crossed.

Why use `(1 | Forest / Site)` rather than `(1 | Forest) + (1 | Site)`? See [the answer in ![:faic](stack-exchange)](https://stats.stackexchange.com/questions/228800/crossed-vs-nested-random-effects-how-do-they-differ-and-how-are-they-specified)!

---
exclude: true

# Challenge 10![:cube]()

**Situation:**

* You have collected **200 fish** from **12 different sites** evenly distributed across **4 habitat types** that are found within **the same lake**.

* You measured **the length of each fish** and the **amount of mercury in its tissue**.

* You want to know if habitat is a good predictor of mercury concentration.

.alert[What mixed model could you use for this dataset?]
---
exclude: true

## Solution!![:cube]()

```{r, eval = FALSE}
lmer(Mercury ~ Length * Habitat_Type + (1 | Site))
```

---
class: inverse, center, middle

# GLMMs


---
exclude: true
# Review: Linear Mixed Models

**Review of LMM Workshop**:

- Structure in the dataset or correlation among observations can result in **lack of independence among observations** sampled from same sites or time points
- Account for this by including r**andom effect terms**

**Random effects**:

- Parameter is a sample from the population, i.e. the subjects you happen to be working with
- Explains the variance of the response variable

**Fixed effects**:

- Parameter is reproducible, i.e. would be the same across studies
- Explain the mean of the response variable


---
exclude: true
# Review: Linear Mixed Models

.pull-left[
**Shrinkage estimates**

- Random effects are often called **shrinkage estimates** because they represent a weighted average of the data and the overall fit (fixed effect)
- The random effect shrinkage toward the overall fit (fixed effect) is more severe if the within-group variability is large compared to the among-group variability
]

.pull-right[
<br>
![](images/lmm.png)
]


---
# Generalized Linear Mixed Models (GLMMs)

**Extension of GLMs to account for additional structure in dataset**

Follows similar steps introduced in LMM Workshop :

**1.** Incorporate random effects (like LMMs)

**2.** Handle non-normal data (letting errors take on different distribution families - e.g. Poisson or negative binomial) (like GLMs)


---
exclude: true
# Review: Generalized Linear Models (GLM)

_Include 2-3 slides recalling GLM_


---
# Implementing GLMMs in R

Import the `Arabidopsis` dataset `banta_totalfruits.csv` into `R`.

```{r, echo = F}
dat.tf <- read.csv("data/banta_totalfruits.csv")
```

```r
dat.tf <- read.csv("banta_totalfruits.csv")
```
```r
# popu factor with a level for each population
# gen factor with a level for each genotype
# nutrient factor with levels for low (value = 1) or high (value = 8)
# amd factor with levels for no damage or simulated herbivory
# total.fruits integer indicating the number of fruits per plant
```

The effect of nutrient availability and herbivory (**fixed effects**) on the fruit production (**response variable**) of Arabidopsis thaliana was evaluated by measuring 625 plants across 9 different populations, each comprised of 2 to 3 different genotypes (**random effects**)


---
# Choosing an error distribution

The response variable is count data which suggests we need a **Poisson distribution** (i.e. the variance is equal to the mean)

```{r, echo = F, fig.height = 5, fig.width = 6}
par(mypar);par(cex = 1.4)
hist(dat.tf$total.fruits, breaks = 50, col = 'blue', main = '',
     xlab = 'Total fruits', ylab = 'Count')
```

However, as we will soon see, the variance increases with the mean much more rapidly than expected under the Poisson distribution...


---
# Exploring variance

To illustrate heterogeneity in variance we will first create boxplots of the **log** of total fruit production (**response variable**) versus different environmental factors.

Let's create new variables that represent every combination of **nutrient** x **clipping** x **random factor**

```{r}
dat.tf <- within(dat.tf,
{
  # genotype x nutrient x clipping
  gna <- interaction(gen,nutrient,amd)
  gna <- reorder(gna, total.fruits, mean)
  # population x nutrient x clipping
  pna <- interaction(popu,nutrient,amd)
  pna <- reorder(pna, total.fruits, mean)
})
```


---
# Exploring variance

.small[
```{r, fig.height =  3.5, fig.width = 8}
# Boxplot of total fruits vs genotype x nutrient x clipping interaction
ggplot(data = dat.tf, aes(factor(x = gna), y = log(total.fruits + 1))) +
  geom_boxplot(colour = "skyblue2", outlier.shape = 21,
  outlier.colour = "skyblue2") +
  ylab("log (Total fruits)\n") + # \n creates a space after the title
  xlab("\nGenotype x nutrient x clipping") + # space before the title
  theme_bw() + theme(axis.text.x = element_blank()) +
  stat_summary(fun = mean, geom = "point", colour = "red")
```
]

.comment[Similarly, the variance of total fruits shows a large amount of heterogeneity among populations (population x nutrient x clipping interaction).]


---
# Choosing error distribution

As we just saw, there is a large amount of heterogeneity among group variances even when the response variable is transformed (i.e. log).

If we plot the **group variances vs group means** (genotype x nutrient x clipping grouping), we can appreciate that the Poisson family is the least appropriate distribution (i.e. variances increase much faster than the means).

```{r, echo = F, fig.height = 5.3, fig.width = 8, fig.align = 'center'}
# Code used to produce the plot : https://github.com/QCBSRworkshops/workshop07/blob/main/pres-fr/data/glmm_e.r

# Substantial variation among the sample variances on the transformed data
# For example, among genotypes:
grpVars <- tapply(dat.tf$total.fruits, dat.tf$gna, var)

grpMeans <- tapply(dat.tf$total.fruits,dat.tf$gna, mean)

# Quasi-Poisson
lm1 <- lm(grpVars~grpMeans-1) 
phi.fit <- coef(lm1)
# The -1 specifies a model with the intercept set to zero

# Negative binomial
lm2 <- lm(grpVars ~ I(grpMeans^2) + offset(grpMeans)-1)
k.fit <- 1/coef(lm2)
# The offset() is used to specify that we want the group means added as a term with its coefficient fixed to 1

# Non-parametric loess fit
Lfit <- loess(grpVars~grpMeans)

# The plot
par(mypar);par(cex = 1.2)
plot(grpVars ~ grpMeans, xlab = "Group means", ylab = "Group variances" )
abline(a = 0, b = 1, lty = 2)
text(105,500, "Poisson")
curve(phi.fit*x, col = 2, add = TRUE)
# bquote() is used to substitute numeric values in equations with symbols
text(110,3900,
     bquote(paste("QP: ", sigma^2==.(round(phi.fit,1))*mu)), col = 2)
curve(x*(1+x/k.fit), col = 4, add = TRUE)
text(104,7200, paste("NB: k = ", round(k.fit, 1), sep = ""), col = 4)
mvec <- 0:120
lines(mvec, predict(Lfit, mvec), col = 5)
text(118, 2000, "loess", col = 5)
```


---
# Poisson GLMM

**Given the mean-variance relationship, we will most likely need a model with overdispersion.**

To understand why, let's start with a Poisson model.

--

To run a GLMM in `R` we will use the `glmer()` function from the `lme4` package :

```{r}
library(lme4)
mp1 <- glmer(total.fruits ~ nutrient*amd + rack + status +
             (1|popu)+
             (1|gen),
             data = dat.tf, family = "poisson")
```

**Random effects**: `(1|popu)` and `(1|gen)`. We model random intercepts for both factors so that total fruit production can vary among populations (`popu`) and genotypes (`gen`).


---
# Overdispersion check

We can check for overdispersion using the `overdisp_fun()` function (Bolker *et al*. 2011) which divides the Pearson residuals by the residual degrees of freedom. 

The function tests whether **the ratio is greater than 1**.

--

Let's run the test :
```{r}
# Download the glmm_funs.R code from the wiki page and source it to run the function
source(file = "data/glmm_funs.R")
# Overdispersion?
overdisp_fun(mp1)
```
--
.alert[Ratio is significantly > 1]
<br><br>

As expected, we need to model a **different distribution** where the variance increases more rapidly than the mean.


---
# Negative binomial GLMM .small[(Poisson-gamma)]

**Option 1.** Recall that the **negative binomial** (or Poisson-gamma) distribution meets the assumption that the variance is proportional to the square of the mean

<br>
--
We model this distribution using the function `glmer.nb()` :
```{R}
mnb1 <- glmer.nb(total.fruits ~ nutrient*amd + rack + status +
                 (1|popu)+
                 (1|gen),
                 data = dat.tf,
                 control = glmerControl(optimizer = "bobyqa"))
# Control argument specifies the way we optimize the parameter values
```

--
We test again for overdispersion :
```{R}
# Overdispersion?
overdisp_fun(mnb1)
```

.alert[Ratio is now much closer to 1 although p < 0.05]


---
# Poisson-lognormal GLMM

**Option 2.** The **Poisson-lognormal** distribution
<br>

This can be achieved simply by placing an **observation-level random effect** in the model formula.

See Harrison (2014) for further details https://doi.org/10.7717/peerj.616.

<br>
--
To do so, we first create a variable named `X` :
```{r}
# This variable is already in your data "dat.tf", but here is how we create it :
dat.tf$X <- 1:nrow(dat.tf)
```


We take overdispersion into account by adding the random effect `(1|X)` in the formula :
```{r}
mpl1 <- glmer(total.fruits ~ nutrient*amd + rack + status +
              (1|X) +
              (1|popu)+
              (1|gen),
data = dat.tf, family = "poisson",
control = glmerControl(optimizer = "bobyqa"))
```


---
# GLMM Poisson-lognormale
<br><br><br>

Finally, we test for overdispersion :
```{r}
overdisp_fun(mpl1)
```

.alert[Ratio now meets our criterion, thus, < 1]


---
# Poisson-lognormal GLMM

**Let's visualize the model parameters**

Can be obtained using the `coefplot2()` function from the `coefplot2` package :
<br><br>


.alert[![:faic](warning) This package is not on CRAN! We install it from GitHub using the remotes package.]

```{R install_coefplot2}
if (!require("coefplot2"))
  remotes::install_github("palday/coefplot2", subdir = "pkg")
library(coefplot2)
```


---
# Poisson-lognormal GLMM

.pull-left[
```{r, fig.height = 5, fig.width = 6, echo = -1}
par(cex = 1.4) #;par(mypar)
# Variance terms
coefplot2(mpl1, ptype = "vcov", intercept = TRUE, main = "Random effect variance")
```
]
.pull-right[
```{r, fig.height = 5, fig.width = 6, echo = -1}
par(cex = 1.3) #;par(mypar)
# Fixed effects
coefplot2(mpl1, intercept = TRUE, main = "Fixed effect coefficient")
```
]

.comment[Note : error bars are only shown for the fixed effects because `glmer()` doesn't model uncertainty for random effects.]


---
# Poisson-lognormal GLMM

**Let's visualize the random effects**

You can extract the random effect predictions using `ranef()` and plot them using a `dotplot()` from the `lattice` package.

<br>
--

We observe differences **among population** :

- Spanish populations (SP) have larger values than Swedish (SW) or Dutch (NL) populations

We observe mild differences **among genotypes** :

- Difference among genotypes largely driven by genotype 34

```r
library(gridExtra)
library(lattice)
# dotplot code
pp <- list(layout.widths = list(left.padding = 0, right.padding = 0),
           layout.heights = list(top.padding = 0, bottom.padding = 0))
r2 <- ranef(mpl1, condVar = TRUE)
d2 <- dotplot(r2, par.settings = pp)

grid.arrange(d2$gen, d2$popu, nrow = 1)
```


---
# Poisson-lognormal GLMM

**Let's visualize the random effects**

<br>

```{r, echo = F, fig.width = 9}
library(gridExtra)
library(lattice)

pp <- list(layout.widths = list(left.padding = 0, right.padding = 0),
           layout.heights = list(top.padding = 0, bottom.padding = 0))
r2 <- ranef(mpl1, condVar = TRUE)
d2 <- dotplot(r2, par.settings = pp, scales = list(x = list(cex = 1.4), y = list(cex = 1.3)))
grid.arrange(d2$gen, d2$popu, nrow = 1)
```


---
# Model selection

The same methods can be used with a glmm or lmm to choose between models with various random intercepts and/or random slopes and to choose fixed effects to keep in final model.

<br>

Here are two approaches :

- an **information theoretic approach** (e.g., AICc - Workshop 5)
- a **frequentist approach** (where the significance of each term is evaluated using a likelihood ratio test; LRT, with the `anova()` function)


---
# Model selection

We first code potential models and compare them using AICc.comment[*]:

```{r}
mpl2 <- update(mpl1, . ~ . - rack) # model without rack
mpl3 <- update(mpl1, . ~ . - status) # model without status
mpl4 <- update(mpl1, . ~ . - amd:nutrient) # without amd:nutrient interaction

aic_tab  <- MuMIn::model.sel(mpl1, mpl2, mpl3, mpl4)
(round(aic_table <- aic_tab[ , c("AICc", "delta", "df")], digits = 2))
```

.comment[*NB: We do not cover all possible models above, however, the interaction `amd:nutrient` can only be evaluated if both amd and nutrient (i.e., the main effects) are included in the model.
]


---
# Model selection

Alternatively, we can use `drop1()` and `dfun()` functions to evaluate our fixed effects (`dfun()` converts the AIC values returned by the `drop1()` into $\Delta$AIC values)

.small[
```{r}
dd_LRT <- drop1(mpl1, test = "Chisq")
(dd_AIC <- dfun(drop1(mpl1)))
```
]

--

- Strong **rack** effect (dAIC = 55.08 if we remove this variable)
- Effects of **status** and **interaction** term are weak (dAIC < 2)


---
# Model selection
Let's start by **removing the non-significant interaction** term to test main effects of nutrient and clipping
```{r}
mpl2 <- update(mpl1, . ~ . - amd:nutrient)

mpl3 <- update(mpl2, . ~ . - rack) # pas de rack ou d'interaction
mpl4 <- update(mpl2, . ~ . - status) # pas de status ou d'interaction
mpl5 <- update(mpl2, . ~ . - nutrient) # pas de nutrient ou d'interaction
mpl6 <- update(mpl2, . ~ . - amd) # pas d'herbivorie ou d'interaction
```

Choose the method you want to select the best model :
.pull-left2[ Method with AICc
```{r}
aic_tab2  <- MuMIn::model.sel(mpl2, mpl3, mpl4, mpl5, mpl6)
(round(aic_table2 <- aic_tab2[ , c("AICc", "delta", "df")], digits = 2))
```
]
.pull-right2[ Method with `drop1()`
```{r}
dd_LRT2 <- drop1(mpl2, test = "Chisq")
dd_AIC2 <- dfun(drop1(mpl2))
```
]


---
# Model selection
**What are our conclusions ?**
<br>

Both the main effects of **nutrient** and **clipping** are strong (large change in AIC of $135.6$ (`mpl5`) and $10.2$ (`mpl6`) if either nutrient or clipping are dropped, respectively).

<br>

**Our final model includes :**

Fixed effects
* nutrients
* clipping
* rack

Random effects
* observation-level random effect `(1|X)` 
* populations `(1|popu)` 
* genotypes `(1|gen)`


---
# Challenge 9 ![:cube]()

Use the `inverts` dataset (larval development times (`PLD`) of 74 marine invertebrate and vertebrate species reared at different temperatures and time), answer the following questions:

- What is the effect of feeding type and climate (**fixed effects**) on `PLD`?
- Does this relationship vary among taxa (**random effects**)?
- What is the **best distribution family** for this count data?
- Finally, once you determined the best distribution family, re-evaluate your random and fixed effects.


---
# Solution ![:cube]()

```{R, eval = FALSE}
# inverts <- read.csv('data/inverts.csv', header = TRUE)
# head(inverts)
# table(inverts$temp, inverts$feeding.type)

# mod.glm <- glm(PLD ~ temp + feeding.type, family = poisson(), data = inverts)
# summary(mod.glm)
# drop1(mod.glm, test = "Chisq")

# boxplot(PLD ~ temp,  data = inverts)
# boxplot(PLD ~ feeding.type,  data = inverts)

# boxplot(predict(mod.glm, type = "response")~inverts$temp)

# plot()

# modglm <- glm(PLD ~ temp + feeding.type, family = poisson(), data = inverts)
```


---
# Solution ![:cube]()
```{R, eval = FALSE}
# r2 <- ranef(mpl1, condVar = TRUE)
# d2 <- dotplot(r2, par.settings = pp)

# plot(aggregate(PLD ~ taxon, FUN = mean, data = inverts)[,2], aggregate(PLD ~ taxon, FUN = var, data = inverts)[,2], pch = 19)
# abline(a = 0, b = 1, lty = 2)

# mod.glmer <- glmer.nb(PLD ~ temp + feeding.type + (1|taxon), data = inverts)
# mod.glm <- glm.nb(PLD ~ temp + feeding.type, family = poisson(), data = inverts)

# plot(aggregate(PLD ~ taxon, FUN = var, data = inverts)[,2], aggregate(PLD ~ taxon, FUN = mean, data = inverts)[,2])
# abline(a = 0, b = 1, lty = 2 )
```


---
exclude: true
## Group discussion [:cube]()

Do you have believe that you have a question that requires the use of a mixed model?


---
# Additional ressources

.center[
![:scale 16%](images/book1.jpg) ![:scale 18%](images/book2.jpg) ![:scale 16%](images/book3.jpg)
]

**Popular libraries for (G)LMMs** 

* Frequentist : `nlme`, `lme4`, `glmmTMB`
* Bayesian : `brms`, `rstan`, `rstanarm`, `MCMCglmm`

**Papers**
* [Harrison *et al.* (2018), *PeerJ*, DOI 10.7717/peerj.4794
](http://dx.doi.org/10.7717/peerj.4794)
* [Silk *et al.* (2020), *PeerJ*,  DOI 10.7717/peerj.9522
](https://doi.org/10.7717/peerj.9522)
* [Schielzeth *et al.* (2020), *Methods Ecol Evol.*,  DOI: 10.1111/2041-210X.13434
]( https://doi.org/10.1111/2041-210X.13434)
* [Zuur & Ieno (2016), *Methods Ecol Evol.*,  DOI: 10.1111/2041-210X.12577
]( https://doi.org/10.1111/2041-210X.12577)


---
class: inverse, center, bottom

# Thank you for attending this workshop!

![:scale 50%](images/qcbs_logo.png)
