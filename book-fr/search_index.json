[["index.html", "Atelier 7: Modèles linéaires et généralisés linéaires mixtes Série d’ateliers R du CSBQ Préface 0.1 Code de conduite 0.2 Contributeurs et contributrices 0.3 Contribuez à la série!", " Atelier 7: Modèles linéaires et généralisés linéaires mixtes Série d’ateliers R du CSBQ Développé et entretenu par les contributeurs et les contributrices de la Série d’ateliers R du CSBQ1. 2021-07-28 20:40:40 Préface La Série d’ateliers R du CSBQ est une série de 10 ateliers qui guide les participants à travers les étapes nécessaires à l’utilisation de R pour un large éventail d’analyses statistiques pertinentes pour la recherche en biologie et en écologie. Ces ateliers en accès libre ont été créés par des membres du CSBQ, à la fois pour les membres du CSBQ et pour la communauté au sens large. Le contenu de cet atelier a été revu par plusieurs membres du CSBQ. Si vous souhaitez suggérer des modifications, veuillez contacter les coordinateurs de la série actuelle, dont la liste figure sur la page principale de Github 0.1 Code de conduite La Série d’ateliers R du CSBQ et le Symposium R du CSBQ sont des lieux dédiés à fournir un environnement accueillant et favorable à toutes les personnes, indépendamment de leurs origines ou de leur identité. Les participants, les présentateurs et les organisateurs de la série d’ateliers et d’autres activités connexes acceptent le présent code de conduite lorsqu’ils assistent à des activités liées aux ateliers. Nous ne tolérons pas les comportements irrespectueux ou qui excluent, intimident ou gênent les autres. Nous ne tolérons pas la discrimination ou le harcèlement fondés sur des caractéristiques telles que, mais sans s’y limiter, l’identité et l’expression du genre, l’orientation sexuelle, le handicap, l’apparence physique, la taille du corps, la citoyenneté, la nationalité, les origines ethniques ou sociales, la grossesse, le statut familial, les informations génétiques, la religion ou les convictions (ou l’absence de celles-ci), l’appartenance à une minorité nationale, la propriété, l’âge, l’éducation, le statut socio-économique, les choix techniques et le niveau d’expérience. Il s’applique à tous les espaces gérés par l’atelier ou affiliés à celui-ci, y compris, mais sans s’y limiter, les ateliers, les listes de diffusion et les forums en ligne tels que GitHub, Slack et Twitter. 0.1.1 Comportement attendu Tous les participants sont tenus de faire preuve de respect et de courtoisie envers les autres. Toutes les interactions doivent être professionnelles, quelle que soit la plateforme utilisée : en ligne ou en personne. Afin de favoriser un environnement d’apprentissage positif et professionnel, nous encourageons les types de comportements suivants dans tous les événements et plates-formes des ateliers : Utiliser un langage accueillant et inclusif ; Respecter les différents points de vue et expériences ; Accepter avec grâce les critiques constructives ; Se concentrer sur ce qui est le mieux pour la communauté ; Faire preuve de courtoisie et de respect envers les autres membres de la communauté. 0.1.2 Comportements inacceptables Voici quelques exemples de comportements inacceptables de la part des participants à tout événement ou plateforme d’atelier : les commentaires écrits ou verbaux qui ont pour effet d’exclure des personnes sur la base de leur appartenance à un groupe spécifique ; faire craindre à quelqu’un pour sa sécurité, par exemple en le harcelant ou en l’intimidant ; des menaces ou des propos violents dirigés contre une autre personne ; l’affichage d’images sexuelles ou violentes ; l’attention sexuelle non désirée ; les contacts physiques non consensuels ou non désirés ; des insultes ou des rabais ; les blagues sexistes, racistes, homophobes, transphobes, incapables ou d’exclusion ; l’incitation à la violence, au suicide ou à l’automutilation ; la poursuite de l’interaction (y compris la photographie ou l’enregistrement) avec une personne après qu’on - lui a demandé d’arrêter ; la publication d’une communication privée sans consentement. 0.2 Contributeurs et contributrices Développé à l’origine par : A contribué à modifier la présentation : Contribution avec des changements à la documentation écrite : Contribution en signalant des problèmes et en suggérant des modifications : 0.3 Contribuez à la série! En construction. La Série d’ateliers R du CSBQ fait partie du Centre de la science de la biodiversité du Québec, et est maintenue par les coordonnateurs et les coordonnatrices de la série, et les membres étudiants diplômés, postdoctoraux et professionnels de la recherche. La liste des contributeurs et des contributrices de cet atelier sont accessiblesici↩︎ "],["objectifs-dapprentissage.html", "Chapitre 1 Objectifs d’apprentissage", " Chapitre 1 Objectifs d’apprentissage Les modèles à effets mixtes permettent aux écologistes de surmonter un certain nombre de limitations liées aux modèles linéaires traditionnels. Dans cet atelier, vous apprendrez à déterminer si vous devez utiliser un modèle à effets mixtes pour analyser vos données. En particulier, nous allons: 1. Décrire les modèles (généralisés) à effets mixtes 2. Identifier les situations dans lesquelles l’utilisation d’effets mixtes est appropriée 3. Construire des modèles linéaires mixtes avec R 4. Exécuter des modèles linéaires généralisés mixtes de base avec R 5. Valider, interpréter et visualiser les modèles mixtes avec R "],["préparez-vous-pour-cet-atelier.html", "Chapitre 2 Préparez-vous pour cet atelier", " Chapitre 2 Préparez-vous pour cet atelier Pour vous préparer pour cet atelier, téléchargez et installez les dernières versions de RStudio et de R. Télécharger également les données et quelques fonctions additionnelles que nous utiliserons au cours de cet atelier: Script R Données: Poissons Données: Arabidopsis Données: Invertébrés glmm_funs (Code pour la section sur les GLMMs) Cet atelier nécessite les paquets R suivants: lme4 AICcmodavg MASS vcdExtra bbmle MuMIn ggplot2 DescTools remotes gridExtra lattice Pour les installer à partir de CRAN, roulez: install.packages(&quot;lme4&quot;) install.packages(&quot;AICcmodavg&quot;) install.packages(&quot;MASS&quot;) install.packages(&quot;vcdExtra&quot;) install.packages(&quot;bbmle&quot;) install.packages(&quot;MuMIn&quot;) install.packages(&quot;ggplot2&quot;) install.packages(&quot;DescTools&quot;) install.packages(&quot;remotes&quot;) install.packages(&quot;gridExtra&quot;) install.packages(&quot;lattice&quot;) Ensuite, chargez ces paquets: library(lme4) library(AICcmodavg) library(MASS) library(vcdExtra) library(bbmle) library(MuMIn) library(ggplot2) library(DescTools) library(remotes) library(gridExtra) library(lattice) "],["pourquoi-choisir-un-mlm.html", "Chapitre 3 Pourquoi choisir un MLM?", " Chapitre 3 Pourquoi choisir un MLM? Les données écologiques et biologiques peuvent être complexes et désordonnées. Il existe généralement une structure particulière dans les données (i.e. les observations individuelles ne sont pas toujours indépendantes), les relations entre les variables d’intérêt peuvent différer en fonction de facteurs de regroupement, telles que les espèces, et la plupart du temps de faibles tailles d’échantillons rendent l’ajustement de modèles avec de nombreux paramètres difficile. Les modèles linéaires à effets mixtes (MLM) ont été développés pour aborder ces questions. Ils peuvent être appliqués à un grand nombre de questions écologiques et prennent de nombreuses formes différentes. Dans cet atelier, nous allons utiliser une simple approche interrogative pour apprendre les bases du fonctionnement des MLMs et nous verrons comment les ajuster. "],["commencer-par-une-question.html", "Chapitre 4 Commencer par une question 4.1 Défi 1", " Chapitre 4 Commencer par une question Avant de nous plonger dans le vif du sujet, commençons par se familiariser avec le jeu de données que nous utiliserons à titre d’exemple pour proposer une question de recherche. Le jeu de données que nous utiliserons porte sur les positions trophiques des poissons. Dans ce jeu de données, des données ont été collectées pour 3 espèces de poissons différentes (S1-3) avec 10 individus échantillonnés par espèce dans 6 lacs différents (L1-6). Les individus de chaque espèce ont été mesurés et présentent des variations dans leur longueur corporelle et leur position trophique. Voici une représentation visuelle pour vous aider à comprendre tout cela! Notez: seulement trois individus sont montrés par espèce, mais en réalité il y a 10 individus par espèce. Une simple question à laquelle vous pourriez répondre avec ce jeu de données est est-ce que la position trophique des poissons augmente avec leur taille? Au cours de l’atelier, on tentera de répondre à cette question. 4.1 Défi 1 Pour notre premier défi, nous allons commencer à examiner notre jeu de données plus en profondeur. Reproduisez les graphiques 1-3 en utilisant le script ci-dessous et le jeu de données de poissons. Observez les graphiques puis evaluez ce que vous observez. Quelques questions clés sont: 1. Est-ce qu’on s’attend à ce que, pour toutes les espèces, la position trophique augmente avec la longueur corporelle? Exactement de la même façon? 2. S’attend-on à ce que la relation entre la position trophique et la longueur corporelle soit pareille entre les lacs? Comment ces relations pourraient-elles différer? # Chargez le jeu de données fish.data &lt;- read.csv(&#39;data/qcbs_w7_data.csv&#39;, stringsAsFactors = TRUE) # Cette ligne variera en fonction de l&#39;endroit où vos données sont enregistrées. #Vérifiez votre répertoire de travail avec getwd(), et changez-le avec setwd() au besoin. # Format &#39;custom&#39; pour simplifier tous les figures ggplot produites par la suite fig &lt;- theme_bw() + theme(panel.grid.minor=element_blank(), panel.grid.major=element_blank(), panel.background=element_blank(), strip.background=element_blank(), strip.text.y = element_text(), legend.background=element_blank(), legend.key=element_blank(), panel.border = element_rect(colour=&quot;black&quot;, fill = NA)) # Explorez les données graphiquement! # Structure ggplot de base pour la relation qui nous intéresse plot &lt;- ggplot(aes(x = Fish_Length, y = Trophic_Pos), data = fish.data) # Graphique 1 - Toutes les données plot + geom_point() + labs(x = &quot;Longueur corporelle (mm)&quot;, y = &quot;Position trophique&quot;, title = &quot;Toutes les données&quot;) + fig # notre joli format ggplot! # Graphique 2 - Par espèce plot + geom_point() + facet_wrap(~ Fish_Species) + # séparer la visualisation par espèce labs(x = &quot;Longueur corporelle (mm)&quot;, y = &quot;Position trophique&quot;, title = &quot;Par espèce&quot;) + fig # Graphique 3 – Par lac plot + geom_point() + facet_wrap(~ Lake) + # séparer la visualisation par lac labs(x = &quot;Longueur corporelle (mm)&quot;, y = &quot;Position trophique&quot;, title = &quot;Par lac&quot;) + fig Défi 1 Solution A partir de ces graphiques, nous pouvons tirer deux premières observations: 1. Toutes les espèces semblent augmenter leur position trophique avec la longueur, mais la pente peut être différente selon les espèces. 2. Certains paramètres spécifiques à chaque lac en particulier (e.g. la productivité primaire du système) peuvent changer la relation observée. "],["analyse-des-données.html", "Chapitre 5 Analyse des données 5.1 Option 1: Nombreuses analyses séparées 5.2 Option 2: Une analyse groupée 5.3 Option 3: Est-ce qu’on a une autre option?", " Chapitre 5 Analyse des données Nous savons que les données écologiques et biologiques sont souvent complexes. De nombreux ensembles de données comprennent: Une structure hiérarchique des données Nombreuses covariables et facteurs de regroupement Une étude ou un plan expérimental non équilibré Alors, comment pouvons-nous analyser nos données? Option 1: Séparer - Faire une analyse séparée pour chaque espèce et chaque lac. Option 2: Tout regrouper - Faire une seule analyse en ignorant les variables espèce et lac. Option 3: ? Examinons de plus près ces options en utilisant notre ensemble de données sur les poissons! 5.1 Option 1: Nombreuses analyses séparées Une façon d’analyser ces données est de faire des régressions linéaires pour chaque espèce dans chaque lac. Voici à quoi cela ressemblerait pour l’espèce 1 dans le lac 1: Remarquez que vous devez estimer une ordonnée à l’origine et une pente pour chaque régression (2 paramètres x 3 espèces X 6 lacs = 36 paramètres estimés) et la taille d’échantillon pour chaque analyse est de 10. Il y a peu de chances de détecter un effet à cause de la faible taille d’échantillon et un taux d’erreur augmenté en raison de comparaisons multiples. 5.2 Option 2: Une analyse groupée Une autre façon d’analyser ces données est de faire une seule analyse en ignorant les variables espèce et lac. Voici à quoi cela ressemblerait pour toutes nos données dans tous les lacs à la fois Remarquez que vous avez maintenant une taille d’échantillon énorme et beaucoup moins de paramètres à estimer! Mais qu’en est-il de la pseudo-réplication? Les poissons d’un même lac et d’une même espèce peuvent être corrélés. De plus, regardez tout ce bruit dans les données! Une partie pourrait être due à des différences entre les espèces et les lacs. 5.3 Option 3: Est-ce qu’on a une autre option? Pour notre question, on veut seulement savoir s’il y a un effet général de la longueur corporelle sur la position trophique. Cependant, cette relation peut différer légèrement entre les espèces en raison de processus biologiques non mesurés (par exemple, le taux de croissance) ou entre les lacs en raison de variables environnementales non mesurées. Mais cette variation ne nous intéresse pas, nous devons donc trouver un moyen de contrôler ces effets potentiels tout en maximisant l’utilisation de nos données. C’est pourquoi la séparation et le regroupement seuls ne sont pas des options satisfaisantes. Cela nous amène aux modèles mixtes! Les MLMs sont un compromis entre séparer et regrouper. Ils: Prennent en compte la variabilité spécifique à chaque espèce et chaque lac (séparer) tout en calculant moins de paramètres qu’une régression classique. Utilisent toutes les données disponibles (regrouper) tout en contrôlant les différences entre les lacs et les espèces (pseudo-replication). Ce faisant, ils: permettent d’utiliser toutes les données disponibles au lieu d’utiliser les moyennes d’un échantillon non indépendant; tiennent compte de la structure des données (par exemple, des quadrats imbriqués dans des sites imbriqués dans des forêts) ; permettent aux relations de varier en fonction de différents facteurs de regroupement (également appelés effets aléatoires) ; nécessitent moins d’estimations de paramètres que la régression classique, ce qui vous fait gagner des degrés de liberté. Mais comment font-ils tout cela? Entrons dans le vif du sujet! "],["effets-fixes-vs-effets-aléatoires.html", "Chapitre 6 Effets fixes vs effets aléatoires 6.1 Effet fixe: processus déterministes 6.2 Effet aléatoire: processus stochastiques", " Chapitre 6 Effets fixes vs effets aléatoires Il y a un débat dans la littérature sur la définition des effets fixes et aléatoires. Il existe plusieurs définitions possibles des effets fixes et aléatoires et nous vous présenterons ici celles que nous trouvons plus faciles à appliquer. 6.1 Effet fixe: processus déterministes Quand une variable a un effet fixe, les données proviennent: de tous les niveaux possibles d’un facteur (variable qualitative) d’un prédicteur (variable quantitative) On souhaite émettre des conclusions à propos des niveaux du facteur ou de la relation entre le prédicteur et la variable réponse. Exemple d’un effet fixe: comparer la concentration de mercure dans les poissons de trois habitats différents. L’habitat est un effet fixe (les trois ont été échantillonnés) et nous sommes intéressés à tirer des conclusions sur les effets de ces trois habitats spécifiques. 6.2 Effet aléatoire: processus stochastiques Les variables avec un effet aléatoire sont également appelées facteurs aléatoires, car il s’agit uniquement de variables qualitatives (catégoriques, non continues). Un effet aléatoire est observé lorsque les données ne comprennent qu’un échantillon aléatoire des nombreux niveaux possibles du facteur, qui présentent tous un intérêt. Il s’agit généralement de facteurs de regroupement dont vous souhaitez contrôler l’effet dans votre modèle, mais dont l’effet spécifique sur la variable de réponse ne vous intéresse pas. Ils nous permettent donc de structurer le processus d’erreur. Exemple d’un effet aléatoire: une étude de la contamination du mercure dans les poissons de lacs de cratères ougandais. Pour des raisons logistiques, vous ne pouvez pas échantillonner tous les lacs de cratères, donc vous échantillonnez seulement huit d’entre eux. Cependant, les poissons d’un lac donné pourrait avoir une sorte de corrélation entre eux (pseudo-corrélation), car ils sont soumis aux mêmes conditions environnementales. Même si vous n’êtes pas intéressé par l’effet de chaque lac spécifiquement, vous devez tenir compte de cette corrélation potentielle avec un facteur aléatoire (lac de cratère) afin de tirer des conclusions sur les lacs de cratères en général. "],["comment-fonctionnent-les-mlms.html", "Chapitre 7 Comment fonctionnent les MLMs? 7.1 Les paramètres peuvent varier 7.2 Tenir compte de la structure des données 7.3 Défi 2", " Chapitre 7 Comment fonctionnent les MLMs? 7.1 Les paramètres peuvent varier Dans les modèles linéaires mixtes, les ordonnées à l’origine et/ou les pentes peuvent varier en fonction d’un facteur donné (effet aléatoire ; par exemple, par lac et/ou par espèce). Permettre aux ordonnées à l’origine et/ou pentes de varier selon certains facteurs (effets aléatoires) signifie simplement que vous supposez qu’ils proviennent d’une distribution normale. La moyenne et l’écart-type de cette distribution sont évalués en fonction de vos données. Les ordonnées à l’origine et pentes les plus probables de cette distribution sont ensuite ajustées par optimisation (ex. maximum de vraisemblance ou maximum de vraisemblance restreint). Ordonnée à l’origine: Si nous considérons d’abord l’espèce comme un effet aléatoire, nous pouvons estimer une moyenne et un écart-type pour la distribution combinée des ordonnées à l’origine des espèces plutôt que des ordonnées à l’origine séparées pour chaque espèce. La moyenne de cette distribution est le “modèle au niveau de l’espèce”. Dans cet exemple, nous n’avons que trois espèces. En général, plus vous avez de niveaux pour un facteur donné, plus les paramètres de la distribution peuvent être estimés avec précision (trois peut être un peu faible pour l’estimation d’une moyenne et d’un écart type, mais cela permet d’obtenir des graphiques plus simples !) Notez que lorsque vous implémentez des LMM dans R, l’intercept dans le résumé est l’intercept du niveau de l’espèce (c’est-à-dire la moyenne de tous les ordonnées à l’origine aléatoires). De même, si nous considérons le lac comme un effet aléatoire, seules la moyenne et la déviation standard de l’ordonnée à l’origine combinée du lac sont estimées. Cela vous évite d’avoir à estimer 6 paramètres différents de l’ordonnée à l’origine du lac, ce qui vous permet de gagner des degrés de liberté puisque moins d’estimations de paramètres sont nécessaires compte tenu de la quantité de données. Pentes Le même concept est utilisé pour faire varier la pente d’un facteur donné (effet aléatoire). Ceci est un peu plus difficile à visualiser que les ordonnées à l’origine. Comme dans le cas des espèces, la moyenne et l’écart type des paramètres de pente sont estimés au lieu de trois pentes distinctes. Notez que lorsque vous implémentez les LMM dans R, la pente dans le résumé est la pente au niveau de l’espèce. 7.2 Tenir compte de la structure des données Dans les modèles mixtes linéaires, les ordonnées à l’origine, pentes, et intervalles de confiance associés sont ajustés pour tenir compte de la structure des données. Qu’arrive-t-il si j’ai peu d’échantillons (faible \\(n\\)) pour un niveau des facteurs? (Par exemple, si on a un faible \\(n\\) pour une espèce…) Si une espèce ou un lac est peu représenté dans les données, le modèle va accorder plus d’importance au modèle groupé pour estimer l’ordonnée à l’origine et la pente de cette espèce ou de ce lac (Processus de « shrinkage »). Nous avons un design équilibré ici, donc ce n’est pas le cas dans notre exemple. Idéalement, on devrait toujours avoir un minimum de \\(n\\) = 3 par niveau d’un facteur. Comment évaluer l’impact d’un effet aléatoire sur le modèle? Les intervalles de confiance des ordonnées à l’origine et des pentes générales sont ajustés pour tenir compte de la pseudo-replication basée sur le coefficient de corrélation intra-classe (CCI). Le CCI correspond au ratio entre la variance d’un effet aléatoire (e.g. ordonnées à l’origine des espèces) et la variance totale. Ainsi, l’ICC décrit la proportion de la variance de la variable de réponse qui est attribuée à un effet aléatoire spécifique: \\[CCI = \\frac{\\sigma_{\\alpha}^2}{\\sigma_{\\alpha}^2 + \\sigma_{\\varepsilon}^2}\\] Notez: La notation mathématique spécifique peut varier selon l’article/livre et selon la façon dont l’équation du modèle a été écrite. Dans notre exemple, le CCI nous informe donc à quel point la position trophique moyenne entre chaque espèce ou chaque lac (c’est-à-dire les ordonnées à l’origine) varie. CCI élevé Le ratio de variance (CCI) est élevé puisque les espèces diffèrent grandement dans leur position trophique moyenne. Les intervalles de confiance pour la pente et l’ordonnée à l’origine générale sont donc grandes. CCI faible Le ratio de variance (CCI) est faible car les espèces diffèrent faiblement dans leur position trophique moyenne. Les intervalles de confiance pour la pente et l’ordonnée à l’origine générale sont donc petits. Pour plus de détails sur le CCI: Nakagawa et Schielzeth (2013) Nakagawa et al. (2017) 7.3 Défi 2 Pour votre deuxième défi, réfléchissez à ces deux questions. Comment le CCI et les intervalles de confiance seront-ils affectés dans ces deux scénarios: 1. Si les positions trophiques des poissons ne varient pas entre les lacs? 2. Si les positions trophiques des poissons sont similaires dans chaque lac, mais différentes entre les lacs? Défi 2 Solution: 1. CCI serait faible et les intervalles de confiance seraient plus petits 2. CCI serait élevé et les intervalles de confiance seraient plus larges "],["le-protocole-pour-implémenter-des-modèles-à-effets-mixtes-dans-r.html", "Chapitre 8 Le protocole pour implémenter des modèles à effets mixtes dans R", " Chapitre 8 Le protocole pour implémenter des modèles à effets mixtes dans R Étape 1. Construction du modèle a priori et exploration des données Étape 2. Coder les modèles potentiels et faire la sélection du meilleur modèle Étape 3. Validation du modèle choisi Étape 4. Interprétation et visualisation des résultats "],["étape-1-construction-du-modèle-a-priori.html", "Chapitre 9 Étape 1. Construction du modèle a priori 9.1 Exploration des données 9.2 Vérifier la colinéarité 9.3 Défi 3 9.4 Considérez l’échelle 9.5 Avez-vous besoin d’un MLM?", " Chapitre 9 Étape 1. Construction du modèle a priori Modèle basé sur connaissance a priori: Nous voulons déterminer si la position trophique peut être prédite par la longueur corporelle, tout en prenant en compte la variation entre les espèces et les lacs. Donc nous voulons un modèle qui ressemble à ceci: \\[PT_{ijk} \\sim Longueur_i + Lac_j + Espèce_k + \\epsilon_{ijk}\\] où: \\(PT_{ijk}\\) est la position trophique du poisson (\\(i\\)) du lac (\\(j\\)) et de l’espèce (\\(k\\)) \\(\\varepsilon\\) sont les résidus du modèle (c’est-à-dire la variation inexpliquée). 9.1 Exploration des données Les données ont-elles la bonne structure? Vérifiez la structure des données : # Vérifiez la structure des données str(fish.data) ## &#39;data.frame&#39;: 180 obs. of 4 variables: ## $ Lake : Factor w/ 6 levels &quot;L1&quot;,&quot;L2&quot;,&quot;L3&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... ## $ Fish_Species: Factor w/ 3 levels &quot;S1&quot;,&quot;S2&quot;,&quot;S3&quot;: 1 1 1 1 1 1 1 1 1 1 ... ## $ Fish_Length : num 105 195 294 414 237 ... ## $ Trophic_Pos : num 2.6 2.7 2.74 2.74 2.79 ... Observez maintenant la distribution des échantillons pour chaque facteur: # Observez la distribution des échantillons pour chaque # facteur: table(fish.data[, c(&quot;Lake&quot;, &quot;Fish_Species&quot;)]) ## Fish_Species ## Lake S1 S2 S3 ## L1 10 10 10 ## L2 10 10 10 ## L3 10 10 10 ## L4 10 10 10 ## L5 10 10 10 ## L6 10 10 10 Ce jeu de données est parfaitement équilibré, mais les modèles mixtes peuvent analyser des designs expérimentaux non équilibrés, comme c’est souvent le cas en écologie! Regardez ensuite la distribution des variables continues: # Regardez la distribution des variables continues. hist(fish.data$Fish_Length, xlab = &quot;Length (mm)&quot;, main = &quot;&quot;) hist(fish.data$Trophic_Pos, xlab = &quot;Trophic position&quot;, main = &quot;&quot;) Des déviations majeures pourraient causer des problèmes d’hétéroscédasticité. Si nécessaire, faites des transformations. Dans ce cas-ci, les données semblent correctes. 9.2 Vérifier la colinéarité Vérifier la colinéarité entre vos variables explicatives Le problème avec les prédicteurs colinéaires est simplement qu’ils expliquent la même chose, alors leur effet sur la variable réponse sera confondu dans le modèle. Par défaut, le modèle attribuera beaucoup de pouvoir explicatif à la première variable du modèle et peu de pouvoir aux variables qui suivent. Dans cet exemple, il n’y a pas de risque de colinéarité avec seulement une variable continue. Si vous aviez une autre variable continue (Var2), une façon simple de vérifier la colinéarité est cor(var1, var2) Voici un exemple de colinéarité. 9.3 Défi 3 C’est un problème de réflexion! Quelles mesures supplémentaires aurions-nous pu prendre sur le terrain qui auraient pu être fortement corrélées avec la longueur corporelle? Défi 3 Solution: Il y a plusieurs réponses possibles ici. Un exemple est la masse du poisson – c’est une variable fortement corrélée avec la longueur du poisson. Par conséquent, nous ne voulons pas inclure ces deux variables dans le même modèle. 9.4 Considérez l’échelle Considérez l’échelle de vos données Si deux variables dans un même modèle ont des échelles très différentes, il est probable que le modèle indique un problème de convergence en essayant de calculer les paramètres. La correction Z standardise les variables et résout ce problème (fonction scale() dans R) : \\[z = \\frac{x-moyenne(x)}{écart.type(x)}\\] Considérez l’échelle des variables dans notre ensemble de données. La longueur corporelle est mesurée sur une longue échelle, tandis que la position trophique est mesurée sur une échelle qui est beaucoup plus courte. Parce que nos données ont des échelles très différentes, on applique la correction Z # Longueur corrigée, &#39;à la main&#39; fish.data$Z_Length &lt;- (fish.data$Fish_Length - mean(fish.data$Fish_Length))/sd(fish.data$Fish_Length) # Position trophique corrigée, avec la fonction scale fish.data$Z_TP &lt;- scale(fish.data$Trophic_Pos) 9.5 Avez-vous besoin d’un MLM? Déterminez si vous avez besoin d’un modèle mixte. Pour savoir si un modèle mixte est nécessaire pour vos données, vous devez déterminer s’il est important de prendre en compte l’effet aléatoire de facteurs qui pourraient influencer la relation qui vous intéresse (dans notre cas, lac et espèce). Nous pouvons le faire en: Créant un modèle linéaire sans les facteurs qui pourraient avoir un effet aléatoire Calculant les résidus de ce modèle linéaire Produisant un graphique de la valeur des résidus en fonction des niveaux des facteurs potentiellement aléatoires Créer un modèle linéaire sans les facteurs lm.test &lt;- lm(Z_TP ~ Z_Length, data = fish.data) Calculer les résidus de ce modèle linéaire lm.test.resid &lt;- rstandard(lm.test) Représentez graphiquement la valeur des résidus en fonction des niveaux des facteurs plot(lm.test.resid ~ as.factor(fish.data$Fish_Species), xlab = &quot;Species&quot;, ylab = &quot;Standardized residuals&quot;) abline(0, 0, lty = 2) plot(lm.test.resid ~ as.factor(fish.data$Lake), xlab = &quot;Lake&quot;, ylab = &quot;Standardized residuals&quot;) abline(0, 0, lty = 2) Les résidues semblent varier de façon non-aléatoire entre les espèces et entre les lacs. Ces patrons suggèrent qu’il y a de la variance résiduelle qui pourrait être expliquée par ces facteurs, et ils devraient donc être inclus dans le modèle! "],["étape-2-coder-le-modèle.html", "Chapitre 10 Étape 2. Coder le modèle 10.1 Note sur les méthodes d’estimation 10.2 Différentes structures de modèles 10.3 Défi 4 10.4 Défi 5 10.5 Comparing models", " Chapitre 10 Étape 2. Coder le modèle Traduisons notre modèle… \\[PT_{ijk} \\sim Longueur_i + Lac_j + Espèce_k + \\varepsilon_{ijk}\\] … en code R lmer(Z_TP ~ Z_Length + (1 | Lake) + (1 | Fish_Species), data = fish.data, REML = TRUE) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: Z_TP ~ Z_Length + (1 | Lake) + (1 | Fish_Species) ## Data: fish.data ## REML criterion at convergence: 72.4662 ## Random effects: ## Groups Name Std.Dev. ## Lake (Intercept) 0.4516 ## Fish_Species (Intercept) 0.9301 ## Residual 0.2605 ## Number of obs: 180, groups: Lake, 6; Fish_Species, 3 ## Fixed Effects: ## (Intercept) Z_Length ## 9.752e-14 4.198e-01 Où: lmer() est la fonction “linear mixed model” du package lme4 (1 | Lake) indique que les ordonnées à l’origine peuvent varier entre les lacs REML = TRUE spécifie la méthode d’estimation 10.1 Note sur les méthodes d’estimation REML (Restricted Maximum Likelihood) est la méthode par défaut dans la fonction lmer (voir ?lmer). La méthode de maximum de vraisemblance (ML, pour Maximum Likelihood) sous-estime les variances du modèle par un facteur \\((n-k) / n\\), ou \\(k\\) est le nombre d’effes fixes. Les estimations REML peuvent être utilisées lorsque vous comparez des modèles ayant les mêmes effets fixes (c’est-à-dire des modèles imbriqués). Cependant, si vous comparez des modèles où les effets fixes diffèrent d’un modèle à l’autre, il est préférable d’utiliser le maximum de vraisemblance pour ajuster les paramètres car cette méthode ne dépend pas des coefficients des effets fixes. L’ajustement en utilisant le maximum de vraisemblance est fait en mettant REML=FALSE dans la commande lmer. Consultez cet article pour plus d’information sur la différence entre ML et REML. En résumé: REML pour comparer des modèles avec des effets aléatoires nichés et la même structure d’effets fixes ML pour comparer des modèles avec des effets fixes nichés et la même structure d’effets aléatoires ML pour comparer des modèles avec et sans effets aléatoires 10.2 Différentes structures de modèles Comment faire si on souhaite que la pente puisse varier? Il y a différentes structures possibles pour le modèle: (1 | Lake) effet aléatoire par lac à l’ordonnée à l’origine (1 + Z_Length | Lake) effet aléatoire par lac à l’ordonnée à l’origine et la pente en réponse à la longueur corporelle (NB: (Z_Length | Lake) donne le même résultat) (-1 + Z_Length | Lake) pour avoir uniquement l’effet aléatoire sur la pente (1 | Lake) + (1 | Species) pour des effets aléatoires croisés (1 | Lake:Fish_Species) pour utiliser l’interaction entre 2 facteurs groupant Si votre jeu de données inclus des effets nichés, vous pouvez utiliser / pour les déclarer, e.g. (1 | facteur1 / facteur2) si facteur2 est niché dans facteur1 (voir stack-exchange) 10.3 Défi 4 Réécrivez le code suivant de façon à ce que les pentes de la relation position trophique en fonction de longueur corporelle varient par lac et par espèces: # Défi 4: Réécrivez le code suivant de façon à ce que les # **pentes** de la relation position trophique en fonction # de longueur corporelle **varient par lac et par # espèces**: lmer(Z_TP ~ Z_Length + (1 | Lake) + (1 | Fish_Species), data = fish.data, REML = TRUE) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: Z_TP ~ Z_Length + (1 | Lake) + (1 | Fish_Species) ## Data: fish.data ## REML criterion at convergence: 72.4662 ## Random effects: ## Groups Name Std.Dev. ## Lake (Intercept) 0.4516 ## Fish_Species (Intercept) 0.9301 ## Residual 0.2605 ## Number of obs: 180, groups: Lake, 6; Fish_Species, 3 ## Fixed Effects: ## (Intercept) Z_Length ## 9.752e-14 4.198e-01 Défi 4 Solution: # Défi 4 Solution: lmer(Z_TP ~ Z_Length + (1 + Z_Length | Lake) + (1 + Z_Length | Fish_Species), data = fish.data, REML = TRUE) ## boundary (singular) fit: see ?isSingular ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: ## Z_TP ~ Z_Length + (1 + Z_Length | Lake) + (1 + Z_Length | Fish_Species) ## Data: fish.data ## REML criterion at convergence: 20.5786 ## Random effects: ## Groups Name Std.Dev. Corr ## Lake (Intercept) 0.45279 ## Z_Length 0.02378 -0.82 ## Fish_Species (Intercept) 0.93103 ## Z_Length 0.15728 1.00 ## Residual 0.22341 ## Number of obs: 180, groups: Lake, 6; Fish_Species, 3 ## Fixed Effects: ## (Intercept) Z_Length ## -0.0009025 0.4223738 ## optimizer (nloptwrap) convergence code: 0 (OK) ; 0 optimizer warnings; 1 lme4 warnings 10.4 Défi 5 Pour déterminer si vous avez construit le meilleur modèle mixte sur la base de vos connaissances préalables, vous devez comparer ce modèle a priori à d’autres modèles alternatifs. Avec l’ensemble de données sur lequel vous travaillez, il existe plusieurs modèles alternatifs qui pourraient mieux s’adapter à vos données. Pour le défi 5, faites une liste de 7 modèles alternatifs qui pourraient être comparés à celui-ci: # Défi 5 : Faites une liste de 7 modèles alternatifs qui # pourraient être comparés à ce modèle initial: lmer(Z_TP ~ Z_Length + (1 | Lake) + (1 | Fish_Species), data = fish.data, REML = TRUE) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: Z_TP ~ Z_Length + (1 | Lake) + (1 | Fish_Species) ## Data: fish.data ## REML criterion at convergence: 72.4662 ## Random effects: ## Groups Name Std.Dev. ## Lake (Intercept) 0.4516 ## Fish_Species (Intercept) 0.9301 ## Residual 0.2605 ## Number of obs: 180, groups: Lake, 6; Fish_Species, 3 ## Fixed Effects: ## (Intercept) Z_Length ## 9.752e-14 4.198e-01 Notez: Si nous avions différents effets fixes entre les modèles ou un modèle sans effects aléatoires, nous aurions dû indiquer REML = FALSE pour les comparer avec une méthode de vraisemblance comme l’AIC. Défi 5 Solution: Nous allons aussi construire le modèle linéaire de base lm() parce qu’il est toujours utile de voir la variation dans les valeurs de AICc. # Solution du défi 5: Modèle linéaire de base M0 &lt;- lm(Z_TP ~ Z_Length, data = fish.data) A fin de comparer ce modèle aux LMMs, il est important de changer la méthode d’estimation en ML (REML=FALSE) pour tous les autres modèles car lm() n’utilise pas la même méthode d’estimation que lmer(). Examinons les autres modèles que vous auriez pu écrire (notez REML = FALSE): # Solution du défi 5, autres modèles potentiels Notez que # REML = FALSE afin de comparer avec le modèle linéaire de # base où la méthode d&#39;estimation = ML. # Modele linéaire de base M0 &lt;- lm(Z_TP ~ Z_Length, data = fish.data) # modèle complet avec variation des ordonnées à l&#39;origine M1 &lt;- lmer(Z_TP ~ Z_Length + (1 | Fish_Species) + (1 | Lake), data = fish.data, REML = FALSE) # modèle complet avec variation des ordonnées à l&#39;origine # et de pentes M2 &lt;- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Fish_Species) + (1 + Z_Length | Lake), data = fish.data, REML = FALSE) ## boundary (singular) fit: see ?isSingular # Pas d&#39;effet lac, les ordonnées à l&#39;origine varient par # espèces M3 &lt;- lmer(Z_TP ~ Z_Length + (1 | Fish_Species), data = fish.data, REML = FALSE) # Pas d&#39;effet espèces, les ordonnées à l&#39;origine varient # par lac M4 &lt;- lmer(Z_TP ~ Z_Length + (1 | Lake), data = fish.data, REML = FALSE) # Pas d&#39;effet de lac, les ordonnées à l&#39;origine et les # pentes varient par espèces M5 &lt;- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Fish_Species), data = fish.data, REML = FALSE) ## boundary (singular) fit: see ?isSingular # Pas d&#39;effet de l&#39;espèces, les ordonnées à l&#39;origine et # les pentes varient par lac M6 &lt;- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Lake), data = fish.data, REML = FALSE) ## boundary (singular) fit: see ?isSingular # modèle complet, variation d&#39;ordonnée à l&#39;origine et pente # par lac M7 &lt;- lmer(Z_TP ~ Z_Length + (1 | Fish_Species) + (1 + Z_Length | Lake), data = fish.data, REML = FALSE) ## boundary (singular) fit: see ?isSingular # modèle complet, variation d&#39;ordonnée à l&#39;origine et pente # par espèces M8 &lt;- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Fish_Species) + (1 | Lake), data = fish.data, REML = FALSE) ## boundary (singular) fit: see ?isSingular Lorsqu’on ajuste des MLM avec lmer(), il est possible de faire face à certaines erreurs our avertissements comme: boundary (singular) fit: see ?isSingular, voir cette discussion Model failed to converge with max|grad| ..., voir cette discussion Voici une liste de problèmes possibles et comment les résoudre. 10.5 Comparing models Maintenant que nous avons une liste de modèles potentiels, nous voulons les comparer entre eux pour sélectionner celui(ceux) qui a(ont) le plus de pouvoir prédictif. Les modèles peuvent être comparés en utilisant la fonction AICc provenant du package MuMIn. Le critère d’information Akaike (AIC) est une mesure de qualité du modèle pouvant être utilisée pour comparer les modèles. AICc corrige pour le biais créé par les faibles tailles d’échantillon. Pour trouver la valeur AICc d’un modèle, utilisez: # Trouver la valeur AICc pour notre premier modèle (Modèle # linéaire de base) avec le paquet MuMIn MuMIn::AICc(M1) ## [1] 77.30499 Pour regrouper toutes les valeurs de l’AICc dans un seul tableau, utilisez MuMIn::model.sel() pour calculer l’AICc pour chaque modèle (avec d’autres sorties) et ensuite sélectionnez seulement les colonnes d’intérêt pour les imprimer dans un tableau. # Pour regrouper toutes les valeurs de l&#39;AICc dans un seul # tableau, utilisez `MuMIn::model.sel()` pour calculer # l&#39;AICc pour chaque modèle (avec d&#39;autres sorties) et # ensuite sélectionnez seulement les colonnes d&#39;intérêt # pour les imprimer dans un tableau. AIC.table &lt;- MuMIn::model.sel(M0, M1, M2, M3, M4, M5, M6, M7, M8) # `df` est le degré de liberté `logLik` est le log de la # vraisemblance `delta` est la différence d&#39;AICc avec la # valeur la plus petite (AIC.table &lt;- AIC.table[, c(&quot;df&quot;, &quot;logLik&quot;, &quot;AICc&quot;, &quot;delta&quot;)]) ## df logLik AICc delta ## M8 7 -8.597929 31.84702 0.000000 ## M2 9 -8.216019 35.49086 3.643839 ## M1 5 -33.480080 77.30499 45.457965 ## M7 7 -33.186374 81.02391 49.176890 ## M5 6 -128.310995 269.10754 237.260517 ## M3 4 -134.532965 277.29450 245.447480 ## M4 4 -224.715763 457.66010 425.813076 ## M6 6 -224.671201 461.82795 429.980930 ## M0 3 -236.861362 479.85909 448.012065 # Pour plus d&#39;informations sur les autres sorties ou # résultats de la fonction model.sel(), roulez # `?model.sel`. Où: df montre les degrés de liberté logLik est le log de la vraisemblance delta est la différence d’AICc avec la valeur la plus petite Nous avons seulement affiché une partie des résultats retourné par la fonction model.sel(), voir ?model.sel pour plus d’informations. Que signifient ces valeurs d’AICc? Le modèle avec le plus petit AICc a le plus grand pouvoir prédictif. Souvent on considère que deux modèles à +/- 2 unités d’AICc de différence ont un pouvoir prédictif équivalent. Examinons de plus proche M8 and M2. On peut exclure les autres modèles, car ils ont des AICc beaucoup plus élevés. Notez qu’on utilise maintenant REML (i.e. REML=TRUE) puisqu’on compare deux modèles avec des effets aléatoires nichés et avec la même structure d’effets fixes. # Examinons de plus proche M8 and M2 (les autres modèlesont # des AICc beaucoup plus élevés) `REML = TRUE` parce qu&#39;on # compare deux modèles avec des effets aléatoires nichés et # avec la même structure d&#39;effets fixes M8 &lt;- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Fish_Species) + (1 | Lake), data = fish.data, REML = TRUE) ## boundary (singular) fit: see ?isSingular M2 &lt;- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Fish_Species) + (1 + Z_Length | Lake), data = fish.data, REML = TRUE) ## boundary (singular) fit: see ?isSingular # Sortonz un tableau pour comparer M2 et M8 MuMIn::model.sel(M2, M8)[, c(&quot;df&quot;, &quot;logLik&quot;, &quot;AICc&quot;, &quot;delta&quot;)] ## df logLik AICc delta ## M8 7 -10.84011 36.33137 0.000000 ## M2 9 -10.28932 39.63747 3.306098 Le modèle M8 semble être le meilleur modèle parmi ceux qu’on a testé! Quelle est la structure du meilleur modèle? # Regardons à nouveau le meilleur modèle, quelle est sa # structure? M8 &lt;- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Fish_Species) + (1 | Lake), data = fish.data, REML = FALSE) ## boundary (singular) fit: see ?isSingular # L&#39;ordonnée à l&#39;origine et l&#39;effet de la longueur sur la # position trophique peut varier selon l&#39;espèce de # poissons, mais seulement l&#39;ordonnée à l&#39;origine peut # varier par lac L’ordonnée à l’origine et l’effet de la longueur sur la position trophique peut varier selon l’espèce de poissons, mais seulement l’ordonnée à l’origine peut varier par lac. Une fois que le meilleur modèle est sélectionné, il faut remettre la méthode d’estimation a REML = TRUE. # Une fois que le meilleur modèle est sélectionné il faut # remettre la méthode d&#39;estimation a `REML = TRUE` M8 &lt;- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Fish_Species) + (1 | Lake), data = fish.data, REML = TRUE) ## boundary (singular) fit: see ?isSingular "],["step-3-validation-du-modèle.html", "Chapitre 11 Step 3. Validation du modèle 11.1 1. Vérifier l’homogénéité de la variance 11.2 2. Vérifier l’indépendance des résidus 11.3 3. Vérifier la normalité", " Chapitre 11 Step 3. Validation du modèle Maintenant qu’on a trouvé notre modèle, on doit vérifier que le modèle respecte toutes les suppositions de base. Il faut donc: 1. Vérifier l’homogénéité de la variance: Faire un graphique des valeurs prédites en fonction des valeurs résiduelles 2. Vérifier l’indépendance des résidus: Graphique des résidus vs chaque covariable du modèle Graphique des résidus vs chaque covariable non incluse du modèle 3. Vérifier la normalité: Histogramme des résidus 11.1 1. Vérifier l’homogénéité de la variance Afin de vérifier l’homogénéité de la variance, nous pouvons tracer les valeurs prédites par rapport aux valeurs résiduelles. Une dispersion homogène des résidus signifie que l’hypothèse est respectée. Maintenant, regardons nos données, la dispersion est-elle homogène ? # Plotez les valeurs prédites par rapport aux valeurs # résiduelles par(mar = c(4, 4, 0.5, 0.5)) plot(resid(M8) ~ fitted(M8), xlab = &quot;Predicted values&quot;, ylab = &quot;Normalized residuals&quot;) abline(h = 0, lty = 2) # La dispersion homogène des résidus signifie que # l&#39;hypothèse est respectée. Oui! La dispersion homogène des résidus signifie que l’hypothèse est respectée. 11.2 2. Vérifier l’indépendance des résidus Afin de vérifier l’indépendance des résidus du modèle par rapport à chaque covariable, nous allons (1) tracer les résidus par rapport à chaque covariable du modèle et (2) tracer les résidus par rapport à chaque covariable non incluse dans le modèle. Commençons par (1) tracer les résidus par rapport à chaque covariable du modèle. # Afin de vérifier l&#39;indépendance des résidus du modèle, # nous devons tracer les résidus en fonction de chaque # covariable du modèle. par(mfrow = c(1, 3), mar = c(4, 4, 0.5, 0.5)) plot(resid(M8) ~ fish.data$Z_Length, xlab = &quot;Length&quot;, ylab = &quot;Normalized residuals&quot;) abline(h = 0, lty = 2) boxplot(resid(M8) ~ Fish_Species, data = fish.data, xlab = &quot;Species&quot;, ylab = &quot;Normalized residuals&quot;) abline(h = 0, lty = 2) boxplot(resid(M8) ~ Lake, data = fish.data, xlab = &quot;Lakes&quot;, ylab = &quot;Normalized residuals&quot;) abline(h = 0, lty = 2) # La dispersion homogène des résidus autour de 0 signifie # qu&#39;il n&#39;y a pas de modèle de résidus en fonction de la # variable, donc l&#39;hypothèse est respectée ! Note : Les # groupes sont dus à la structure des données, où les # poissons de seulement 5 classes de taille (grande, # petite, et trois groupes intermédiaires) ont été # capturés. La dispersion homogène des résidus autour de 0 signifie qu’il n’y a pas de modèle de résidus en fonction de la variable, donc l’hypothèse est respectée! *Remarque : les groupes sont dus à la structure des données, où les poissons de seulement 5 classes de taille (grande, petite, et trois groupes intermédiaires) ont été capturés. Maintenant, nous devons (2) tracer les résidus par rapport à chaque covariable non incluse dans le modèle. Si vous observez des tendances dans ces graphiques, vous saurez qu’il existe une variation dans votre ensemble de données qui pourrait être expliquée par ces covariables et vous devriez envisager de les inclure dans votre modèle. Cependant, comme nous avons inclus toutes les variables mesurées dans notre modèle, nous ne pouvons pas effectuer cette étape avec nos données. 11.3 3. Vérifier la normalité Nous allons maintenant vérifier la normalité des résidus du modèle, car des résidus suivant une distribution normale indiquent que le modèle n’est pas biaisé. # Vérifiez la normalité des résidus du modèle car des # résidus suivant une distribution normale indiquent que le # modèle n&#39;est pas biaisé. hist(resid(M8)) # Les résidus sont normaux ! Cela signifie que notre modèle # n&#39;est pas biaisé. Les résidus sont normaux ! Cela signifie que notre modèle n’est pas biaisé. "],["step-4-interprétation-et-visualisation.html", "Chapitre 12 Step 4. Interprétation et visualisation 12.1 Interprétation de notre modèle 12.2 Défi 6 12.3 Défi 7 12.4 Défi 8", " Chapitre 12 Step 4. Interprétation et visualisation 12.1 Interprétation de notre modèle Regardons de plus près notre modèle final en utilisant la fonction summary(). Comment pouvons-nous interpréter ces informations? # Maintenant nous sommes prêts pour l&#39;interprétation et la # visualisation. Regardons de plus près notre modèle final # en utilisant la fonction `summary()`. (summ_M8 &lt;- summary(M8)) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: Z_TP ~ Z_Length + (1 + Z_Length | Fish_Species) + (1 | Lake) ## Data: fish.data ## ## REML criterion at convergence: 21.7 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.77187 -0.60166 0.05589 0.64239 2.27776 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## Lake (Intercept) 0.20504 0.4528 ## Fish_Species (Intercept) 0.86715 0.9312 ## Z_Length 0.02466 0.1570 1.00 ## Residual 0.05039 0.2245 ## Number of obs: 180, groups: Lake, 6; Fish_Species, 3 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) -0.0009059 0.5687733 -0.002 ## Z_Length 0.4222697 0.0922117 4.579 ## ## Correlation of Fixed Effects: ## (Intr) ## Z_Length 0.929 ## optimizer (nloptwrap) convergence code: 0 (OK) ## boundary (singular) fit: see ?isSingular Allons-y section par section et essayons de comprendre ce que nous regardons. La sortie est divisée en descriptions des effets aléatoires (ce qui peut varier en fonction de la distribution normale) et les effets fixes (ce que nous estimons comme pour une régression classique) : Effets aléatoires: Groups: facteurs de regroupement Name: (Intercept) pour l’ordonnée à l’origine, ou le nom de la variable sur lequel porte l’effet mixe dans le cas d’une pente aléatoire, (Z_length dans notre exemple) Variance la variance estimée de l’effet (Std.Dev. est l’écart type de cette valeur) Corr indique la corrélation entre la pente aléatoire et l’ordonnée à l’origine aléatoire pour un groupement donné (voir cette discussion) Effets fixes: Cette partie présente l’estimation des effets fixes. Une valeur de la statistique T (test de Student) est retournée sans valeur de p (c’est un choix des auteurs du package, voir pourquoi dans cette discussion). Cette statistique peut être utilisée telle quelle. Vous pouvez aussi calculer l’intervalle de confiance (IC) à 95% avec cette table en utilisant: \\[ IC = Estimate \\pm 1.96*Std.Error \\] Si 0 est dans cet interval, alors le paramètre n’est pas significativement différente de zéro au seuil \\(\\alpha\\) = 0.05. En utilisant notre exemple: Pour déterminer si la pente, et donc l’effet de la longueur sur la position trophique, est significativement différente de zéro, vous devez d’abord calculer l’intervalle de confiance (IC) du paramètre de la pente (estimation pour Z_Length dans la section des effets fixes = 0,4223). CI = l’erreur-type de l’estimation x 1,96 plus ou moins l’estimation du paramètre. Si l’IC inclut zéro, la pente n’est pas significativement différente de zéro au seuil de 0,05. Quelques fonctions utiles coef(M8) et ranef(M8) retournent les effets aléatoires du modèle M8 coef(summary(M8)) retourne les effets fixes sigma(M8) retourne l’écart type des résidus fitted(M8) retourne les valeurs prédites par le modèle residuals(M8) retourne les résidus 12.2 Défi 6 1. Quelle est la pente et son intervalle de confiance de la variable Z_Length dans le modèle M8? 2. Est-ce que la pente de Z_Length est significativement différente de 0 ? Défi 6 Solution: 1. Quelle est la pente et son intervalle de confiance de la variable Z_Length dans le modèle M8? pente = 0.422; limite supérieure de l’IC = 0.4223 + 0.09*1.96 = 0.5987 limite inférieure de l’IC = 0.4223 - 0.09*1.96 = 0.2459 2. Est-ce que la pente de Z_Length est significativement différente de 0 ? Oui, car l’IC [0.2459, 0.5987] n’inclut pas 0 12.3 Défi 7 Il est possible de visualiser graphiquement les différentes ordonnées à l’origine et pentes du modèle pour mieux interpréter les résultats? Prenez 2 minutes pour réfléchir aux différentes façons pour représenter les résultats de M8. Indice: considérez les différents “niveaux” du modèle Défi 7 Solution: Il est possible de visualiser graphiquement les différentes ordonnées à l’origine et pentes du modèle pour mieux interpréter les résultats? Oui! Nous pourrions le faire en générant: Figure avec toutes les données regroupées Figure par espèce Figure par lac Pour faire ces figures, il nous faut (1) les coefficients du modèle complet qui sont dans le résumé du modèle, (2) les coefficients pour chaque niveau du modèle qu’on obtient avec la fonction coef. # Défi 7 : *Il est possible de visualiser graphiquement les # différentes ordonnées à l&#39;origine et pentes du modèle # pour mieux interpréter les résultats ? # Solution du défi 7 : Oui ! Nous pourrions le faire en # générant les figures suivantes. a) Figure avec toutes # les données regroupées b) Figure par espèce c) Figure par # lac # Pour produire ces figures, nous avons d&#39;abord besoin des # coefficients du modèle complet qui se trouvent dans le # résumé du modèle. summ_M8$coefficients ## Estimate Std. Error t value ## (Intercept) -0.0009058974 0.56877327 -0.001592722 ## Z_Length 0.4222697238 0.09221166 4.579352788 # Intercept = Intercept = 9.0589745 × 10^4 Slope = # 0.4222697 # Nous avons également besoin des coefficients pour chaque # niveau du modèle, qui peuvent être obtenus avec la # fonction `coef`. coef(M8) ## $Lake ## (Intercept) Z_Length ## L1 -0.085984071 0.4222697 ## L2 0.002205209 0.4222697 ## L3 -0.301816557 0.4222697 ## L4 -0.574039728 0.4222697 ## L5 0.218650140 0.4222697 ## L6 0.735549622 0.4222697 ## ## $Fish_Species ## (Intercept) Z_Length ## S1 -1.0752985 0.2410746 ## S2 0.5597871 0.5168300 ## S3 0.5127938 0.5089046 ## ## attr(,&quot;class&quot;) ## [1] &quot;coef.mer&quot; Maintenant, faisons nos figures! Figure avec toutes les données regroupées # Maintenant, faisons nos figures ! # a) Figure avec toutes les données groupées Créez un thème # ggplot simplifié fig &lt;- theme_bw() + theme(panel.grid.minor = element_blank(), panel.grid.major = element_blank(), panel.background = element_blank()) + theme(strip.background = element_blank(), strip.text.y = element_text()) + theme(legend.background = element_blank()) + theme(legend.key = element_blank()) + theme(panel.border = element_rect(colour = &quot;black&quot;, fill = NA)) plot &lt;- ggplot(aes(Z_Length, Z_TP), data = fish.data) Plot_AllData &lt;- plot + geom_point() + xlab(&quot;Length (mm)&quot;) + ylab(&quot;Trophic position&quot;) + labs(title = &quot;All data&quot;) + fig Plot_AllData + geom_abline(intercept = summ_M8$coefficients[1, 1], slope = summ_M8$coefficients[2, 1]) # Vous pouvez également écrire les chiffres comme ceci : # Plot_AllData + geom_abline(intercept = -0.0009059, slope # = 0.4222697) Figure par espèce # b) Figure par espèce Mettre les coefs dans un tableau # pour les rendre plus faciles à manipuler Lake.coef &lt;- coef(M8)$Lake colnames(Lake.coef) &lt;- c(&quot;Intercept&quot;, &quot;Slope&quot;) Species.coef &lt;- coef(M8)$Fish_Species colnames(Species.coef) &lt;- c(&quot;Intercept&quot;, &quot;Slope&quot;) Plot_BySpecies &lt;- plot + geom_point(aes(colour = factor(Fish_Species)), size = 4) + xlab(&quot;Longueur (mm)&quot;) + ylab(&quot;Position trophique&quot;) + labs(title = &quot;Par espèce&quot;) + fig # Ajoutez les lignes de régression pour chaque espèce Plot_BySpecies + geom_abline(intercept = Species.coef[1, 1], slope = Species.coef[1, 2], col = &quot;coral2&quot;) + geom_abline(intercept = Species.coef[2, 1], slope = Species.coef[2, 2], col = &quot;green4&quot;) + geom_abline(intercept = Species.coef[3, 1], slope = Species.coef[3, 2], col = &quot;blue1&quot;) Figure par lac # c) Figure par lac Plot_ByLake &lt;- plot + geom_point(aes(colour = factor(Lake)), size = 4) + xlab(&quot;Length (mm)&quot;) + ylab(&quot;Trophic Position&quot;) + labs(title = &quot;By Lake&quot;) + fig # Ajouter les lignes de régression avec les ordonnées à # l&#39;origine spécifiques à chaque lac Plot_ByLake + geom_abline(intercept = Lake.coef[1, 1], slope = Lake.coef[1, 2], col = &quot;coral2&quot;) + geom_abline(intercept = Lake.coef[2, 1], slope = Lake.coef[2, 2], col = &quot;khaki4&quot;) + geom_abline(intercept = Lake.coef[3, 1], slope = Lake.coef[3, 2], col = &quot;green4&quot;) + geom_abline(intercept = Lake.coef[4, 1], slope = Lake.coef[4, 2], col = &quot;darkgoldenrod&quot;) + geom_abline(intercept = Lake.coef[5, 1], slope = Lake.coef[5, 2], col = &quot;royalblue1&quot;) + geom_abline(intercept = Lake.coef[6, 1], slope = Lake.coef[6, 2], col = &quot;magenta3&quot;) 12.4 Défi 8 Vérifions nos connaissances en envisageant un autre scénario. Vous avez inventorié la richesse dans 1000 quadrats qui sont dans 10 sites différents qui sont également dans 10 forêts différentes. Vous avez de plus mesuré la productivité dans chaque quadrat. Vous désirez savoir si la productivité est un bon prédicteur de biodiversité. Quel modèle mixte pourriez-vous utiliser pour ce jeu de données? Défi 8 Solution: lmer(Biodiv ~ Productivity + (1 | Forest/Site)) Ici les effets aléatoires sont nichés (i.e. Sites dans forêt) et non croisés. Pourquoi utiliser (1 | Foret / Site) plutôt que (1 | Foret) + (1 | Site) ? Regardez cette réponse! "],["introduction-aux-glmm.html", "Chapitre 13 Introduction aux GLMM", " Chapitre 13 Introduction aux GLMM Les modèles linéaires généralisés mixtes (GLMM) sont une extension des modèles linéaires généralisés (GLM) qui prennent en compte une structure supplémentaire dans l’ensemble des données. Ils suivent des étapes similaires à celles que nous venons de présenter avec les modèles linéaires mixtes (LMM): 1. Ils incorporent les effets aléatoires (comme les LMMs) 2. Permettent de gérer des données non-normales (en laissant les erreurs prendre différentes familles de distribution - e.g Poisson ou binomial négatif) (comme les GLMs; atelier 6) Comme pour la partie LMM de cet atelier, nous allons travailler sur le matériel GLMM avec un ensemble de données afin de mieux comprendre le fonctionnement des GLMMs et comment les implémenter dans R. Dans le jeu de données Arabidopsis, l’effet de la disponibilité des nutriments et de l’herbivorie (effets fixes) sur la production de fruits (variable de réponse) d’Arabidopsis thaliana a été évalué en mesurant 625 plantes dans 9 populations différentes, chacune comprenant 2 à 3 génotypes différents (effets aléatoires). Chargez les données Arabidopsis banta_totalfruits.csv dans R. dat.tf &lt;- read.csv(&quot;data/banta_totalfruits.csv&quot;) # Dans cet ensemble de données, les en-têtes de colonne # sont définis comme suit: popu: facteur avec un niveau # pour chaque population gen: facteur avec un niveau pour # chaque génotype nutrient: facteur avec niveau bas (valeur # = 1) ou haut (valeur = 8) amd: facteur précisant # l&#39;absence ou la présence d&#39;herbivorie total.fruits: # nombre entier indiquant le nombre de fruits par plante "],["choisir-la-distribution-des-erreurs.html", "Chapitre 14 Choisir la distribution des erreurs", " Chapitre 14 Choisir la distribution des erreurs Nous devons maintenant choisir une distribution d’erreurs. Ce choix sera informé par la structure de nos données. La variable réponse constitue des données d’abondance, donc nous devons choisir une distribution de Poisson (i.e variance égale à la moyenne) Jetons-y un coup d’oeil: # Avant d&#39;aller plus loin, nous devons choisir une # distribution d&#39;erreurs. Ce choix sera guidé par la # structure de nos données. Notre variable de réponse est # une donnée de comptage, ce qui suggère que nous avons # besoin d&#39;une distribution de Poisson (c&#39;est-à-dire que la # variance est égale à la moyenne). hist(dat.tf$total.fruits, breaks = 50, col = &quot;blue&quot;, main = &quot;&quot;, xlab = &quot;Total fruits&quot;, ylab = &quot;Count&quot;) Cependant, comme nous le verrons, la variance de chaque groupe augmente beaucoup plus rapidement que prévu… Exploration de la variance Examinons de plus près la variance au sein de nos données. Pour illustrer l’hétérogénéité de la variance, nous allons créer des boxplots du log du nombre total de fruits (variable réponse) par rapport aux différents facteurs environnementaux. Créons d’abord de nouvelles variables qui représentent toutes les combinaisons de nutriments x herbivorie x facteur aléatoire. # Explorons la variance dans nos données Créez de nouvelles # variables qui représentent chaque combinaison de # variables. dat.tf &lt;- within(dat.tf, { # genotype x nutrient x clipping gna &lt;- interaction(gen, nutrient, amd) gna &lt;- reorder(gna, total.fruits, mean) # population x nutrient x clipping pna &lt;- interaction(popu, nutrient, amd) pna &lt;- reorder(pna, total.fruits, mean) }) Maintenant, visualisons: # Boxplot of total fruits vs genotype x nutrient x clipping interaction ggplot(data = dat.tf, aes(factor(x = gna), y = log(total.fruits + 1))) + geom_boxplot(colour = &quot;skyblue2&quot;, outlier.shape = 21, outlier.colour = &quot;skyblue2&quot;) + ylab(&quot;log (Total fruits)\\n&quot;) + # \\n creates a space after the title xlab(&quot;\\nGenotype x nutrient x clipping&quot;) + # space before the title theme_bw() + theme(axis.text.x = element_blank()) + stat_summary(fun = mean, geom = &quot;point&quot;, colour = &quot;red&quot;) De même, la variance du total de fruits montre une grande hétérogénéité entre les populations (population x nutriments x herbivorie). Retour au choix de la distribution des erreurs Comme nous venons de voir, il existe une importante hétérogénéité parmi la variance de chaque groupe, même lorsque la variable réponse est transformée (i.e. log). Pour identifier la famille de distribution la plus appropriée, nous pouvons examiner un graphique de diagnostic de la variance de chaque groupe par rapport à leurs moyennes. Nous présentons un exemple ci-dessous pour le regroupement par génotype x nutriments x herbivore (clipping). Si nous observons une relation linéaire entre la variance et la moyenne avec une pente = 1, une famille de Poisson serait appropriée, Si nous observons une relation moyenne-variance linéaire avec une pente&gt; 1 (c. \\(Var = \\varphi\\mu\\) où \\(\\varphi &gt; 1\\)), la famille quasi-Poisson (tel que présenté ci-dessus) doit être utilisée, Enfin, une relation quadratique entre la variance et la moyenne (c. \\(Var = \\mu(1+\\alpha) or \\mu(1+\\mu/k)\\)), est caractéristique des données surdispersées résultant d’une hétérogénéité sous-jacente entre les échantillons. Dans ce cas, la distribution binomiale négative (Poisson-gamma) serait plus appropriée. # Figure diagnostique de variances par groupe vs moyennes # par groupe (genotype x nutrient x clipping grouping). # Code pour créer la figure: # https://github.com/QCBSRworkshops/workshop07/blob/main/pres-fr/data/glmm_e.r # On remarque beaucoup de variation entre les variances des # échantillons dans les données transformées Par exemple, # entre génotypes: grpVars &lt;- tapply(dat.tf$total.fruits, dat.tf$gna, var) grpMeans &lt;- tapply(dat.tf$total.fruits, dat.tf$gna, mean) # Quasi-Poisson lm1 &lt;- lm(grpVars ~ grpMeans - 1) phi.fit &lt;- coef(lm1) # Le -1 specifie un modèle avec une ordonnée à l&#39;origine de # 0 # Binomiale négative lm2 &lt;- lm(grpVars ~ I(grpMeans^2) + offset(grpMeans) - 1) k.fit &lt;- 1/coef(lm2) # offset() spécifie qu&#39;on veut ajouter un terme pour les # moyennes de groupes avec un coefficient fixé à 1 # Non-parametric loess fit Lfit &lt;- loess(grpVars ~ grpMeans) # La figure plot(grpVars ~ grpMeans, xlab = &quot;Group means&quot;, ylab = &quot;Group variances&quot;) abline(a = 0, b = 1, lty = 2) text(105, 500, &quot;Poisson&quot;) curve(phi.fit * x, col = 2, add = TRUE) # bquote() remplace des valeurs numériques dans des # équations avec des symboles text(110, 3900, bquote(paste(&quot;QP: &quot;, sigma^2 == .(round(phi.fit, 1)) * mu)), col = 2) curve(x * (1 + x/k.fit), col = 4, add = TRUE) text(104, 7200, paste(&quot;NB: k = &quot;, round(k.fit, 1), sep = &quot;&quot;), col = 4) mvec &lt;- 0:120 lines(mvec, predict(Lfit, mvec), col = 5) text(118, 2000, &quot;loess&quot;, col = 5) La figure ci-dessus montre qu’un modèle linéaire quasi-Poisson sera peut-être mieux qu’une binomiale négative, mais il faudrait continuer le processus de modélisation. "],["glmm-poisson.html", "Chapitre 15 GLMM Poisson", " Chapitre 15 GLMM Poisson Compte tenu de la relation moyenne-variance, nous avons besoin d’un modèle qui tient compte de la surdispersion. Pour comprendre pourquoi, commençons avec un modèle avec une distribution de Poisson. Pour lancer un GLMM dans R, nous faisons appel à la fonction glmer() de la librairie lme4: # GLMM Poisson Nous avons besoin d&#39;un modèle qui tient # compte de la surdispersion. Commençons avec un modèle # Poisson mp1 &lt;- glmer(total.fruits ~ nutrient * amd + rack + status + (1 | popu) + (1 | gen), data = dat.tf, family = &quot;poisson&quot;) Effets aléatoires : (1|popu) et (1|gen). Nous faisons varier les ordonnées à l’origine pour les différentes populations (popu) et génotypes (gen). Vérification de la surdispersion On vérifie la surdispersion en utilisant la fonction overdisp_fun() (Bolker et al. 2011) qui divise la déviance des résidus (de Pearson) par leurs degrés de liberté. La fonction teste si le rapport est plus grand que 1. Effectuons ce test: # Téléchargez le code glmm_funs.R de la page wiki et # exécutez la fonction dans R source(file = &quot;data/glmm_funs.R&quot;) # Surdispersion? overdisp_fun(mp1) ## chisq ratio p logp ## 15755.86829 25.57771 0.00000 -6578.47025 # Le rapport est significativement &gt; 1 Le rapport est significativement &gt; 1 Comme on s’y attendait, nous devons modéliser une distribution différente où la variance augmente plus rapidement que la moyenne. "],["glmm-binomiale-négative.html", "Chapitre 16 GLMM binomiale négative", " Chapitre 16 GLMM binomiale négative Une option pour une distribution où la variance augmente plus rapidement avec la moyenne est la distribution binomiale négative (ou Poisson-gamma). Rappelons que la distribution binomiale négative répond à l’hypothèse selon laquelle la variance est proportionnelle au carré de la moyenne. On peut modéliser cette distribution avec la fonction glmer.nb(): # GLMM binomial négatif utilisant la fonction glmer.nb() mnb1 &lt;- glmer.nb(total.fruits ~ nutrient * amd + rack + status + (1 | popu) + (1 | gen), data = dat.tf, control = glmerControl(optimizer = &quot;bobyqa&quot;)) # &#39;control&#39; spécifie la façon dont nous optimisons les # valeurs des paramètres On teste encore une fois la surdispersion du modèle: # Surdispersion? overdisp_fun(mnb1) ## chisq ratio p logp ## 721.034466390 1.170510497 0.002143424 -6.145350714 # Le rapport est beaucoup plus près de 1 mais la valeur de # p &lt; 0.05 Le rapport est beaucoup plus près de 1 mais la valeur de p &lt; 0.05 "],["glmm-poisson-lognormale.html", "Chapitre 17 GLMM Poisson-lognormale 17.1 Intercepts aléatoires 17.2 Représentation graphique des paramètres du modèle", " Chapitre 17 GLMM Poisson-lognormale Une deuxième option pour une distribution où la variance augmente plus rapidement avec la moyenne est la distribution Poisson-lognormale. Ce modèle place effectivement une priorité lognormale sur \\(εi\\). Une distribution Poisson-lognormale avec une moyenne de \\(µ\\) et une variance antérieure lognormale de \\(σ2\\) a une variance: \\(var(y) = µ + µ2 [exp(σ2) - 1]\\) En revanche, nous avons vu que la distribution binomiale négative (Poisson-gamma) était donné par: \\(var(y) = µ + µ2/k\\) En générale, la variance \\(σ2\\) dans la distribution Poisson-lognormal dépendra du niveau de regroupement que nous sélectionnons (i.e. au niveau individuel, génotype ou de la population). Donc, le modèle de Poisson-lognormal nous permet d’assigner l’agrégation observée à différentes sources d’hétérogénéité. Pour mettre en œuvre le effet aléatoire au niveau de l’observation, nous allons l’évaluer au niveau individuel. Pour ce faire, il suffit de placer un effet aléatoire au niveau des observations dans la formule du modèle. Voir Harrison (2014) pour plus de détails https://doi.org/10.7717/peerj.616. Pour ce faire, nous créons tout d’abord une variable nommée X: # GLMM Poisson-lognormale # Cette variable est déjà dans vos données &#39;dat.tf&#39;, mais # voici comment la créer. dat.tf$X &lt;- 1:nrow(dat.tf) On traite la surdispersion en ajoutant l’effet (1|X) dans la formule: # Tenir compte de la surdispersion mpl1 &lt;- glmer(total.fruits ~ nutrient * amd + rack + status + (1 | X) + (1 | popu) + (1 | gen), data = dat.tf, family = &quot;poisson&quot;, control = glmerControl(optimizer = &quot;bobyqa&quot;)) On teste finalement pour la présence de surdispersion: # Surdispersion? overdisp_fun(mpl1) ## chisq ratio p logp ## 1.775360e+02 2.886764e-01 1.000000e+00 -3.754681e-73 # Le rapport est maintenant conforme avec notre critère, # soit &lt; 1 Le rapport est maintenant conforme avec notre critère, soit &lt; 1! 17.1 Intercepts aléatoires Maintenant que nous avons la distribution d’erreur appropriée, nous pouvons tester l’importance des interceptes aléatoires (pour population et génotype) en comparant des modèles nichés avec et sans les effets aléatoires d’intérêt en utilisant soit: 1. L’approche théorique d’information (tel que le Critère d’Information d’Akaike; AIC), qui, comme nous l’avons vu apres examine plusieurs hypothèses concurrentes (modèles) simultanément pour identifier le modèle avec le pouvoir prédictif le plus élevé compte tenu des données. Nous allons encore une fois utiliser le AICc pour corriger les petites tailles d’échantillon. 2. L’approche fréquentiste (test d’hypothèse nulle traditionnelle), où deux modèles nichés sont comparés en utilisant le tests de rapport de vraisemblance de la fonction anova(). Il est important de noter qu’avec cette approche, nous testons une hypothèse nulle d’une variance de zéro, mais étant donné que nous ne pouvons pas avoir un écart négatif, nous testons le paramètre à la limite de sa région réalisable. Par conséquent, la valeur de p rapporté est environ le double de ce qu’elle devrait être (c. nous avons tronquée la moitié des valeurs possibles ; celles qui tombent en dessous de 0). # popu seulement mpl1.popu &lt;- glmer(total.fruits ~ nutrient * amd + rack + status + (1 | X) + (1 | popu), data = dat.tf, family = &quot;poisson&quot;, control = glmerControl(optimizer = &quot;bobyqa&quot;)) # gen seulement mpl1.gen &lt;- glmer(total.fruits ~ nutrient * amd + rack + status + (1 | X) + (1 | gen), data = dat.tf, family = &quot;poisson&quot;, control = glmerControl(optimizer = &quot;bobyqa&quot;)) # Approche AICc ICtab(mpl1, mpl1.popu, mpl1.gen, type = c(&quot;AICc&quot;)) ## dAICc df ## mpl1 0.0 10 ## mpl1.popu 2.0 9 ## mpl1.gen 16.1 9 # Approche fréquentiste (Likelihood Ratio Test) anova(mpl1, mpl1.popu) ## Data: dat.tf ## Models: ## mpl1.popu: total.fruits ~ nutrient * amd + rack + status + (1 | X) + (1 | popu) ## mpl1: total.fruits ~ nutrient * amd + rack + status + (1 | X) + (1 | popu) + (1 | gen) ## npar AIC BIC logLik deviance Chisq Df Pr(&gt;Chisq) ## mpl1.popu 9 5017.4 5057.4 -2499.7 4999.4 ## mpl1 10 5015.4 5059.8 -2497.7 4995.4 4.0639 1 0.04381 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 anova(mpl1, mpl1.gen) ## Data: dat.tf ## Models: ## mpl1.gen: total.fruits ~ nutrient * amd + rack + status + (1 | X) + (1 | gen) ## mpl1: total.fruits ~ nutrient * amd + rack + status + (1 | X) + (1 | popu) + (1 | gen) ## npar AIC BIC logLik deviance Chisq Df Pr(&gt;Chisq) ## mpl1.gen 9 5031.5 5071.5 -2506.8 5013.5 ## mpl1 10 5015.4 5059.8 -2497.7 4995.4 18.177 1 2.014e-05 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Notez que le modèle sans l’intercept aléatoire pour génotype est à moins de deux unités AICc du modèle complet, ce qui indique que les deux modèles sont tout aussi plausibles (i.e. peu de soutien pour inclure un intercept aléatoire pour le génotype). Toutefois, lorsque nous utilisons la comparaison de vraisemblance de modèles nichés (anova()), et corrigeons pour les valeurs p gonflés par un facteur de 2, nous trouvons que dans les deux cas, p &lt;0,05. Donc le modèle avec les deux effets aléatoires (mpl1) est sélectionné. 17.2 Représentation graphique des paramètres du modèle Maintenant que nous avons choisi notre modèle, visualisons les paramètres du modèle. Peut être obtenu en utilisant la fonction coefplot2()de la librairie coefplot2: Notez: Cette librairie n’est pas sur le CRAN! On utilise la librairie remotes pour l’installer à partir de GitHub. # Visualisons les paramètres du modèle # Cette librairie n&#39;est pas sur le CRAN! On utilise la # librairie `remotes` pour l&#39;installer à partir de GitHub. if (!require(&quot;coefplot2&quot;)) remotes::install_github(&quot;palday/coefplot2&quot;, subdir = &quot;pkg&quot;) ## Loading required package: coefplot2 ## Loading required package: coda library(coefplot2) # Effets aléatoires coefplot2(mpl1, ptype = &quot;vcov&quot;, intercept = TRUE, main = &quot;Random effect variance&quot;) Ici, nous pouvons voir que certains effets aléatoires présentent une plus grande variance que d’autres. La variance des effets aléatoires (σ2i) représente la variance moyenne des effets aléatoires du modèle. Puisque cette variance reflète la variance “moyenne” des effets aléatoires pour les modèles mixtes, elle est également appropriée pour les modèles avec des structures d’effets aléatoires plus complexes, comme les pentes aléatoires ou les effets aléatoires imbriqués. # Effets fixes coefplot2(mpl1, intercept = TRUE, main = &quot;Fixed effect coefficient&quot;) La variance des effets fixes (σ2f) est la variance de la matrice-multiplication β∗X (vecteur de paramètres par matrice de modèle) Notez: Les barres d’erreur sont visibles seulement pour les effets fixes, car glmer() ne modélise pas d’incertitude pour les effets aléatoires. Visualisation des effets aléatoires Vous pouvez extraire les effets aléatoires en utilisant la fonction ranef() et les tracer en utilisant un dotplot() de la librairie lattice. On constate une variation inter-population: Les populations espagnoles (SP) ont des valeurs plus élevées que les populations suédoises (SW) et néerlandaises (NL) On constate une faible variation inter-génotype : Les différences entre les génotypes semblent induites par le génotype 34 # dotplot code pp &lt;- list(layout.widths = list(left.padding = 0, right.padding = 0), layout.heights = list(top.padding = 0, bottom.padding = 0)) r2 &lt;- ranef(mpl1, condVar = TRUE) d2 &lt;- dotplot(r2, par.settings = pp) grid.arrange(d2$gen, d2$popu, nrow = 1) "],["modèle-final.html", "Chapitre 18 Modèle final 18.1 Défi 9", " Chapitre 18 Modèle final Les même méthodes peuvent être utilisées avec un GLMM ou un LMM pour choisir entre des modèles avec différentes ordonnées à l’origine et/ou pentes aléatoires ainsi que pour choisir les effets fixes à conserver dans le modèle final. En voici deux: une approche de la théorie de l’information (e.g., AICc - Atelier 5) une approche fréquentiste (où l’importance de chaque terme est évaluée en faisant un test de rapport de vraisemblance; LRT, avec la fonction anova()) Nous dérivons d’abord les modèles potentiels et les comparons en utilisant l’AICc: mpl1 &lt;- glmer(total.fruits ~ nutrient * amd + rack + status + (1 | X) + (1 | popu) + (1 | gen), data = dat.tf, family = &quot;poisson&quot;, control = glmerControl(optimizer = &quot;bobyqa&quot;)) mpl2 &lt;- update(mpl1, . ~ . - rack) # modèle sans rack mpl3 &lt;- update(mpl1, . ~ . - status) # modèle sans status mpl4 &lt;- update(mpl1, . ~ . - amd:nutrient) # modèle sans interaction amd:nutrient aic_tab &lt;- MuMIn::model.sel(mpl1, mpl2, mpl3, mpl4) (round(aic_table &lt;- aic_tab[, c(&quot;AICc&quot;, &quot;delta&quot;, &quot;df&quot;)], digits = 2)) ## AICc delta df ## mpl1 5015.73 0.00 10 ## mpl4 5017.11 1.38 9 ## mpl3 5017.22 1.49 8 ## mpl2 5070.75 55.02 9 Nous ne couvrons pas tous les modèles possibles ci-dessus, cependant, l’interaction amd:nutriments ne peut être évaluée que si les effets additifs de amd et de nutriments sont présents dans le modèle. Nous pouvons aussi utiliser les fonctions drop1() et dfun() pour évaluer nos effets fixes (dfun() convertit les valeurs AIC retournées par drop1() en valeurs \\(\\Delta\\)AIC) dd_LRT &lt;- drop1(mpl1, test = &quot;Chisq&quot;) (dd_AIC &lt;- dfun(drop1(mpl1))) ## Single term deletions ## ## Model: ## total.fruits ~ nutrient * amd + rack + status + (1 | X) + (1 | ## popu) + (1 | gen) ## npar dAIC ## &lt;none&gt; 0.000 ## rack 1 55.083 ## status 2 1.612 ## nutrient:amd 1 1.444 Fort effet de rack (dAIC = 55.08 si on enlève cette variable) Effets de status et de l’interaction sont faibles (dAIC &lt; 2) Commençons par enlever l’interaction non significative afin de tester les effets principaux de nutriments et d’herbivorie. mpl2 &lt;- update(mpl1, . ~ . - amd:nutrient) mpl3 &lt;- update(mpl2, . ~ . - rack) # pas de rack ou d&#39;interaction mpl4 &lt;- update(mpl2, . ~ . - status) # pas de status ou d&#39;interaction mpl5 &lt;- update(mpl2, . ~ . - nutrient) # pas de nutrient ou d&#39;interaction mpl6 &lt;- update(mpl2, . ~ . - amd) # pas d&#39;herbivorie ou d&#39;interaction Sélectionnez le meilleur modèle avec la méthode de votre choix: Méthode par AICc aic_tab2 &lt;- MuMIn::model.sel(mpl2, mpl3, mpl4, mpl5, mpl6) (round(aic_table2 &lt;- aic_tab2[, c(&quot;AICc&quot;, &quot;delta&quot;, &quot;df&quot;)], digits = 2)) ## AICc delta df ## mpl2 5017.11 0.00 9 ## mpl4 5018.28 1.17 7 ## mpl6 5027.27 10.16 8 ## mpl3 5071.28 54.17 8 ## mpl5 5152.74 135.63 8 Méthode avec drop1() dd_LRT2 &lt;- drop1(mpl2, test = &quot;Chisq&quot;) dd_AIC2 &lt;- dfun(drop1(mpl2)) Quels sont nos constats ? Les nutriments et l’herbivorie ont un effet important (grand changement d’AIC de \\(135.6\\) (mpl5) et \\(10.2\\) (mpl6) si l’un ou l’autre sont supprimés, respectivement). Notre modèle final inclut donc : Effets fixes * nutriments, * herbivorie * la variable nuisance de rack. Effets aléatoires * effet du niveau d’observation (1|X) * populations (1|popu) * génotypes (1|gen) 18.1 Défi 9 En utilisant l’ensemble de données inverts (temps de développement larvaire (PLD) de 74 espèces d’invertébrés et vertébrés marins élevés à différentes températures et temps), répondez aux questions suivantes: Quel est l’effet du type d’alimentation et du climat (effets fixes) sur PLD? Est-ce que cette relation varie selon les taxons (effets aléatoires)? Quelle est la meilleure famille de distributions pour ces données? Finalement, une fois que vous avez déterminé la meilleure famille de distribution, re-évaluez vos effets fixes et aléatoires. Défi 9 Solution: # inverts &lt;- read.csv(&#39;data/inverts.csv&#39;, header = TRUE) # head(inverts) table(inverts$temp, inverts$feeding.type) # mod.glm &lt;- glm(PLD ~ temp + feeding.type, family = # poisson(), data = inverts) summary(mod.glm) # drop1(mod.glm, test = &#39;Chisq&#39;) # boxplot(PLD ~ temp, data = inverts) boxplot(PLD ~ # feeding.type, data = inverts) # boxplot(predict(mod.glm, type = &#39;response&#39;)~inverts$temp) # plot() # modglm &lt;- glm(PLD ~ temp + feeding.type, family = # poisson(), data = inverts) # r2 &lt;- ranef(mpl1, condVar = TRUE) d2 &lt;- dotplot(r2, # par.settings = pp) # plot(aggregate(PLD ~ taxon, FUN = mean, data = # inverts)[,2], aggregate(PLD ~ taxon, FUN = var, data = # inverts)[,2], pch = 19) abline(a = 0, b = 1, lty = 2) # mod.glmer &lt;- glmer.nb(PLD ~ temp + feeding.type + # (1|taxon), data = inverts) mod.glm &lt;- glm.nb(PLD ~ temp + # feeding.type, family = poisson(), data = inverts) # plot(aggregate(PLD ~ taxon, FUN = var, data = # inverts)[,2], aggregate(PLD ~ taxon, FUN = mean, data = # inverts)[,2]) abline(a = 0, b = 1, lty = 2 ) "],["ressources-additionnelles.html", "Chapitre 19 Ressources additionnelles", " Chapitre 19 Ressources additionnelles Libraries connues pour des (G)LMM Fréquentiste : nlme, lme4, glmmTMB Bayésien : brms, rstan, rstanarm, MCMCglmm Articles * Harrison et al. (2018), PeerJ, DOI 10.7717/peerj.4794 * Silk et al. (2020), PeerJ, DOI 10.7717/peerj.9522 * Schielzeth et al. (2020), Methods Ecol Evol., DOI: 10.1111/2041-210X.13434 * Zuur &amp; Ieno (2016), Methods Ecol Evol., DOI: 10.1111/2041-210X.12577 Merci de votre participation à cet atelier!! "],["references.html", "Chapitre 20 References", " Chapitre 20 References "]]
