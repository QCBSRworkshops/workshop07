[["index.html", "Atelier 7: Modèles linéaires et généralisés linéaires mixtes Série d’ateliers R du CSBQ Préface 0.1 Code de conduite 0.2 Contributeurs et contributrices 0.3 Contribuez à la série!", " Atelier 7: Modèles linéaires et généralisés linéaires mixtes Série d’ateliers R du CSBQ Développé et entretenu par les contributeurs et les contributrices de la Série d’ateliers R du CSBQ1. 2021-03-16 21:59:16 Préface La Série d’ateliers R du CSBQ est une série de 10 ateliers qui guide les participants à travers les étapes nécessaires à l’utilisation de R pour un large éventail d’analyses statistiques pertinentes pour la recherche en biologie et en écologie. Ces ateliers en accès libre ont été créés par des membres du CSBQ, à la fois pour les membres du CSBQ et pour la communauté au sens large. Le contenu de cet atelier a été revu par plusieurs membres du CSBQ. Si vous souhaitez suggérer des modifications, veuillez contacter les coordinateurs de la série actuelle, dont la liste figure sur la page principale de Github 0.1 Code de conduite La Série d’ateliers R du CSBQ et le Symposium R du CSBQ sont des lieux dédiés à fournir un environnement accueillant et favorable à toutes les personnes, indépendamment de leurs origines ou de leur identité. Les participants, les présentateurs et les organisateurs de la série d’ateliers et d’autres activités connexes acceptent le présent code de conduite lorsqu’ils assistent à des activités liées aux ateliers. Nous ne tolérons pas les comportements irrespectueux ou qui excluent, intimident ou gênent les autres. Nous ne tolérons pas la discrimination ou le harcèlement fondés sur des caractéristiques telles que, mais sans s’y limiter, l’identité et l’expression du genre, l’orientation sexuelle, le handicap, l’apparence physique, la taille du corps, la citoyenneté, la nationalité, les origines ethniques ou sociales, la grossesse, le statut familial, les informations génétiques, la religion ou les convictions (ou l’absence de celles-ci), l’appartenance à une minorité nationale, la propriété, l’âge, l’éducation, le statut socio-économique, les choix techniques et le niveau d’expérience. Il s’applique à tous les espaces gérés par l’atelier ou affiliés à celui-ci, y compris, mais sans s’y limiter, les ateliers, les listes de diffusion et les forums en ligne tels que GitHub, Slack et Twitter. 0.1.1 Comportement attendu Tous les participants sont tenus de faire preuve de respect et de courtoisie envers les autres. Toutes les interactions doivent être professionnelles, quelle que soit la plateforme utilisée : en ligne ou en personne. Afin de favoriser un environnement d’apprentissage positif et professionnel, nous encourageons les types de comportements suivants dans tous les événements et plates-formes des ateliers : Utiliser un langage accueillant et inclusif ; Respecter les différents points de vue et expériences ; Accepter avec grâce les critiques constructives ; Se concentrer sur ce qui est le mieux pour la communauté ; Faire preuve de courtoisie et de respect envers les autres membres de la communauté. 0.1.2 Comportements inacceptables Voici quelques exemples de comportements inacceptables de la part des participants à tout événement ou plateforme d’atelier : les commentaires écrits ou verbaux qui ont pour effet d’exclure des personnes sur la base de leur appartenance à un groupe spécifique ; faire craindre à quelqu’un pour sa sécurité, par exemple en le harcelant ou en l’intimidant ; des menaces ou des propos violents dirigés contre une autre personne ; l’affichage d’images sexuelles ou violentes ; l’attention sexuelle non désirée ; les contacts physiques non consensuels ou non désirés ; des insultes ou des rabais ; les blagues sexistes, racistes, homophobes, transphobes, incapables ou d’exclusion ; l’incitation à la violence, au suicide ou à l’automutilation ; la poursuite de l’interaction (y compris la photographie ou l’enregistrement) avec une personne après qu’on - lui a demandé d’arrêter ; la publication d’une communication privée sans consentement. 0.2 Contributeurs et contributrices Développé à l’origine par : A contribué à modifier la présentation : Contribution avec des changements à la documentation écrite : Contribution en signalant des problèmes et en suggérant des modifications : 0.3 Contribuez à la série! En construction. La Série d’ateliers R du CSBQ fait partie du Centre de la science de la biodiversité du Québec, et est maintenue par les coordonnateurs et les coordonnatrices de la série, et les membres étudiants diplômés, postdoctoraux et professionnels de la recherche. La liste des contributeurs et des contributrices de cet atelier sont accessiblesici↩︎ "],["objectifs-dapprentissage.html", "Chapitre 1 Objectifs d’apprentissage", " Chapitre 1 Objectifs d’apprentissage Les modèles à effets mixtes permettent aux écologistes de surmonter un certain nombre de limitations liées aux modèles linéaires traditionnels. Dans cet atelier, vous apprendrez à déterminer si vous devez utiliser un modèle à effets mixtes pour analyser vos données. En particulier, nous allons: 1. Décrire les modèles (généralisés) à effets mixtes 2. Identifier les situations dans lesquelles l’utilisation d’effets mixtes est appropriée 3. Mettre en œuvre des modèles linéaires mixtes de base avec R 4. Exécuter des modèles linéaires généralisés mixtes de base avec R 5. Valider, interpréter et visualiser les modèles mixtes avec R "],["préparez-vous-pour-cet-atelier.html", "Chapitre 2 Préparez-vous pour cet atelier", " Chapitre 2 Préparez-vous pour cet atelier Pour vous préparer à cet atelier, vous devez télécharger et installer les dernières versions de RStudio et de R. Vous devez également télécharger les données que nous utiliserons au cours de cet atelier: R Script Fish data Arabidopsis data Inverts data glmm_funs Cet atelier nécessite les paquets R suivants: ggplot2 lm4 AICcmodavg MASS vcdExtra bbmle DescTools Pour les installer depuis CRAN, exécutez: install.packages(&quot;ggplot2&quot;) install.packages(&quot;lme4&quot;) install.packages(&quot;AICcmodavg&quot;) install.packages(&quot;MASS&quot;) install.packages(&quot;vcdExtra&quot;) install.packages(&quot;bbmle&quot;) install.packages(&quot;DescTools&quot;) Pour charger ces paquets, exécutez: library(ggplot2) library(lme4) library(AICcmodavg) library(MASS) library(vcdExtra) library(bbmle) library(DescTools) "],["pourquoi-choisir-un-mlm.html", "Chapitre 3 Pourquoi choisir un MLM?", " Chapitre 3 Pourquoi choisir un MLM? Les données écologiques et biologiques peuvent être complexes et désordonnées. Il existe généralement une structure particulière dans les données (i.e. les observations individuelles ne sont pas toujours indépendantes), les relations entre les variables d’intérêt peuvent différer en fonction de facteurs de regroupement, telles que les espèces, et la plupart du temps de faibles tailles d’échantillons rendent l’ajustement de modèles avec de nombreux paramètres difficile. Les modèles linéaires à effets mixtes (MLM) ont été développés pour aborder ces questions. Ils peuvent être appliqués à un grand nombre de questions écologiques et prennent de nombreuses formes différentes. Dans cet atelier, nous allons utiliser une simple approche interrogative pour apprendre les bases du fonctionnement des MLMs et nous verrons comment les ajuster. "],["quest-ce-quun-mlm-et-pourquoi-est-ce-important.html", "Chapitre 4 Qu’est-ce qu’un MLM et pourquoi est-ce important?", " Chapitre 4 Qu’est-ce qu’un MLM et pourquoi est-ce important? Les MLMs vous permettent d’utiliser toutes les données que vous avez au lieu d’utiliser des moyennes d’échantillons non indépendants, ils tiennent compte de la structure de vos données (par exemple, quadrats nichés dans les sites eux-mêmes nichés dans les forêts), ils permettent aux relations de varier en fonction de différents facteurs de regroupement (parfois appelés des effets aléatoires) et ils nécessitent moins d’estimation de paramètres que la régression classique, ce qui vous permet d’économiser des degrés de liberté. Mais comment font-ils tout cela? Ces questions vous paraîtront beaucoup plus claires apès avoir lu cette section. Tout d’abord, commençons par se familiariser avec l’ensemble des données. "],["introduction-au-jeu-de-données.html", "Chapitre 5 Introduction au jeu de données", " Chapitre 5 Introduction au jeu de données # Supprimer commandes antérieures en R rm(list = ls()) # Placez tout le matériel de l&#39;atelier dans un même dossier # sur votre ordinateur Exécutez la ligne de code suivante et # utilisez la fenêtre de navigation pour sélectionner # QCBS_W6_Data.csv le fichier dans le dossier qui contient le # matériel de l&#39;atelier file.choose() # Réglez le répertoire de travail vers le dossier qui # contient les fichiers en copiant toute la sortie de la # commande file.choose (), à l&#39;exception du nom de fichier R, # et collez le tout dans setwd(). # Par exemple collez &#39;/Users/ziegljac/Documents/QCBS_R/&#39; -&gt; # incluez les guillemets NON # &#39;/Users/ziegljac/Documents/QCBS_R/Get_Data_Func.R&#39; -&gt; # incluez les guillemets setwd() # Chargez les bibliothèques et les données utiles Si vous # n’avez jamais chargé ces bibliothèques avant, vous devrez # utiliser la fonction install.packages() avant la fonction # library() library(ggplot2) library(lme4) library(arm) library(AICcmodavg) data &lt;- read.csv(&quot;QCBS_W6_Data.csv&quot;) Le jeu de données que nous utiliserons porte sur les positions trophiques de poissons. Trois espèces ont été sélectionnées pour l’étude et dix individus par espèce ont été mesurés (longueur corporelle) dans six lacs différents. Voici une représentation visuelle pour vous aider à comprendre tout cela ! Notez : seulement trois individus sont montrés par espèce, mais en réalité il y a 10 individus par espèce. Une simple question à laquelle vous pourriez répondre avec ce jeu de données est : \"est-ce que la position trophique des poissons augmente avec leur taille\" ? Au cours de l’atelier, on tentera de répondre à cette question. DÉFI 1 Pour votre premier défi, vous devez reproduire les graphiques 1 à 3 du code QCBS_W5_LMM.R. Regardez les graphiques et essayez d’obtenir une idée de ce qui se passe. Deux questions clés à se poser sont : -Est-ce qu&#39;on s&#39;attend à ce que, pour toutes les espèces, la position trophique augmente avec la longueur corporelle? Exactement de la même façon? -S&#39;attend-on à ce que ces relations soient pareilles entre les lacs? Comment pourraient-elles différer ? ++++ Réponse au défi 1 | # Utilisé pour simplifier les figures fig &lt;- theme_bw() + theme(panel.grid.minor = element_blank(), panel.grid.major = element_blank(), panel.background = element_blank()) + theme(strip.background = element_blank(), strip.text.y = element_text()) + theme(legend.background = element_blank()) + theme(legend.key = element_blank()) + theme(panel.border = element_rect(colour = &quot;black&quot;, fill = NA)) # Faites les trois graphiques suivants pour explorer les # données plot &lt;- ggplot(aes(Fish_Length, Trophic_Pos), data = data) # Graphique 1 - Toutes les données plot + geom_point() + xlab(&quot;Length (mm)&quot;) + ylab(&quot;Trophic Position&quot;) + labs(title = &quot;All Data&quot;) + fig # Graphique 2 - Par espèce plot + geom_point() + facet_wrap(~Fish_Species) + xlab(&quot;Length (mm)&quot;) + ylab(&quot;Trophic Position&quot;) + labs(title = &quot;By Species&quot;) + fig # Graphique 3 – Par lac plot + geom_point() + facet_wrap(~Lake) + xlab(&quot;Length (mm)&quot;) + ylab(&quot;Trophic Position&quot;) + labs(title = &quot;By Lake&quot;) + fig SORTIE Graphique 1 Graphique 2 Graphique 3 Est-ce qu’on s’attend à ce que, pour toutes les espèces, la position trophique augmente avec la longueur corporelle? Exactement de la même façon? Toutes les espèces semblent augmenter en position trophique avec la longueur, mais la pente peut être différente selon les espèces. S’attend-on à ce que ces relations soient pareilles entre les lacs? Comment pourraient-elles différer? Certains paramètres spécifiques à un lac en particulier peuvent modifier la relation, tels que la productivité primaire du système. ++++ "],["comment-pourrions-nous-analyser-ces-données.html", "Chapitre 6 Comment pourrions-nous analyser ces données? 6.1 Nombreuses analyses séparées 6.2 Une analyse groupée 6.3 Construire un MLM", " Chapitre 6 Comment pourrions-nous analyser ces données? 6.1 Nombreuses analyses séparées Une façon d’analyser ces données est de faire une analyse séparée pour chaque espèce et chaque lac. Voici le graphique de la position trophique en fonction de la taille pour l’espèces 1 dans le lac 1 : Remarquez que vous devez estimer une ordonnée à l’origine et une pente pour chaque régression (2 paramètres x 3 espèces X 6 lacs = 36 paramètres estimés) et la taille d’échantillon pour chaque analyse est de 10. Il y a peu de chances de détecter un effet à cause de la faible taille d’échantillon et un taux d’erreur augmenté en raison de comparaisons multiples. 6.2 Une analyse groupée Une autre façon d’analyser ces données est de faire une seule analyse en ignorant les variables espèce et lac. Encore une fois, voici le graphique de toutes les données : Notez que vous avez maintenant une énorme taille d’échantillon et beaucoup moins de paramètres à estimer. Mais qu’en est-il de la pseudoréplication? Les poissons d’un même lac et d’une même espèce sont plus similaires entre-eux que les poissons de lacs et d’espèces différentes. De plus, regardez tout ce bruit dans les données ! Une partie doit être due aux effets de l’espèce et du lac. Pour notre question, on veut seulement savoir s’il y a un effet général de la longueur corporelle sur la position trophique. On ne cherche pas directement à savoir si cet effet pourrait varier faiblement par espèce en raison de processus biologiques que nous n’avons pas mesurés ou parmi les lacs en raison de variables environnementales non mesurées. Nous voulons simplement prendre en compte cette variation dans le modèle (parfois désignée effets aléatoires). 6.3 Construire un MLM Les MLMs sont un compromis entre séparer et regrouper. Ils: - Estiment une pente et une ordonnée à l&#39;origine pour chaque espèce et chaque lac (séparer), mais en calculant moins de paramètres qu&#39;une régression classique. - Utilisent toutes les données disponibles (regrouper) tout en contrôlant les différences entre les lacs et les espèces (pseudo-réplication). "],["effets-fixes-et-aléatoires.html", "Chapitre 7 Effets fixes et aléatoires 7.1 Effet fixe 7.2 Effet aléatoire", " Chapitre 7 Effets fixes et aléatoires Il y a un débat dans la littérature sur la définition des effets fixes et aléatoires. Il existe plusieurs définitions possibles des effets fixes et aléatoires et nous vous présenterons aujourd’hui celles que nous trouvons plus faciles à appliquer. 7.1 Effet fixe Quand une variable a un effet fixe, les données proviennent de tous les niveaux possibles d’un facteur (variable qualitative). On souhaite émettre des conclusions à propos des niveaux du facteur d’où les données proviennent. Exemple d’un effet fixe : comparer la concentration de mercure dans les poissons de trois habitats différents. L’habitat est un effet fixe (les trois ont été échantillonnés) et nous sommes intéressés à tirer des conclusions sur les effets de ces trois habitats spécifiques. 7.2 Effet aléatoire Les variables avec un effet aléatoire sont également appelées facteurs aléatoires, car elles sont seulement qualitatives (pas de variable continue). Un effet aléatoire est observé lorsque les données incluent seulement un échantillon aléatoire de tous les niveaux possibles du facteur, qui sont tous d’intérêt. Ils correspondent souvent à des facteurs de regroupement pour lesquels vous souhaitez contrôler l’effet dans votre modèle; vous ne vous intéressez pas à leur effet spécifique sur la variable de réponse. Exemple d’un effet aléatoire: une étude de la contamination du mercure dans les poissons de lacs de cratères ougandais. Pour des raisons logistiques, vous ne pouvez pas échantillonner tous les lacs de cratères, donc vous échantillonnez seulement huit d’entre eux. Cependant, les poissons d’un lac donné pourrait avoir une sorte de corrélation entre eux (pseudo-corrélation), car ils sont soumis aux mêmes conditions environnementales. Même si vous n’êtes pas intéressé par l’effet de chaque lac spécifiquement, vous devez tenir compte de cette corrélation potentielle avec un facteur aléatoire (lac de cratère) afin de tirer des conclusions sur les lacs de cratères en général. "],["comment-fonctionnent-les-mlms.html", "Chapitre 8 Comment fonctionnent les MLMs? 8.1 Permettre aux intercepts et/ou pentes de varier selon le lac et l’espèce 8.2 Les intercepts, pentes, et intervalles de confiance associés sont ajustés pour tenir compte de la structure des données", " Chapitre 8 Comment fonctionnent les MLMs? 8.1 Permettre aux intercepts et/ou pentes de varier selon le lac et l’espèce Permettre aux intercepts et/ou pentes de varier selon certains facteurs (effets aléatoires) signifie simplement que vous supposez qu’ils proviennent d’une distribution normale. La moyenne et l’écart-type de cette distribution sont évalués en fonction de vos données. Les intercepts et pentes les plus probables de cette distribution sont ensuite ajustées par optimisation (ex. maximum de vraisemblance ou maximum de vraisemblance restreint). Intercepts Dans le cas d’espèces, seulement la moyenne et l’écart-type de la distribution d’intercepts sont estimés au lieu de trois intercepts pour chaque espèce. La moyenne de cette distribution est le «modèle au niveau de l’espèce». Dans cet exemple, nous n’avons que trois espèces. En général, plus votre facteur comporte de niveaux, plus la moyenne et l’écart-type de la distribution normale seront estimés précisément. Trois niveaux c’est un peu faible, mais plus facile à visualiser! Lorsque vous implémenterez un MLM dans R, notez que l’intercept dans le résumé est l’intercept au niveau des espèces (c.-à-d. la moyenne de tous les intercepts aléatoires). C’est la même chose pour les lacs : seuls la moyenne et l’écart-type des intercepts des lacs sont estimés au lieu de six intercepts pour chaque lac. Cela économise des degrés de liberté (moins d’estimation de paramètres sont nécessaires). Pentes Le même concept s’applique aux pentes qui varient par un facteur donné (effet aléatoire). C’est juste plus difficile à visualiser. Comme dans le cas des espèces, seuls la moyenne et l’écart-type des pentes sont estimés au lieu de trois pentes distinctes. Encore une fois, quand vous implémenterez votre MLM dans R, la pente dans le résumé sera la pente au niveau des espèces. 8.2 Les intercepts, pentes, et intervalles de confiance associés sont ajustés pour tenir compte de la structure des données Si une certaine espèce ou un lac est peu représenté (faible échantillon) dans les données (nous avons un design équilibré ici, donc ce n’est pas le cas dans notre exemple), le modèle va accorder plus d’importance au modèle groupé pour estimer l’ordonnée à l’origine et la pente de cette espèce ou de ce lac. Les intervalles de confiance des intercepts et pentes sont ajustés pour tenir compte de la pseudo-réplication basée sur ** le coefficient de corrélation intra-classe (CIC) ** - Combien de variation y a-t-il dans chaque groupe versus entre les groupes ? Ceci détermine votre ** taille effective de l’échantillon** - Une taille d’échantillon ajustée en fonction de la façon dont les données sont corrélées à l’intérieur des groupes. CIC élevé Dans ce scénario, le MLM traitera les points provenant du même lac plus comme une moyenne globale, car ils sont fortement corrélés. Par conséquent, la taille effective de l’échantillon sera plus petite, ce qui entraînera des intervalles de confiance plus grands pour la pente et l’intercept. CIC faible Dans ce scénario, le MLM traitera les points parvenant du même lac plus indépendamment parce qu’ils sont moins corrélés au sein du groupe que parmi les groupes. Par conséquent, la taille de l’échantillon sera plus grande, ce qui entraînera des intervalles de confiance plus petits pour la pente et l’intercept. DÉFI 2 Pour votre deuxième défi, répondez aux deux questions suivantes avec vos voisins. Comment le CIC et son intervalle de confiance seront affectés dans ces deux scénarios? -Les positions trophiques des poissons ne varient pas entre les lacs? -Les positions trophiques des poissons sont similaires dans les lacs mais différentes entre les lacs? ++++ Réponse défi 2 | -CIC faible - intervalles de confiance plus petits -CIC élevé - intervalles de confiance plus larges ++++ "],["comment-implémenter-un-mlm-dans-r.html", "Chapitre 9 Comment implémenter un MLM dans R? 9.1 Le protocole des modèles mixtes dans R: 9.2 Construction du modèle a priori et exploration des données 9.3 Coder les modèles potentiels et sélectionner le meilleur modèle 9.4 Validation du modèle 9.5 Interpréter les résultats et les visualiser graphiquement 9.6 Exercice de réflexion", " Chapitre 9 Comment implémenter un MLM dans R? 9.1 Le protocole des modèles mixtes dans R: 2.1: Construction du modèle a priori et exploration des données 2.2: Coder les modèles potentiels et sélectionner le meilleur modèle 2.3: Valider le modèle 2.4: Interpréter les résultats et visualiser le modèle 9.2 Construction du modèle a priori et exploration des données Nous voulons déterminer si la position trophique peut être prédite par la longueur corporelle, tout en prenant en compte la variation entre les espèces et les lacs. Donc nous voulons un modèle qui ressemble à ceci: &lt;m&gt; {PT_ijk} ∼ {Longueur_i} + {Lac_j} + {Espèce_k} + {ε} &lt;/m&gt; où, &lt;m&gt;{PT_ijk}&lt;/m&gt; est la position trophique du poisson (i) du lac (j) et de l’espèce (k) et ε sont les résidus du modèle (c. à d. la variation inexpliquée). Exploration des données Assurez-vous d’avoir fait le ménage de l’espace de travail (Housekeeping) avant de construire un modèle ! Les données ont-elles la bonne structure ? Utilisez le code suivant pour visualiser la structure et les types de variables au sein de votre jeu de données. ################ Section 2######################### Exécution d&#39;un modèle ################ mixte en R Processus de quatre étapes pour la construction ################ d&#39;un modèle mixte en R # 1) Construction du modèle a priori et exploration des # données #### i) Définir un modèle basé sur une connaissance # a priori Nous savons que nous voulons construire un modèle # qui évalue la relation entre la position trophique et la # longueur tout en tenant compte de la variation due au lac # et à l&#39;espèce Position trophique ~ Longueur + Espèce + Lac # ii)Housekeeping et exploration des données Assurez-vous que # la structure de vos données soit correcte str(data) ++++ Sortie | ++++ Regardez la distribution des échantillons pour chaque facteur : # Regardez la distribution des échantillons de chaque facteur # pour vérifier si le jeu de données est équilibré table(data$Lake) table(data$Fish_Species) ++++ Sortie | Lac ---- ---- Espèce ---- ---- ++++ Ce jeu de donné est parfaitement équilibré, mais les modèles mixtes peuvent analyser les plans expérimentaux non équilibrés (comme c’est souvent le cas en écologie!) Regardez la distribution des variables continues : # Regardez la distribution des variables continues # Transformez si nécessaire (ça évitera des problèmes # d’hétérogénéité des résidus du modèle) hist(data$Fish_Length) hist(data$Trophic_Pos) ++++ Sortie | Longueur ---- ---- Position trophique ---- ---- ++++ Des déviations majeures pourraient causer des problèmes d’hétéroscédasticité. Si c’est nécessaire, appliquez des transformations à vos données. Dans ce cas-ci, les données semblent correctes. Vérifier la colinéarité entre vos variables explicatives : Vous ne pouvez pas inclure deux variables explicatives colinéaires dans un même modèle, car leurs effets sur la variable réponse seront confondus, c.-à-d. que le modèle ne peut pas indiquer quelle variable colinéaire est responsable de la variation de la variable réponse. Par défaut, le modèle attribuera beaucoup de pouvoir explicatif à la première variable du modèle et peu de pouvoir aux variables qui suivent. Dans cet exemple, il n’y a pas de risque de colinéarité avec seulement une variable explicative continue. Si vous aviez une autre variable explicative (Var2) et vouliez vérifier la colinéarité, vous pouvez utiliser le code suivant : # Évaluer la colinéarité entre variables plot(data) cor(data$Fish_Length, data$Var2) DÉFI 3 Quelles mesures supplémentaires aurions-nous pu prendre sur le terrain et qui auraient pu être fortement corrélées avec la longueur corporelle? ++++ Réponse défi 3 | Un exemple est la masse du poisson – c’est une variable fortement corrélée avec la longueur du poisson. Par conséquent, nous ne voulons pas inclure ces deux variables dans le même modèle. ++++ Considérez l’échelle de vos données : Si deux variables dans le même modèle ont des valeurs se situant sur des échelles très différentes, il est probable que le modèle mixte indique un ‘problème de convergence’ en essayant de calculer les paramètres. La correction Z standardize les variables et résout ce problème. Elle permet également de mettre toutes vos variables sur la même échelle, même si elles étaient à l’origine de différentes unités : &lt;m&gt; {z} = ({x} - {mean(x)}) / {sd(x)} &lt;/m&gt; Parce que nos données ont des échelles très différentes, (la longueur est à une échelle plus longue que la position trophique), on applique la correction Z. # Considérez l&#39;échelle de vos données Note : Si deux # variables dans le même modèle ont des valeurs se situant # sur des échelles très différentes, il est probable que le # modèle mixte indique un &#39;problème de convergence&#39; en # essayant de calculer les paramètres. La correction Z # standardize les variables et résout ce problème : Qu&#39;est-ce # qu&#39;une correction de Z ?: (z = (x - mean(x))/sd(x)) # Longueur corrigée data$Z_Length &lt;- (data$Fish_Length - mean(data$Fish_Length))/sd(data$Fish_Length) # Position trophique corrigée data$Z_TP &lt;- (data$Trophic_Pos - mean(data$Trophic_Pos))/sd(data$Trophic_Pos) Pour savoir si un modèle mixte est nécessaire pour vos données, vous devez déterminer s’il est important de prendre en compte l’effet aléatoire de facteurs qui pourraient influencer la relation qui vous intéresse (dans notre cas, Lac et Espèce). Nous pouvons le faire en : -Créant un modèle linéaire sans les facteurs qui pourraient avoir un effet aléatoire -Calculant les résidus de ce modèle linéaire -Produisant un graphique de la valeur des résidus en fonction des niveaux des facteurs potentiellement aléatoires # Déterminez s&#39;il est important de tenir compte des # variations dans les &#39;effets aléatoires&#39; en comparant les # résidus d&#39;un modèle linéaire sans les effets aléatoires en # fonction des effets aléatoires potentiels lm.test &lt;- lm(Z_TP ~ Z_Length, data = data) lm.test.resid &lt;- rstandard(lm.test) # Effet de l’espèce plot(lm.test.resid ~ data$Fish_Species, xlab = &quot;Species&quot;, ylab = &quot;Standardized residuals&quot;) abline(0, 0, lty = 2) # Effet du lac plot(lm.test.resid ~ data$Lake, xlab = &quot;Lake&quot;, ylab = &quot;Standardized residuals&quot;) abline(0, 0, lty = 2) ++++ Sortie| Effet de l’espèce ---- ---- Effet du lac ---- ---- ++++ Pour ce modèle, nous devrions garder les effets aléatoires parce que les résidus standardisés montrent une variation à travers le lac et les espèces. 9.3 Coder les modèles potentiels et sélectionner le meilleur modèle Notre modèle a priori &lt;m&gt; {PT_ijk} ∼ {Longueur_i} + {Lac_j} + {Espèce_k} + {ε} &lt;/m&gt; Dans R, on le code ainsi : La structure de lmer n’est pas intuitive. Les éléments de base de la fonction sont : REML (Restricted Maximum Likelihood) est la méthode par défaut dans la fonction \"lmer\". Il est à noter que l’estimateur de l’écart-type (sigma) du maximum de vraisemblance (ML) est biaisé d’un facteur (n-2) / n. REML corrige ce biais en faisant un truc (multiplication matricielle de Y telle que la dépendance à X est enlevée).** En règle générale **, on devrait ** comparer les modèles d’effets aléatoires nichés avec REML** (parce que nous examinons les composantes de la variance et ceux-ci doivent être sans biais),** mais lorsque l’on compare des modèles nichés à effets fixes, nous devrions utiliser ML ** (parce REML fait ce truc avec les matrices X et Y pour corriger le biais). Mais comment faire si on souhaite aussi que la pente puisse varier? DÉFI 4 Réécrivez le code suivant de façon à ce que les pentes de la relation de la position trophique en fonction de la longueur corporelle varient par lac et par espèce. lmer(Z_TP ~ Z_Length + (1 | Lake) + (1 | Species), data = data, REML = TRUE) ++++ Réponse défi 4 | lmer(Z_TP ~ Z_Length + (1 + Z_Length | Lake) + (1 + Z_Length | Species), data = data, REML = TRUE) ++++ Pour déterminer si vous avez construit le meilleur modèle mixte basé sur vos connaissances a priori, vous devez comparer ce modèle a priori à d’autres modèles possibles. Avec le jeu de données sur lequel vous travaillez, il y a plusieurs modèles qui pourraient mieux correspondre à vos données. DÉFI 5 Faites une liste de 7 modèles alternatifs qui pourraient être construits et comparés à partir de celui-ci: Note - Si nous avions différents effets fixes entre les modèles, nous aurions dû indiquer «REML = FALSE» afin de comparer les modèles avec des méthodes de vraisemblance tels que AIC (voir ci-dessus). Cependant, vous devez rapporter les estimations des paramètres du «meilleur» modèle en utilisant «REML = TRUE». lmer(Z_TP ~ Z_Length + (1 | Lake) + (1 | Species), data = data, REML = TRUE) ++++ Réponse défi 5 | m1 &lt;- lmer(Z_TP ~ Z_Length + (1 | Lake) + (1 | Species), data = data, REML = TRUE) m2 &lt;- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Lake) + (1 + Z_Length | Species), data = data, REML = TRUE) m3 &lt;- lmer(Z_TP ~ Z_Length + (1 | Species), data = data, REML = TRUE) m4 &lt;- lmer(Z_TP ~ Z_Length + (1 | Lake), data = data, REML = TRUE) m5 &lt;- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Species), data = data, REML = TRUE) m6 &lt;- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Lake), data = data, REML = TRUE) m7 &lt;- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Lake) + (1 | Species), data = data, REML = TRUE) m8 &lt;- lmer(Z_TP ~ Z_Length + (1 | Lake) + (1 + Z_Length | Species), data = data, REML = TRUE) # Modèle bonus! M0 &lt;- lm(Z_TP ~ Z_Length, data = data) # Il est toujours utile de construire le modèle linéaire de # base sans facteurs avec variation de l&#39;ordonnée à l&#39;origine # ou de pente pour voir la variation dans les valeurs de AICc # values (même si &#39;lm&#39; n&#39;utilise pas la même méthode # d&#39;estimation). ++++ Maintenant que nous avons une liste de modèles potentiels, nous voulons les comparer entre eux pour sélectionner celui (ceux) qui a (ont) le plus grand pouvoir prédictif. Les modèles peuvent être comparés en utilisant la fonction \"AICc\" provenant du paquet (package) \"AICcmodavg\". Le critère d’information d’Akaike (AIC) est une mesure de qualité du modèle pouvant être utilisée pour comparer les modèles. L’AICc corrige pour le biais créé par les faibles tailles d’échantillon quand le AIC est calculé. Nous allons aussi construire le modèle linéaire de base lm() parce qu’il est toujours utile de voir la variation dans les valeurs de AICc. Pour cette comparaison il est important de changer la méthode à ML (REML=FALSE) parce que lm() n’utilise pas la même méthode d’estimation que lmer(). Par contre, il y a une preuve qui démontre que pour les modèles linéaires de bases les résultats de la méthode des moindres carrés (Least squares) est équivalente au résultats de la méthode ML. # 2) Coder les modèles potentiels et sélectionner le meilleur # modèle #### i) Coder les modèles potentiels Liste de tous # les modèles potentiels --&gt; Note: vous pouvez choisir de ne # pas coder ceux qui n&#39;ont pas de sens biologique. # Construisez aussi le modèle lm() pour voir la variation # dans les valeurs de AICc, mais changez la méthode à ML # (REML=FALSE) parce que lm() n&#39;utilise pas la même méthode # d&#39;estimation que lmer(). Modèle linéaire sans effets # aléatoires M0 &lt;- lm(Z_TP ~ Z_Length, data = data) # Modèle complet avec différents intercepts M1 &lt;- lmer(Z_TP ~ Z_Length + (1 | Fish_Species) + (1 | Lake), data = data, REML = FALSE) # Modèle complet avec différents intercepts et pentes M2 &lt;- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Fish_Species) + (1 + Z_Length | Lake), data = data, REML = FALSE) # Aucun effet Lac, intercept aléatoire seulement M3 &lt;- lmer(Z_TP ~ Z_Length + (1 | Fish_Species), data = data, REML = FALSE) # Aucun effet Espèce, intercept aléatoire seulement M4 &lt;- lmer(Z_TP ~ Z_Length + (1 | Lake), data = data, REML = FALSE) # Aucun effet Lac, intercept et pente aléatoires M5 &lt;- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Fish_Species), data = data, REML = FALSE) # Aucun effet Espèce, intercept et pente aléatoires M6 &lt;- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Lake), data = data, REML = FALSE) # Modèle complet avec intercepts et pentes qui variant par # Lac M7 &lt;- lmer(Z_TP ~ Z_Length + (1 | Fish_Species) + (1 + Z_Length | Lake), data = data, REML = FALSE) # Modèle complet avec intercepts et pentes qui variant par # Espèce M8 &lt;- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Fish_Species) + (1 | Lake), data = data, REML = FALSE) # ii) Comparer les modèles en comparant les valeurs AICc # Calculer les valeurs AICc pour chaque modèle AICc &lt;- c(AICc(M0), AICc(M1), AICc(M2), AICc(M3), AICc(M4), AICc(M5), AICc(M6), AICc(M7), AICc(M8)) # Mettre des valeurs dans une table pour faciliter la # comparaison Model &lt;- c(&quot;M0&quot;, &quot;M1&quot;, &quot;M2&quot;, &quot;M3&quot;, &quot;M4&quot;, &quot;M5&quot;, &quot;M6&quot;, &quot;M7&quot;, &quot;M8&quot;) AICtable &lt;- data.frame(Model = Model, AICc = AICc) AICtable # M8 a la plus faible valeur AICc donc le meilleur modèle M2 # est également un bon modèle, mais tous les autres modèles # ne sont pas aussi bons. ++++ Sortie| ++++ Le modèle avec un AICc plus bas a le plus grand pouvoir prédictif considérant les données. Certains disent que si deux modèles sont à plus ou moins 2 unitées d’AICc de différence, leurs pouvoirs prédictifs sont équivalents. Dans notre cas, on peut regarder de plus près M8 et M2, mais tous les autres ont des AICc tellement plus élevés qu’on peut exclure la possibilité qu’ils soient les meilleurs modèles pour nos données. # Une fois que les meilleurs modèles sont sélectionnés il # faut remettre REML=TRUE M8 &lt;- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Fish_Species) + (1 | Lake), data = data, REML = TRUE) M2 &lt;- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Fish_Species) + (1 + Z_Length | Lake), data = data, REML = TRUE) DÉFI 6 Prenez 2 minutes avec votre voisin pour étudier la structure du modèle M2. Comment diffère-t-elle de M8 d’un point de vue biologique? Pourquoi n’est-il pas surprenant que sa valeur de AICc soit la deuxième meilleure? ++++ Réponse défi 6 | M2: La position trophique est une fonction de la longueur. L’intercept et l’effet de la longueur sur la position trophique peuvent varier selon l’espèce de poissons et le lac. M8: La position trophique est une fonction de la longueur. L’intercept et l’effet de la longueur sur la position trophique peut varier selon l’espèce de poissons, mais seulement l’intercept peut varier par lac (et non la pente de la position trophique sur la longueur). Biologiquement parlant, M2 indique que les facteurs intrinsèques des espèces (par exemple les taux de croissance) et des lacs (par exemple, la productivité, la composition de la communauté, etc.) sont à la base de relations différentes entre la position trophique et la longueur (c.-à-d. pentes et intercepts), tandis que M8 indique que les facteurs intrinsèques des espèces seulement sont responsables pour les différentes relations (c.-à-d. pentes) et que, en moyenne, les positions trophiques pourraient être supérieures ou inférieures d’un lac à l’autre (par exemple intercepts). Ces modèles sont très similaires dans leur structure et les unités AIC le suggèrent. La complexité supplémentaire de permettre que les pentes varient par lac dans M2 n’améliore pas le pouvoir prédictif par rapport au modèle M8. ++++ 9.4 Validation du modèle Pour vérifier la supposition d’homogénéité, il faut faire un graphique des valeurs prédites en fonction des valeurs résiduelles. # 3) Vérification des suppositions du modèle #### # Vérification pour M8 A. Vérifiez l&#39;homogénéité : graphique # des valeurs prédites vs valeurs résiduelles E1 &lt;- resid(M8) F1 &lt;- fitted(M8) plot(x = F1, y = E1, xlab = &quot;Fitted Values&quot;, ylab = &quot;Normalized residuals&quot;) abline(h = 0, lty = 2) ++++ Sortie| ++++ L’étendue similaire des résidus suggère que le modèle est adéquat pour bien modéliser nos données. Pour vérifier la supposition d’indépendance, il faut faire un graphique des résidus en fonction de chaque covariable du modèle : # B. Vérifiez l’indépendance : i. graphique des résidus VS # chaque covariable du modèle Longueur corporelle des # poissons plot(x = data$Z_Length, y = E1, xlab = &quot;Z Length&quot;, ylab = &quot;Normalized residuals&quot;) abline(h = 0, lty = 2) # Note: Les regroupements de données sont dus à la structure # des données, où des poissons de seulement 5 classes de # taille (grandes, petites, et trois groupes entre les deux) # étaient capturés. # Espèce boxplot(E1 ~ Fish_Species, ylab = &quot;Normalized residuals&quot;, data = data, xlab = &quot;Species&quot;) abline(h = 0, lty = 2) # Lac boxplot(E1 ~ Lake, ylab = &quot;Normalized residuals&quot;, data = data, xlab = &quot;Lake&quot;) abline(h = 0, lty = 2) ++++ Sortie| ++++ L’étendue similaire au dessus et sous zéro indique qu’il n’y a pas de problème d’indépendance avec cette variable. Idéalement, vous devriez aussi faire l’analyse ci-dessus pour chaque covariable non inclus dans votre modèle. Si vous observez des patrons dans ces graphiques, vous saurez qu’il y a de la variation dans votre jeu de données qui pourrait être expliquée par ces covariables et vous devriez considérer d’inclure ces variables dans votre modèle. Puisque dans notre cas, nous avons inclus toutes les variables mesurées dans notre modèle, nous ne pouvons pas faire cette étape. Il est également important de vérifier la normalité des résidus. Des résidus suivant une distribution normale indiquent que le modèle n’est pas biaisé. # D. Vérifier la normalité : histogramme hist(E1) ++++ Sortie| ++++ 9.5 Interpréter les résultats et les visualiser graphiquement Vous pouvez voir le résumé du modèle à l’aide de : # Vérifiez le résumé du modèle Cela vous permet d&#39;avoir une # idée de la variance expliquée par les différentes # composantes du modèle et la «significativité» des effets # fixes summary(M8) ++++ Sortie| ++++ La sortie est divisée en descriptions des effets aléatoires (ce qui peut varier en fonction de la distribution normale) et les effets fixes (ce que nous estimons comme pour une régression classique) : Pour déterminer si la pente, et donc l’effet de la longueur sur la position trophique, est significativement différente de zéro, vous devez d’abord calculer l’intervalle de confiance (IC) du paramètre de la pente (estimation pour Z_Length dans la section des effets fixes = 0,4223). CI = l’erreur-type de l’estimation x 1,96 plus ou moins l’estimation du paramètre. Si l’IC inclut zéro, la pente n’est pas significativement différente de zéro au seuil de 0,05. DÉFI 7 a) Quelle est la pente et l’intervalle de confiance de la variable Z_Length du le modèle M8? b) Est-ce que la pente de Z_Length est significativement différente de 0? ++++ Réponse défi 7 | a) Quelle est la pente et son intervalle de confiance de la variable Z_Length dans le modèle M8? Pente = 0.4223 limite supérieure de l’IC = 0.4223 + 0.09*1.96 = 0.5987 limite inférieure de l’IC = 0.4223 - 0.09*1.96 = 0.2459 b) Est-ce que la pente de Z_Length est significativement différente de 0? Oui, car l’IC n’inclut pas 0. ++++ Pour mieux visualiser les résultats d’un modèle mixte, les différentes ordonnées à l’origine et pentes générées par le modèle peuvent être représentées dans des figures. Nos coefficients du modèle au niveau du groupe (aka: \"coefs\", dans ce cas seulement un intercept et une pente) se trouvent dans le résumé du modèle dans la section des effets fixes. Les \"coefs\" pour chacun des niveaux du modèle (dans ce cas: Lac et Espèces) qui ont été ajustés à une distribution normale peuvent être obtenus en utilisant la fonction \"coef ()\". Deux façons de visualiser ces données sont : Montrer le modèle au niveau du groupe (toutes les données groupées) Montrer le modèle au niveau de l’espèce ou du lac 1. Pour montrer le modèle au niveau du groupe : Obtenir les paramètres d’intérêts et tracer les données avec le modèle superposée # Visualiser les résultats du modèle #### Il existe plusieurs # façons de visualiser les résultats d&#39;un modèle mixte, qui # font tous appel au coefficients générés par le modèle. La # première étape est d&#39;obtenir les coefficients du modèle # afin de les ajouter aux figures coef(M8) # Maintenant, mettez les coefs dans un tableau pour les # rendre plus faciles à manipuler Lake.coef &lt;- as.data.frame(coef(M8)$Lake) colnames(Lake.coef) &lt;- c(&quot;Intercept&quot;, &quot;Slope&quot;) Species.coef &lt;- as.data.frame(coef(M8)$Fish_Species) colnames(Species.coef) &lt;- c(&quot;Intercept&quot;, &quot;Slope&quot;) # Graphique 1 – toutes les données Graphique qui inclut # toutes les données plot &lt;- ggplot(aes(Z_Length, Z_TP), data = data) Plot_AllData &lt;- plot + geom_point() + xlab(&quot;Length (mm)&quot;) + ylab(&quot;Trophic Position&quot;) + labs(title = &quot;All Data&quot;) + fig # Ajoutez un abline avec l&#39;intercept et la pente de la # relation entre la longueur et la position trophique Notez # que vous pouvez obtenir l’origine et la pente du facteur # fixe directement à partir du résumé du modèle summary(M8) Plot_AllData + geom_abline(intercept = -0.0009059, slope = 0.4222697) ++++ Sortie| ++++ 2. Montrer les modèle au niveau de l’espèce ou du lac: Obtenir les paramètres d’intérêts et tracer les données avec le modèle superposé # Graphique 2 - Par Espèce Colorez les données par espèce Plot_BySpecies &lt;- plot + geom_point(aes(colour = factor(Fish_Species)), size = 4) + xlab(&quot;Length (mm)&quot;) + ylab(&quot;Trophic Position&quot;) + labs(title = &quot;By Species&quot;) + fig # Ajoutez les lignes de régression pour chaque espèce Plot_BySpecies + geom_abline(intercept = Species.coef[1, 1], slope = Species.coef[1, 2], colour = &quot;coral2&quot;) + geom_abline(intercept = Species.coef[2, 1], slope = Species.coef[2, 2], colour = &quot;green4&quot;) + geom_abline(intercept = Species.coef[3, 1], slope = Species.coef[3, 2], colour = &quot;blue1&quot;) # Graphique 3 – Par Lac Colorez les données par lac Plot_ByLake &lt;- plot + geom_point(aes(colour = factor(Lake)), size = 4) + xlab(&quot;Length (mm)&quot;) + ylab(&quot;Trophic Position&quot;) + labs(title = &quot;By Lake&quot;) + fig # Ajouter les lignes de régression avec les intercepts # spécifiques à chaque lac Plot_ByLake + geom_abline(intercept = Lake.coef[1, 1], slope = Lake.coef[1, 2], colour = &quot;coral2&quot;) + geom_abline(intercept = Lake.coef[2, 1], slope = Lake.coef[2, 2], colour = &quot;khaki4&quot;) + geom_abline(intercept = Lake.coef[3, 1], slope = Lake.coef[3, 2], colour = &quot;green4&quot;) + geom_abline(intercept = Lake.coef[4, 1], slope = Lake.coef[4, 2], colour = &quot;darkgoldenrod&quot;) + geom_abline(intercept = Lake.coef[5, 1], slope = Lake.coef[5, 2], colour = &quot;royalblue1&quot;) + geom_abline(intercept = Lake.coef[6, 1], slope = Lake.coef[6, 2], colour = &quot;magenta3&quot;) ++++ Sortie| ++++ 9.6 Exercice de réflexion Les modèles mixtes sont très utiles pour prendre en compte la structure complexe des données en écologie tout en permettant de ne pas perdre beaucoup de degrés de liberté. Nous avons couvert seulement une petite partie de ce que les MLMs peuvent faire. Ci-dessous vous trouverez quelques autres exercices avec des structures de données semblables aux données de l’atelier et deux livres qui détaillent l’utilité des MLMs. DÉFI 8 Situation : Vous avez récolté des estimés de biodiversité dans 1000 quadrats qui sont dans 10 différents sites et qui sont également dans 10 forêts différentes (i.e. 10 quadrats par site et 10 sites par forêt). Vous avez de plus mesuré la productivité dans chaque quadrat. Vous cherchez à savoir si la productivité est un bon prédicteur de la biodiversité. Quel modèle mixte pourriez-vous utiliser pour ce jeu de données? ++++ Réponse défi 8 | &gt;lmer(Bio_Div ~ Productivity + (1|Forest/Site)) &gt;# Ici, les effets aléatoires sont nichés (i.e. sites dans forêt) et non croisés. ++++ DÉFI 9 Situation : Vous avez récolté 200 poissons dans 12 différents sites distribués également dans 4 habitats différents qui se retrouvent dans un même lac. Vous avez mesuré la longueur de chaque poisson et la quantité de mercure dans ses tissus. Vous cherchez surtout à savoir si l’habitat est un bon prédicteur de la concentration en mercure. Quel modèle mixte pourriez-vous utiliser pour ce jeu de données? ++++ Réponse défi 9 | &gt; lmer(Mercury~Length*Habitat_Type+ (1|Site)...) ++++ "],["les-modèles-linéaires-généralisés-mixtes-glmm.html", "Chapitre 10 Les modèles linéaires généralisés mixtes (GLMM)", " Chapitre 10 Les modèles linéaires généralisés mixtes (GLMM) On vient de voir que les variables réponses binaires et d’abondance peuvent être modélisées de façon plus appropriée en laissant tomber la supposition que les résidus doivent suivre une distribution normale en spécifiant une distribution pour les résidus (par exemple Poisson ou binomiale négative). Toutefois, que devrions-nous faire s’il existe une structure nichée dans les données ou des corrélations entre les observations qui causent certaines observations à être plus semblables les unes aux autres que les observations échantillonnées dans différents sites ou points dans le temps ? Comme nous l’avons vu dans l’atelier 6, cette non-indépendance peut être expliquée en ajoutant des termes à effets aléatoires dans le modèle. Rappelez-vous que les intercepts et / ou pentes peuvent varier en fonction des effets aléatoires (facteurs de regroupement) et que l’écart entre ces pentes et / ou intercepts suit une distribution normale. Les effets aléatoires sont également nommés \"estimations de rétrécissement\" parce qu’ils représentent une moyenne pondérée des données et de l’effet global (effet fixe). La quantité de rétrécissement vers l’effet global est plus sévère si la variabilité intra-groupe est large par rapport à la variabilité inter-groupe (i.e. quand nous avons moins confiance en l’estimation aléatoire, en raison de la faible taille de l’échantillon ou d’une haute variabilité intra-groupe, l’estimation est ‘tirée’ vers l’effet fixe). Les propriétés des modèles linéaires mixtes (atelier 6) qui incorporent des effets aléatoires et celles des modèles linéaires généralisés (vu ci-dessus), qui permettent de spécifier une distribution statistique autre que la distribution normale, peuvent être combinées dans le cadre des modèles linéaires mixtes généralisés (GLMMs). L’extension des GLM qui spécifie cette structure supplémentaire suit des étapes similaires à celles présentées dans l’atelier sur les modèles linéaires mixte. Pour donner un bref aperçu des GLMM, nous allons voir une étude de cas présentée par Bolker et al. (2009) et par la suite Bolker et al. (2011) où les observations échantillonnées dans différentes populations ont créé une structure (ou manque d’indépendance) dans le jeu de données. Plus précisément, les auteurs ont évalué comment l’abondance d’Arabidopsis thaliana (arabette des dames) varie en fonction de variables environnementales (disponibilité d’éléments nutritifs et herbivorie) et en fonction de leur population d’origine et / ou de leur génotype. En utilisant l’ensemble des données d’Arabidopsis, nous allons maintenant examiner l’effet des niveaux de nutriments, d’herbivorie et leur interaction (effets fixes) sur la production de fruits d’Arabidopsis thaliana et la variabilité de ces relations à travers différentes populations et / ou génotypes (effets aléatoires). # Chargez et affichez le jeu de données dat.tf &lt;- read.csv(&quot;Banta_TotalFruits.csv&quot;) str(dat.tf) # X numéro d&#39;observation reg facteur pour l&#39;une des trois # régions; Pays-Bas, l&#39;Espagne ou la Suède popu facteur avec # un niveau pour chaque population (effet aléatoire) gen # facteur avec un niveau pour chaque génotype (effet # aléatoire) rack facteur de nuisance pour l&#39;un des deux # racks placés dans la serre nutrient facteur à deux niveaux # précisant une faible (valeur = 1) ou haute (valeur = 8) # concentration de nutriments (effet fixe) amd facteur à deux # niveaux précisant l&#39;absence ou la présence d&#39;herbivorie # (lésions sur le méristème apical) (effet fixe) status # facteur de nuisance pour la méthode de germination # total.fruits variable réponse; nombre entier indiquant le # nombre de fruits par plante # 2-3 génotypes imbriqués dans chacune des neuf populations table(dat.tf$popu, dat.tf$gen) # Entretien : changer nombres entiers en facteurs, rajuster # les niveaux d&#39;herbivorie (amd) et renommer les niveaux de # nutriments dat.tf &lt;- transform(dat.tf, X = factor(X), gen = factor(gen), rack = factor(rack), amd = factor(amd, levels = c(&quot;unclipped&quot;, &quot;clipped&quot;)), nutrient = factor(nutrient, label = c(&quot;Low&quot;, &quot;High&quot;))) # Installer / charger les librairies if (!require(lme4)) { install.packages(&quot;lme4&quot;) } require(lme4) if (!require(coefplot2)) { install.packages(&quot;coefplot2&quot;, repos = &quot;http://www.math.mcmaster.ca/bolker/R&quot;, type = &quot;source&quot;) } require(coefplot2) if (!require(reshape)) { install.packages(&quot;reshape&quot;) } require(reshape) if (!require(ggplot2)) { install.packages(&quot;ggplot2&quot;) } require(ggplot2) if (!require(plyr)) { install.packages(&quot;plyr&quot;) } require(plyr) if (!require(gridExtra)) { install.packages(&quot;gridExtra&quot;) } require(gridExtra) if (!require(emdbook)) { install.packages(&quot;emdbook&quot;) } require(emdbook) source(&quot;glmm_funs.R&quot;) "],["la-structure-du-jeu-de-données.html", "Chapitre 11 La structure du jeu de données 11.1 Un GLMM avec une distribution de Poisson 11.2 Un GLMM avec un distribution binomiale négative 11.3 Un GLMM avec une distribution \"Poisson-lognormal\"", " Chapitre 11 La structure du jeu de données Lorsque nous examinons l’interaction entre les éléments nutritifs et l’herbivorie (clipping) à travers les neuf populations différentes, nous constatons que le nombre de fruits est toujours plus élevé dans le traitement élevé (High) en nutriments. L’effet de clipping est plus faible, même que dans certaines populations nous notons une pente négative. ggplot(dat.tf,aes(x=amd,y=log(total.fruits+1),colour=nutrient)) + geom_point() + stat_summary(aes(x= as.numeric(amd)),fun.y=mean,geom=&quot;line&quot;) + theme_bw() + theme(panel.margin=unit(0,&quot;lines&quot;)) + scale_color_manual(values=c(&quot;#3B9AB2&quot;,&quot;#F21A00&quot;)) + # de la palette Wes Anderson Zissou facet_wrap(~popu) Un graphique similaire peut être fait pour les 24 génotypes différents (en changeant facet_wrap(~gen)). ==== Choisir une distribution pour les résidus ==== La variable réponse représente des données d’occurrences, donc nous devons choisir une distribution de Poisson pour modéliser cette variable. Rappelez-vous qu’une propriété importante de la distribution de Poisson est que la variance est égale à la moyenne. Cependant, comme nous le verrons ci-dessous, la variance de chaque groupe augmente beaucoup plus rapidement que la moyenne attendue sous la distribution de Poisson. # Créez de nouvelles variables qui représentent toutes les # combinaisons de nutriments x facteur clipping x facteur # aléatoire dat.tf &lt;- within(dat.tf, { # génotype x nutriments x clipping gna &lt;- interaction(gen, nutrient, amd) gna &lt;- reorder(gna, total.fruits, mean) # population x nutriments x clipping pna &lt;- interaction(popu, nutrient, amd) pna &lt;- reorder(pna, total.fruits, mean) }) # Boîte à moustaches du total de fruits vs. nouvelle variable # (génotype x nutriments x clipping) ggplot(data = dat.tf, aes(factor(x = gna), y = log(total.fruits + 1))) + geom_boxplot(colour = &quot;skyblue2&quot;, outlier.shape = 21, outlier.colour = &quot;skyblue2&quot;) + theme_bw() + theme(axis.text.x = element_text(angle = 90)) + stat_summary(fun.y = mean, geom = &quot;point&quot;, colour = &quot;red&quot;) # Boîte à moustaches du total des fruits vs. nouvelle # variable (population x nutriments x clipping) ggplot(data = dat.tf, aes(factor(x = pna), y = log(total.fruits + 1))) + geom_boxplot(colour = &quot;skyblue2&quot;, outlier.shape = 21, outlier.colour = &quot;skyblue2&quot;) + theme_bw() + theme(axis.text.x = element_text(angle = 90)) + stat_summary(fun.y = mean, geom = &quot;point&quot;, colour = &quot;red&quot;) Tel qu’illustré ci-dessus, il existe une importante hétérogénéité parmi la variance de chaque groupe même lorsque la variable réponse est transformée. Nous notons également que certains groupes ont une moyenne et variance de zéro. Pour identifier __la famille de distribution la plus appropriée __, nous pouvons examiner un graphique de diagnostic de la variance de chaque groupe par rapport à leurs moyennes. Nous présentons un exemple ci-dessous pour le regroupement par génotype x nutriments x herbivore (clipping). Si nous observons une relation linéaire entre la variance et la moyenne avec une pente = 1, une famille de Poisson serait appropriée, Si nous observons une relation moyenne-variance linéaire avec une pente&gt; 1 (c. Var = φµ où φ &gt; 1), la famille quasi-Poisson (tel que présenté ci-dessus) doit être utilisée, Enfin, une relation quadratique entre la variance et la moyenne (c. Var = µ(1 + α ) ou µ(1 + µ/k)), est caractéristique des données surdispersées résultant d’une hétérogénéité sous-jacente entre les échantillons. Dans ce cas, la distribution binomiale négative (Poisson-gamma) serait plus appropriée. En examinant la figure ci-dessus, nous constatons qu’une distribution quasi-Poisson linéaire peut être meilleure que la distribution binomiale négative, mais nous aurions besoin de modélisation supplémentaire pour le confirmer. 11.1 Un GLMM avec une distribution de Poisson On crée un GLMM en utilisant la fonction glmer() de la librairie lme4. On spécifie le modèle avec un intercepte aléatoire pour les facteurs génotype et population. Nous incluons les variables de nuisance (rack et la méthode de germination) comme effets fixes. Compte tenu de la relation entre la moyenne et la variance que nous avons observée ci-dessus, nous aurons probablement besoin d’un modèle avec surdispersion, mais nous allons commencer par un modèle avec une distribution de Poisson. mp1 &lt;- glmer(total.fruits ~ nutrient * amd + rack + status + (1 | popu) + (1 | gen), data = dat.tf, family = &quot;poisson&quot;) Nous pouvons vérifier la surdispersion en utilisant la fonction overdisp_fun fournie par Bolker et al. (2011) qui divise les résidus de Pearson par les degrés de liberté des résidus et vérifie si les valeurs diffèrent de façon significative (i.e. si le rapport entre la déviance et les degrés de liberté est significativement différent de 1). Une faible valeur de p indique que les données sont surdispersées (i.e. le ratio est significativement différent de 1). # Surdispersion? overdisp_fun(mp1) # On peut aussi l’estimer en divisant la déviance résiduelle # par les degrés de liberté des résidus summary(mp1) # déviance résiduelle = 18253.7 and dl resid = 616 Le ratio est &gt;&gt; 1, donc comme on s’y attendait, nous devons utiliser une distribution différente où la variance augmente plus rapidement que la moyenne, tels que la distribution binomiale négative. 11.2 Un GLMM avec un distribution binomiale négative Rappelez-vous que la distribution binomiale négative (ou Poisson-gamma) satisfait la supposition que la variance est ** proportionnelle au carré de la moyenne **. # Note : Ce modèle converge si vous utilisez la version 3.0.2 # de R, mais peut ne pas converger avec des versions plus # récentes. Si vous avez des problèmes de convergence, # essayez le code suivant avec la version 3.0.2. mnb1 &lt;- glmer.nb(total.fruits ~ nutrient * amd + rack + status + (1 | popu) + (1 | gen), data = dat.tf, control = glmerControl(optimizer = &quot;bobyqa&quot;)) # Le nouvel argument «control», bien qu’au-delà de la portée # de cet atelier, spécifie la façon dont nous optimisons les # valeurs des paramètres (c. en prenant la dérivée d&#39;une # fonction ou en procédant par itération). Si ce n’est pas # possible de prendre la dérivée de la fonction, un # algorithme itératif comme bobyqa (Bound Optimization BY # Quadratic Approximation) est utilisé. # Surdispersion? overdisp_fun(mnb1) Le rapport est maintenant beaucoup plus près de 1 (bien que la valeur p est encore inférieur à 0,05). 11.3 Un GLMM avec une distribution \"Poisson-lognormal\" Une autre option que nous n’avons pas encore décrit est la distribution Poisson-lognormal. Cette approche aborde le problème de la surdispersion en appliquant un effet aléatoire au niveau de l’observation (voir Harrison (2014)), et modèle la variation Poisson supplémentaire de la variable de réponse en utilisant un effet aléatoire avec un niveau de chaque observation unique. Un modèle Poisson-lognormal peut être construit en modélisant les εi avec une distribution a priori lognormal. Une distribution Poisson-lognormal avec une moyenne µ et une variance a priori lognormal σ2 est donné par : var(y) = µ + µ2 \\[exp(σ^2^) - 1\\] En revanche, nous avons vu que la distribution binomiale négative (Poisson-gamma) était donné par: var(y) = µ + µ2/k En générale, la variance σ2 dans la distribution Poisson-lognormal dépendra du niveau de regroupement que nous sélectionnons (i.e. au niveau individuel, génotype ou de la population). Donc, le modèle de Poisson-lognormal nous permet d’assigner l’agrégation observée à différentes sources d’hétérogénéité. Ici, afin d’évaluer un effet aléatoire au niveau de l’observation, nous allons l’évaluer au niveau individuel. mpl1 &lt;- glmer(total.fruits ~ nutrient * amd + rack + status + (1 | X) + (1 | popu) + (1 | gen), data = dat.tf, family = &quot;poisson&quot;, control = glmerControl(optimizer = &quot;bobyqa&quot;)) overdisp_fun(mpl1) Nous avons réussi! Le rapport entre la déviance et les degrés de liberté est maintenant conforme avec notre critère (en fait, il est plus //petit // 1). "],["intercepts-aléatoires.html", "Chapitre 12 Intercepts aléatoires 12.1 Représentation graphique des paramètres du modèle 12.2 Graphiques des intercepts aléatoires 12.3 Pentes aléatoires", " Chapitre 12 Intercepts aléatoires Maintenant que nous avons la distribution d’erreur appropriée, nous pouvons tester l’importance des interceptes aléatoires (pour population et génotype) en comparant des modèles nichés avec et sans les effets aléatoires d’intérêt en utilisant soit: l’approche théorique d’information (tel que le Critère d’Information d’Akaike; AIC), qui, comme nous l’avons vu dans l’atelier 6 examine plusieurs hypothèses concurrentes (modèles) simultanément pour identifier le modèle avec le pouvoir prédictif le plus élevé compte tenu des données. Nous allons encore une fois utiliser le AICc pour corriger les petites tailles d’échantillon. l’approche fréquentiste (test d’hypothèse nulle traditionnelle), où deux modèles nichés sont comparés en utilisant le tests de rapport de vraisemblance de la fonction anova(). Il est important de noter qu’avec cette approche, nous testons une hypothèse nulle d’une variance de zéro, mais étant donné que nous ne pouvons pas avoir un écart négatif, nous testons le paramètre à la limite de sa région réalisable. Par conséquent, la valeur de p rapporté est environ le double de ce qu’elle devrait être (c. nous avons tronquée la moitié des valeurs possibles ; celles qui tombent en dessous de 0). summary(mpl1)$varcor # popu seulement mpl1.popu &lt;- glmer(total.fruits ~ nutrient*amd + rack + status + (1|X) + (1|popu), data=dat.tf, family=&quot;poisson&quot;, control=glmerControl(optimizer=&quot;bobyqa&quot;)) # gen seulement mpl1.gen &lt;-glmer(total.fruits ~ nutrient*amd + rack + status + (1|X) + (1|gen), data=dat.tf, family=&quot;poisson&quot;, control=glmerControl(optimizer=&quot;bobyqa&quot;)) # Approche AICc ICtab(mpl1, mpl1.popu, mpl1.gen, type = c(&quot;AICc&quot;)) # dAICc df # mpl1 0.0 10 # mpl1.popu 2.0 9 # mpl1.gen 16.1 9 # Approche fréquentiste (Likelihood Ratio Test) anova(mpl1,mpl1.popu) # Data: dat.tf # Df AIC BIC logLik deviance Chisq Chi Df Pr(&gt;Chisq) # mpl1.popu 9 5017.4 5057.4 -2499.7 4999.4 # mpl1 10 5015.4 5059.8 -2497.7 4995.4 4.0639 1 0.04381 * # --- # Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 anova(mpl1,mpl1.gen) # Df AIC BIC logLik deviance Chisq Chi Df Pr(&gt;Chisq) # mpl1.gen 9 5031.5 5071.5 -2506.8 5013.5 # mpl1 10 5015.4 5059.8 -2497.7 4995.4 18.177 1 2.014e-05 *** # --- # Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 Notez que le modèle sans l’intercept aléatoire pour génotype est à moins de deux unités AICc du modèle complet, ce qui indique que les deux modèles sont tout aussi plausibles (i.e. peu de soutien pour inclure un intercept aléatoire pour le génotype). Toutefois, lorsque nous utilisons la comparaison de vraisemblance de modèles nichés (anova()), et corrigeons pour les valeurs p gonflés par un facteur de 2, nous trouvons que dans les deux cas, p &lt;0,05 et donc le modèle avec les deux effets aléatoires (mpl1) est sélectionné. 12.1 Représentation graphique des paramètres du modèle Une représentation graphique des paramètres du modèle peut être obtenue en utilisant la fonction coefplot2. Par exemple, pour afficher les paramètres de variance de nos trois intercepts aléatoires: # Paramètres de la variance coefplot2(mpl1,ptype=&quot;vcov&quot;,intercept=TRUE,main=&quot;Random effect variance&quot;) # Effets fixes coefplot2(mpl1,intercept=TRUE,main=&quot;Fixed effect coefficient&quot;) Notez que les barres d’erreur ne sont visibles que pour les effets fixes parce glmer ne nous donne pas d’informations sur l’incertitude des paramètres de variance. 12.2 Graphiques des intercepts aléatoires Nous pouvons également extraire les prédictions des effets aléatoires en utilisant la fonction ranef et les tracer en utilisant la fonction dotplot, qui crée un graphique à deux facettes pour chaque effet aléatoire (popu et gen). Notez : la fonction grid.arrange est utilisée pour supprimer l’effet aléatoire au niveau de l’observation (i.e. (1 | X)). pp &lt;- list(layout.widths=list(left.padding=0, right.padding=0), layout.heights=list(top.padding=0, bottom.padding=0)) r2 &lt;- ranef(mpl1,condVar=TRUE) d2 &lt;- dotplot(r2, par.settings=pp) grid.arrange(d2$gen,d2$popu,nrow=1) Le graphique indique un peu de variabilité régionale parmi les populations où les populations espagnoles (SP) ont des valeurs plus élevées que les populations suédoises (SW) et néerlandais (NL). La différence entre les génotypes semble largement induite par le génotype 34. 12.3 Pentes aléatoires ++++ Section bonus: Pentes aléatoires| Notez: Pour cet ensemble de données, nous ne pouvons pas tester les pentes aléatoires, car lorsque les pentes aléatoires sont inclus dans le modèle, on obtient une forte corrélation entre les intercepts et pentes aléatoires. Ces fortes corrélations peuvent être dues à une \"sur-paramétrisation\" de notre modèle. Donc, bien qu’il pourrait y avoir une variation de l’effet nutriments ou herbivorie au niveau du génotype ou de la population (et bien que cette variation peut être ce qui nous intéresse le plus), il n’y a tout simplement pas suffisamment de données pour tester ces effets avec confiance. Regardons un exemple avec une pente aléatoire pour clipping: # Poisson-lognormal avec pentes aléatoires pour popu et amd mpl2 &lt;- glmer(total.fruits ~ nutrient * amd + rack + status + (1 | X) + (amd | popu) + (amd | gen), data = dat.tf, family = &quot;poisson&quot;, control = glmerControl(optimizer = &quot;bobyqa&quot;)) Examinons les coefficients de variance en utilisant summary du modèle. Nous pourrions aussi examiner la matrice de corrélation entre les intercepts et pentes aléatoires. Une troisième option est d’utiliser la fonction printvc qui montre les matrices de variance-covariance avec un signe égal ( = ) à côté de toute composante de covariance avec une forte corrélation. summary(mpl2) # option 1 attr(VarCorr(mpl2)$gen, &quot;correlation&quot;) # option 2 printvc(mpl2) # option 3 Notez la corrélation parfaite entre (Intercept) et amdclipped (pente). ++++ "],["modèle-final.html", "Chapitre 13 Modèle final", " Chapitre 13 Modèle final Nous terminons cette section sur les GLMMs avec l’évaluation des effets fixes. Nous décrivons d’abord les modèles potentiels et les comparons en utilisant AICc. mpl2 &lt;- update(mpl1, . ~ . - rack) # modèle sans rack mpl3 &lt;- update(mpl1, . ~ . - status) # modèle sans status mpl4 &lt;- update(mpl1, . ~ . - amd:nutrient) # modèle sans l’ interaction amd:nutrient ICtab(mpl1,mpl2,mpl3,mpl4, type = c(&quot;AICc&quot;)) Nous pouvons aussi utiliser les fonctions drop1 et dfun, où dfun convertit les valeurs AIC retournées par drop1 en valeurs ΔAIC (produisant un tableau comparable à ICtab ci-dessus). (dd_LRT &lt;- drop1(mpl1,test=&quot;Chisq&quot;)) # Model: # total.fruits ~ nutrient * amd + rack + status + (1 | X) + (1 | popu) + (1 | gen) # Df AIC LRT Pr(Chi) # &lt;none&gt; 5015.4 # rack 1 5070.5 57.083 4.179e-14 *** # status 2 5017.0 5.612 0.06044 . # nutrient:amd 1 5016.8 3.444 0.06349 . # --- # Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 (dd_AIC &lt;- dfun(drop1(mpl1))) # Df dAIC # &lt;none&gt; 0.000 # rack 1 55.083 # status 2 1.612 # nutrient:amd 1 1.444 Il y a un fort effet de rack (un changement de AIC de 55 si on enlève cette variable), alors que les effets de « status » et de l’interaction sont faibles (différence AIC moins de 2). Nous pouvons donc commencer par enlever l’interaction non significative afin de tester les effets principaux de nutriments et d’herviborie (clipping). mpl2 &lt;- update(mpl1, . ~ . - and:nutrient) # Avec AICc: mpl3 &lt;- update(mpl2, . ~ . - rack) # modèle sans rack ou l’interaction mpl4 &lt;- update(mpl2, . ~ . - status) # modèle sans status ou l’interaction mpl5 &lt;- update(mpl2, . ~ . - nutrient) # modèle sans nutrient ou l’interaction mpl6 &lt;- update(mpl2, . ~ . - amd) # modèle sans clipping ou l’interaction ICtab(mpl2,mpl3,mpl4,mpl5,mpl6, type = c(&quot;AICc&quot;)) # dAICc df # mpl2 0.0 9 # mpl4 1.2 7 # mpl6 10.2 8 # mpl3 54.2 8 # mpl5 135.6 8 # Ou, avec drop1: (dd_LRT2 &lt;- drop1(mpl2,test=&quot;Chisq&quot;)) # Model: # total.fruits ~ nutrient + amd + rack + status + (1 | X) + (1 | popu) + (1 | gen) # Df AIC LRT Pr(Chi) # &lt;none&gt; 5016.8 # nutrient 1 5152.5 137.688 &lt; 2.2e-16 *** # amd 1 5027.0 12.218 0.0004734 *** # rack 1 5071.0 56.231 6.443e-14 *** # status 2 5018.1 5.286 0.0711639 . # --- # Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 (dd_AIC2 &lt;- dfun(drop1(mpl2))) # Df dAIC # &lt;none&gt; 0.000 # nutrient 1 135.688 # amd 1 10.218 # rack 1 54.231 # status 2 1.286 summary(mpl2) Les effets de nutriments et d’herbivorie sont forts (grand changement d’AIC de 135,6 (mpl5) et 10,2 (mpl6) si nutriments ou clipping sont supprimés respectivement). Notre modèle final inclut l’effet fixe des nutriments (fortement positif) et l’effet fixe d’herbivorie (négatifs), la variable nuisance de rack, l’effet aléatoire au niveau de l’observation (1 | X) pour tenir compte de la surdispersion et la variation de fruits par population et // génotype //. ** DÉFI 10 ** En utilisant l’ensemble de données inverts (temps de développement larvaire (PLD) de 74 espèces d’invertébrés et vertébrés marins élevés à différentes températures et temps), répondez aux questions suivantes: - Quel est l&#39;effet du type d&#39;alimentation et du climat (effets fixes) sur PLD (variable réponse)? - Est-ce que cette relation varie selon les taxons (effets aléatoires)? - Quelle est la meilleure famille de distribution pour ces données? - Une fois que vous avez déterminé la meilleure famille de distribution, réévaluez vos effets aléatoires et fixes. ++++ Défi 10: Solution 1| # Charger les données inverts &lt;- read.csv(&quot;inverts.csv&quot;) str(inverts) mlm1 &lt;- lm(PLD ~ temp * feeding.type, data = inverts) anova(mlm1) # toutes les variables sont significatives ++++ ++++ Défi 10: Solution 2| # Réponse vs effets fixes ggplot(inverts,aes(x=temp,y=log(PLD+1),colour=feeding.type)) + geom_point() + stat_summary(aes(x=as.numeric(temp)),fun.y=mean,geom=&quot;line&quot;) + theme_bw() + scale_color_manual(values=c(&quot;#3B9AB2&quot;,&quot;#F21A00&quot;)) + # from Wes Anderson Zissou palette facet_wrap(~taxon) # Créer de nouvelles variables qui représentent toutes les combinaisons de feeding type x temp x taxa # (effets aléatoires) inverts &lt;- within(inverts, { # taxon x feeding.type tft &lt;- interaction(taxon,feeding.type,temp) tft &lt;- reorder(tft, PLD, mean) }) # Boîte à moustaches total des fruits vs nouvelle variable (feeding type x temp x taxa) ggplot(data = inverts, aes(factor(x = tft),y = log(PLD))) + geom_boxplot(colour = &quot;skyblue2&quot;, outlier.shape = 21, outlier.colour = &quot;skyblue2&quot;) + theme_bw() + theme(axis.text.x=element_text(angle=90)) + stat_summary(fun.y=mean, geom=&quot;point&quot;, colour = &quot;red&quot;) ++++ ++++ Défi 10: Solution 3| grpVars &lt;- tapply(inverts$PLD, inverts$tft, var) summary(grpVars) grpMeans &lt;- tapply(inverts$PLD, inverts$tft, mean) summary(grpMeans) # Quasi-Poisson lm1 &lt;- lm(grpVars ~ grpMeans - 1) phi.fit &lt;- coef(lm1) # Le -1 spécifie un modèle avec l&#39;intercept fixer à zéro # Binomial négative lm2 &lt;- lm(grpVars ~ I(grpMeans^2) + offset(grpMeans) - 1) k.fit &lt;- 1/coef(lm2) # Offset () est utilisé pour fixer la moyenne de chaque # groupe à 1 # Ajustement Loess non-paramétrique Lfit &lt;- loess(grpVars ~ grpMeans) plot(grpVars ~ grpMeans, xlab = &quot;group means&quot;, ylab = &quot;group variances&quot;) abline(a = 0, b = 1, lty = 2) text(60, 200, &quot;Poisson&quot;) curve(phi.fit * x, col = 2, add = TRUE) # bquote()est utilisé pour remplacer des valeurs numériques # dans les équations avec des symboles text(60, 800, bquote(paste(&quot;QP: &quot;, sigma^2 == .(round(phi.fit, 1)) * mu)), col = 2) curve(x * (1 + x/k.fit), col = 4, add = TRUE) text(60, 1600, paste(&quot;NB: k=&quot;, round(k.fit, 1), sep = &quot;&quot;), col = 4) mvec &lt;- 0:120 lines(mvec, predict(Lfit, mvec), col = 5) text(50, 1300, &quot;loess&quot;, col = 5) # Poisson GLMM mp1 &lt;- glmer(PLD ~ temp * feeding.type + (1 | taxon), data = inverts, family = &quot;poisson&quot;) overdisp_fun(mp1) # rapport est significativement &gt; 1 # NB GLMM mnb1 &lt;- glmer.nb(PLD ~ temp * feeding.type + (1 | taxon), data = inverts) overdisp_fun(mnb1) # Semble bon! ++++ ++++ Défi 10: Solution 4| # Re-évaluer les intercepts aléatoires summary(mnb1)$varcor mnb1.taxless &lt;- glm.nb(PLD ~ temp * feeding.type, data = inverts) # Ici, parce que nous comparons un glmer avec un glm, nous # devons faire quelque chose de différent que anova(). Pour # tester l&#39;importance de l’intercept aléatoire, nous allons # comparer la vraisemblance de chaque modèle : NL1 &lt;- -logLik(mnb1) NL0 &lt;- -logLik(mnb1.taxless) devdiff &lt;- 2 * (NL0 - NL1) dfdiff &lt;- attr(NL1, &quot;df&quot;) - attr(NL0, &quot;df&quot;) pchisq(devdiff, dfdiff, lower.tail = FALSE) # Nous pourrions aussi comparer l&#39;AIC du modèle avec (mnb1) # et sans (mnb1.taxless) effets aléatoires avec la fonction # AICtab() AICtab(mnb1, mnb1.taxless) # Changement important du AIC si nous supprimons l’intercept # aléatoire. Donc, ça vaut la peine de garder cet effet. # Graphique diagnostic locscaleplot(mnb1) # Graphique des paramètres de variance coefplot2(mnb1, ptype = &quot;vcov&quot;, intercept = TRUE, main = &quot;Random effect variance&quot;) # Graphique des effets fixes coefplot2(mnb1, intercept = TRUE, main = &quot;Fixed effect coefficient&quot;) # Graphique des intercepts aléatoires pp &lt;- list(layout.widths = list(left.padding = 0, right.padding = 0)) r2 &lt;- ranef(mnb1, condVar = TRUE) d2 &lt;- dotplot(r2, par.settings = pp) grid.arrange(d2$taxon, nrow = 1) # Évaluer pentes aléatoires mnb2 &lt;- glmer.nb(PLD ~ temp * feeding.type + (PLD | taxon), data = inverts) # Examiner composant de variance-covariance summary(mnb2) # option 1 attr(VarCorr(mnb2)$taxon, &quot;correlation&quot;) # option 2 printvc(mnb2) # option 3 # Forte corrélation entre les effets aléatoires -&gt; pas assez # de puissance pour tester pentes aléatoires # Re-évaluer les effets fixes Remarque : pour utiliser la # fonction de drop1 nous devons spécifier le paramètre thêta # et exécuter le modèle NB avec glmer : theta.mnb1 &lt;- theta.md(inverts$PLD, fitted(mnb1), dfr = df.residual(mnb1)) mnb1 &lt;- glmer(PLD ~ temp * feeding.type + (1 | taxon), data = inverts, family = negative.binomial(theta = theta.mnb1)) (dd_LRT &lt;- drop1(mnb1, test = &quot;Chisq&quot;)) (dd_AIC &lt;- dfun(drop1(mnb1))) # Lorsque l’interaction feeding.type x température est # supprimée, dAIC change de plus de 2 unité → suggère de # garder l&#39;interaction dans le modèle ++++ "],["summary.html", "Chapitre 14 Summary", " Chapitre 14 Summary -Add- "],["ressources-additionnelles.html", "Chapitre 15 Ressources additionnelles 15.1 Livres de référence pour les MLMs 15.2 Ressources pour les GLMMs", " Chapitre 15 Ressources additionnelles 15.1 Livres de référence pour les MLMs Gelman, A., and Hill, J. (2006). Data analysis using regression and multilevel/hierarchical models (Cambridge University Press). Zuur, A., Ieno, E.N., Walker, N., Saveliev, A.A., and Smith, G.M. (2009). Mixed effects models and extensions in ecology with R (Springer). 15.2 Ressources pour les GLMMs Livres B. Bolker (2009) Ecological Models and Data in R. Princeton University Press. A. Zuur et al. (2009) Mixed Effects Models and Extensions in Ecology with R. Springer. **Articles ** Harrison, X. A., L. Donaldson, M. E. Correa-Cano, J. Evans, D. N. Fisher, C. E. D. Goodwin, B. S. Robinson, D. J. Hodgson, and R. Inger. 2018. A brief introduction to mixed effects modelling and multi-model inference in ecology. PeerJ 6:e4794–32. Sites web GLMM for ecologists: Un site web très complet et avec une section Questions-Réponses pertinente ! "],["references.html", "Chapitre 16 References", " Chapitre 16 References "]]
