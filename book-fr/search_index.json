[["index.html", "Atelier 9 : Analyses multivariées en R Série d’ateliers R du CSBQ Préface 0.1 Code de conduite 0.2 Contributeurs et contributrices 0.3 Contribuez à la série!", " Atelier 9 : Analyses multivariées en R Série d’ateliers R du CSBQ Développé et entretenu par les contributeurs et les contributrices de la Série d’ateliers R du CSBQ1. 2021-02-22 22:46:01 Préface La Série d’ateliers R du CSBQ est une série de 10 ateliers qui guide les participants à travers les étapes nécessaires à l’utilisation de R pour un large éventail d’analyses statistiques pertinentes pour la recherche en biologie et en écologie. Ces ateliers en accès libre ont été créés par des membres du CSBQ, à la fois pour les membres du CSBQ et pour la communauté au sens large. Le contenu de cet atelier a été revu par plusieurs membres du CSBQ. Si vous souhaitez suggérer des modifications, veuillez contacter les coordinateurs de la série actuelle, dont la liste figure sur la page principale de Github 0.1 Code de conduite La Série d’ateliers R du CSBQ et le Symposium R du CSBQ sont des lieux dédiés à fournir un environnement accueillant et favorable à toutes les personnes, indépendamment de leurs origines ou de leur identité. Les participants, les présentateurs et les organisateurs de la série d’ateliers et d’autres activités connexes acceptent le présent code de conduite lorsqu’ils assistent à des activités liées aux ateliers. Nous ne tolérons pas les comportements irrespectueux ou qui excluent, intimident ou gênent les autres. Nous ne tolérons pas la discrimination ou le harcèlement fondés sur des caractéristiques telles que, mais sans s’y limiter, l’identité et l’expression du genre, l’orientation sexuelle, le handicap, l’apparence physique, la taille du corps, la citoyenneté, la nationalité, les origines ethniques ou sociales, la grossesse, le statut familial, les informations génétiques, la religion ou les convictions (ou l’absence de celles-ci), l’appartenance à une minorité nationale, la propriété, l’âge, l’éducation, le statut socio-économique, les choix techniques et le niveau d’expérience. Il s’applique à tous les espaces gérés par l’atelier ou affiliés à celui-ci, y compris, mais sans s’y limiter, les ateliers, les listes de diffusion et les forums en ligne tels que GitHub, Slack et Twitter. 0.1.1 Comportement attendu Tous les participants sont tenus de faire preuve de respect et de courtoisie envers les autres. Toutes les interactions doivent être professionnelles, quelle que soit la plateforme utilisée : en ligne ou en personne. Afin de favoriser un environnement d’apprentissage positif et professionnel, nous encourageons les types de comportements suivants dans tous les événements et plates-formes des ateliers : Utiliser un langage accueillant et inclusif ; Respecter les différents points de vue et expériences ; Accepter avec grâce les critiques constructives ; Se concentrer sur ce qui est le mieux pour la communauté ; Faire preuve de courtoisie et de respect envers les autres membres de la communauté. 0.1.2 Comportements inacceptables Voici quelques exemples de comportements inacceptables de la part des participants à tout événement ou plateforme d’atelier : les commentaires écrits ou verbaux qui ont pour effet d’exclure des personnes sur la base de leur appartenance à un groupe spécifique ; faire craindre à quelqu’un pour sa sécurité, par exemple en le harcelant ou en l’intimidant ; des menaces ou des propos violents dirigés contre une autre personne ; l’affichage d’images sexuelles ou violentes ; l’attention sexuelle non désirée ; les contacts physiques non consensuels ou non désirés ; des insultes ou des rabais ; les blagues sexistes, racistes, homophobes, transphobes, incapables ou d’exclusion ; l’incitation à la violence, au suicide ou à l’automutilation ; la poursuite de l’interaction (y compris la photographie ou l’enregistrement) avec une personne après qu’on - lui a demandé d’arrêter ; la publication d’une communication privée sans consentement. 0.2 Contributeurs et contributrices Développé à l’origine par : A contribué à modifier la présentation : Contribution avec des changements à la documentation écrite : Contribution en signalant des problèmes et en suggérant des modifications : 0.3 Contribuez à la série! En construction. La Série d’ateliers R du CSBQ fait partie du Centre de la science de la biodiversité du Québec, et est maintenue par les coordonnateurs et les coordonnatrices de la série, et les membres étudiants diplômés, postdoctoraux et professionnels de la recherche. La liste des contributeurs et des contributrices de cet atelier sont accessiblesici↩︎ "],["objectifs-dapprentissage.html", "Chapitre 1 Objectifs d’apprentissage", " Chapitre 1 Objectifs d’apprentissage Résumé: Dans cet atelier, vous apprendrez les bases des analyses multivariées qui vous permettront de révéler les patrons de diversité dans vos données de communautés. Vous apprendrez d’abord comment choisir les mesures de distance et les transformations appropriées pour ensuite réaliser plusieurs types d’analyses multivariées: des groupements, des Analyses en Composantes Principales (PCA), des Analyses de Correspondance (CA), des Analyses en Coordonnées Principales (PCoA) et des Positionnements Multidimensionnels Non-Métriques (NMDS). "],["préparez-vous-pour-cet-atelier.html", "Chapitre 2 Préparez-vous pour cet atelier", " Chapitre 2 Préparez-vous pour cet atelier Téléchargez le script R et les données pour cet atelier: script R DoubsEnv DoubsSpe Coldiss (fonction R) Télechargez les paquets R pour cet atelier: vegan gclus ape install.packages(&quot;vegan&quot;) install.packages(&quot;gclus&quot;) install.packages(&quot;ape&quot;) library(vegan) library(gclus) library(ape) source(file.choose()) #coldiss.R "],["quest-ce-que-lordination.html", "Chapitre 3 Qu’est-ce que l’ordination?", " Chapitre 3 Qu’est-ce que l’ordination? L’ordination est un ensemble de méthodes pour décrire des échantillons dans de multiples dimensions (Clarke et Warwick 2011). Les méthodes d’ordination sont donc très utiles pour simplifier et interpréter des données multivariées. Les écologistes parlent souvent de \"faire une PCA\" face à des données multidimensionnelles complexes et désordonnées. Programmer des méthodes d’ordination à partir de R est relativement simple. L’interprétation des analyses d’ordination peut par contre être plus difficile, surtout si vous n’êtes pas sûr des questions biologiques que vous souhaitez explorer avec la méthode d’ordination que vous utilisez. Un examen attentif des objectifs de ces méthodes et de leur cadre d’application est nécessaire pour obtenir de bons résultats ! Lorsque vous utilisez une méthode d’ordination, un ensemble de variables est utilisé pour ordonner des échantillons (objets, sites, etc.) le long d’axes principaux représentant des combinaison de variables (Gotelli et Ellison 2004). L’ordination permet donc de réduire ou de simplifier les données en créant de nouveaux axes intégrant la majeure partie de la variation présentes dans les données. A titre d’exemple, un ensemble de données avec 24 variables peut être réduit à cinq composantes principales qui représentent les principaux gradients de variation entre les échantillons. Les méthodes d’ordination sans contrainte ne sont pas adaptées au test d’hypothèses biologiques, mais permettent l’analyse exploratoire des données. Voir (the Ordination Website) pour un aperçu des différents méthodes (en Anglais). "],["introduction-aux-données.html", "Chapitre 4 Introduction aux données", " Chapitre 4 Introduction aux données Nous allons utiliser deux principaux ensembles de données dans la première partie de cet atelier. \"DoubsSpe.csv\" est une matrice de données d’abondance d’espèces de communautés de poissons dans laquelle la première colonne contient les noms des sites de 1 à 30 et les colonnes subséquentes correspondent aux différentes espèces de poissons. \"DoubsEnv.csv\" est une matrice de données environnementales pour les mêmes sites. La première colonne contient donc les noms des sites de 1 à 30 et les colonnes suivantes les mesures de 11 variables abiotiques. Notez que les données utilisées pour les analyses d’ordination sont généralement en format long (en anglais). # Matrice d&#39;abondances d&#39;espèces: “DoubsSpe.csv” spe &lt;- read.csv(file.choose(), row.names = 1) spe &lt;- spe[-8, ] #Pas d&#39;espèces dans le site 8, supprimer site 8. # Exécutez cette ligne une seule fois. # L&#39;environnement: “DoubsEnv.csv” env &lt;- read.csv(file.choose(), row.names = 1) env &lt;- env[-8, ] #Supprimer site 8 puisqu&#39;on l&#39;a retiré de la matrice d&#39;abondances. # Exécutez cette ligne une seule fois. "],["exploration-des-données.html", "Chapitre 5 1. Exploration des données 5.1 1.1 Données sur les espèces 5.2 1.2 Données sur l’environnement", " Chapitre 5 1. Exploration des données 5.1 1.1 Données sur les espèces Nous pouvons utiliser les fonctions de résumé R pour explorer les données \"Spe\" (données d’abondances de poissons) et découvrir les caractéristiques telles que les dimensions de la matrice, les noms des colonnes et les statistiques descriptives de ces colonnes (révision de l’atelier 2). names(spe) # Les noms des colonnes dim(spe) # Le nombre de lignes et de colonnes. str(spe) # La structure interne de la matrice. head(spe) # Les premières lignes. summary(spe) # Les statistiques descriptives. Regardez la distribution des espèces. (ab&lt;-table(unlist(spe))) #Les parenthèses signifient que la sortie s&#39;affiche immédiatement barplot(ab, las=1, xlab=”Abundance class”, ylab=”Frequency”, col=grey(5:0/5)) Pouvez-vous voir qu’il y a une grande fréquence de zéros dans les données d’abondance ? Calculez le nombre d’absences. sum(spe == 0) Regardez la proportion de zéros dans les données de la communauté de poissons. sum(spe == 0)/(nrow(spe) * ncol(spe)) La proportion de zéros dans la matrice est de ~0.5 Calculez le nombre de sites où chaque espèce est présente. spe.pres&lt;- colSums(spe&gt;0) # Somme des sites où chaque espèce est présente. hist(spe.pres, main=”Cooccurrence des espèces”, las=1, xlab=”Fréquence”, breaks=seq(0,30, by=5), col=”grey”) Le plus grand nombre d’espèces se retrouvent dans un nombre intermédiaire de sites. Calculez le nombre d’espèces présentes à chaque site. Ici, nous utilisons une façon simpliste de calculer la richesse en espèces. Dans certains cas, le nombre d’espèces présentes dans un site varie entre les sites car il peut y avoir une relation entre le nombre d’individus comptés (l’abondance) dans ce site et la richesse en espèces. richesse d’espèces raréfiée (en anglais) est souvent une mesure plus appropriée que la richesse totale. La fonction rarefy () de vegan peut être utilisée pour calculer la richesse raréfiée des espèces. site.pres&lt;- rowSums(spe&gt;0) # Nombre d&#39;espèces présentes dans chaque site hist(site.pres, main=”Richesse en espèces”, las=1, xlab=”Fréquence des sites”, ylab=”Nombre d&#39;espèces”, breaks=seq(0,30, by=5), col=”grey”) 5.2 1.2 Données sur l’environnement Explorez les données environnementales pour détecter les colinéarités : names(env) dim(env) str(env) head(env) summary(env) pairs(env, main = &quot;Données environnementales&quot;) Dans ce cas, les données environnementales sont toutes dans des unités différentes et doivent donc être standardisées avant de calculer les mesures de distance utilisées pour effectuer la plupart des analyses d’ordination. La standardisation des données (11 variables) peut être effectuée en utilisant la fonction decostand () de vegan. env.z &lt;- decostand(env, method = &quot;standardize&quot;) apply(env.z, 2, mean) # Les données sont maintenant centrées (moyennes~0)... apply(env.z, 2, sd) # et réduites (écart-type=1) "],["la-dissimilarité-des-données.html", "Chapitre 6 La (dis)similarité des données", " Chapitre 6 La (dis)similarité des données L’algèbre matricielle est à la base des méthodes d’ordination. Une matrice est constituée de données (ex. valeurs mesurées) réparties en lignes et colonnes. Les analyses d’ordination sont effectuées sur des matrices d’association calculées à partir des matrices de données écologiques (telles que DoubsEnv ou DoubsSpe). La création d’une matrice d’association permet le calcul de similarité et de distance entre les objets ou les descripteurs (Legendre et Legendre 2012). Avant de se lancer dans des analyses d’ordination, il est important de passer du temps sur vos matrices de données. Explorer les mesures possibles d’association qui peuvent être générées à partir de vos données avant de faire une ordination peut vous aider à mieux comprendre quelles mesures de distance sont appropriées pour les méthodes d’ordination. Il peut être difficile de voir l’objectif de chaque indice de dissimilarité, mais cette connaissance sera nécessaire pour mieux comprendre les méthodes d’ordination canoniques présentées par la suite. EN RÉSUMÉ: Pour l’ordination d’objets, il faut calculer les distances entre eux. Ces distances peuvent être calculées de plusieurs façons, en prenant en compte l’abondance ou les données de présence / absence. Plus important encore, plusieurs propriétés sont de grande importance pour les mesures de distances, et elles seront explorées dans les exemples ci-dessous. Pour plus d’informations sur les propriétés des mesures de distance et certains termes clés, cliquez sur la section cachée. Termes clés: Association - «Terme général pour décrire toute mesure ou coefficient servant à quantifier la ressemblance ou différence entre les objets ou les descripteurs. Dans une analyse entre descripteurs, zéro signifie l’absence d’association.» (Legendre et Legendre 2012). Similarité - une mesure dont «le maximum (S = 1) est atteint lorsque deux objets sont identiques et le minimum lorsque deux objets sont complètement différents.» (Legendre et Legendre 2012). Distance (aussi «dissimilarité») - une mesure dont «le maximum (D=1) est atteint lorsque deux objects sont complètement différent.» (Legendre et Legendre 2012). Distance ou dissimilarité (D) = 1-S Le choix d’une mesure d’association dépend de vos données, mais aussi de ce que vous en savez d’un point de vue écologique. Par exemple, la distance euclidienne est une mesure de distance très commune, facile à utiliser et utile pour comprendre comment les différences entre deux échantillons sont basées sur la cooccurrence des espèces. Le calcul de la distance euclidienne prend en compte les zéros dans les données, ce qui signifie que deux échantillons ou sites ne contenant aucune espèce en commun (double-absence) peuvent sembler plus similaires que deux sites partageant quelques espèces. Dans ce cas, la distance euclidienne peut être trompeuse et il est souvent préférable de choisir une mesure de distance différente si beaucoup d’espèces ont une abondance nulle dans votre matrice. Cette propriété est communément appelée le problème des «double zéros» en ordination. Quelques mesures de distance (d’après Gotelli et Ellison 2004): Mesure Propriété Description Euclidienne Métrique Distance entre deux points dans un espace en 2D. Manhattan Métrique Distance entre deux points - la distance est la somme des différences entre coordonnées cartésiennes. Corde Métrique Généralement utilisée pour déterminer les différences dues à la dérive génétique. Mahalanobis Métrique Distance entre un point et une distribution, où la distance est le nombre d’écart-types du point correspondant à la moyenne de la distribution. Chi-carré Métrique Similaire à la distance euclidienne. Bray-Curtis Semi-métrique Dissimilarité entre deux échantillons (ou sites) où la somme des valeurs minimales des espèces présentes dans les deux sites sont divisées par la somme des espèces répertoriées dans chaque site. Jaccard Métrique Description Sorensen’s S emi-métrique B ray-Curtis correspond à 1 - Sorensen "],["quantifier-la-dissimilarité-des-données.html", "Chapitre 7 Quantifier la (dis)similarité des données 7.1 Transformations des données de composition des communautés", " Chapitre 7 Quantifier la (dis)similarité des données Les données quantitatives des espèces Nous pouvons utiliser la fonction vegdist () pour calculer des indices de dissimilarité sur des données de composition de la communauté. Ceux-ci peuvent ensuite être visualisés sous forme de matrice si désiré. spe.db &lt;- vegdist(spe, method = &quot;bray&quot;) # distance de Bray (avec des données de présence-absence, correspond à Sorensen) spe.dj &lt;- vegdist(spe, method = &quot;jac&quot;) # distance de Jaccard spe.dg &lt;- vegdist(spe, method = &quot;gower&quot;) # distance de Gower spe.db &lt;- as.matrix(spe.db) # réarranger en format matrice (pour visualisation, ou pour exporter en .csv) Une version condensée de la matrice spe.db représentant la distance entre les trois premières espèces de DoubsSpe ressemblerait à ceci: Espèce 1 Espèce 2 Espèce 3 Espèce 1 0.0 0.6 0.68 Espèce 2 0.6 0.0 0.14 Espèce 3 0.68 0.14 0.0 Vous pouvez voir que lorsque l’on compare une espèce à elle-même (par exemple, Espèce 1 à Espèce 1), la distance est de 0 puisque les espèces sont identiques. Ces mêmes mesures de distance peuvent être calculées à partir des données de présence-absence par l’utilisation de l’argument binary=TRUE dans la fonction vegdist(). Cela donnera des mesures de distance légèrement différentes. Vous pouvez également créer des représentations graphiques de ces matrices d’association en utilisant la fonction coldiss. Cette fonction peut être sourcée à partir du script coldiss.R: windows() coldiss(spe.db, byrank = FALSE, diag = TRUE) # Carte des points chauds Bray-Curtis windows() coldiss(spe.dj, byrank = FALSE, diag = TRUE) # Carte des points chauds Jaccard windows() coldiss(spe.dg, byrank = FALSE, diag = TRUE) # Carte des points chauds Gower La figure montre une matrice de dissimilarité dont les couleurs reflètent la mesure de distance. La couleur violet est associée aux zones de fortes dissimilarités. Données environnementales quantitatives Regardons les associations entre les variables environnementales (aussi appelée mode Q): env.de &lt;- dist(env.z, method = &quot;euclidean&quot;) # matrice de distances euclidiennes des données env. standardisées windows() # crée une nouvelle fenêtre graphique coldiss(env.de, diag = TRUE) Nous pouvons ensuite regarder la dépendance entre les variables environnementales (aussi appelée mode R): (env.pearson &lt;- cor(env)) # coefficient r de corrélation de Pearson round(env.pearson, 2) # arrondit les coefficients à deux décimales (env.ken &lt;- cor(env, method = &quot;kendall&quot;)) # coefficient tau de corrélation de rang de Kendall round(env.ken, 2) La corrélation de Pearson mesure la corrélation linéaire entre deux variables. La corrélation de Kendall est une corrélation de rang qui quantifie la relation entre deux descripteurs ou deux variables lorsque les données sont ordonnées au sein de chaque variable. Dans certains cas, il peut y avoir des types mixtes de variables environnementales. Le mode Q peut alors être utilisé pour trouver des associations entre variables environnementales. C’est ce que nous allons faire avec l’exemple fictif suivant: var.g1 &lt;- rnorm(30, 0, 1) var.g2 &lt;- runif(30, 0, 5) var.g3 &lt;- gl(3, 10) var.g4 &lt;- gl(2, 5, 30) (dat2 &lt;- data.frame(var.g1, var.g2, var.g3, var.g4)) str(dat2) summary(dat2) Une matrice de dissimilarité peut être générée pour ces variables mixtes en utilisant la distance de Gower: `?`(daisy #Cette fonction peut gérer la présence de NA dans les données ) (dat2.dg &lt;- daisy(dat2, metric = &quot;gower&quot;)) coldiss(dat2.dg) Défi 1 - Niveau intermédiaire Discutez avec votre voisin: Comment pouvons-nous dire si des objets sont similaires avec un jeu de données multivariées? Faites une liste de toutes vos suggestions. Défi 1 - Solution Discussion avec le groupe. Défi 1 - Niveau avancé Calculer à la mitaine // sans utiliser la fonction decostand () // les distances de Bray-Curtis et de Gower pour l’abondance des espèces CHA, TRU et VAI dans les sites 1, 2 et 3. Défi 1 - Solution Formule pour calculer la distance de Bray-Curtis: d\\[jk\\] = (sum abs(x\\[ij\\]-x\\[ik\\]))/(sum (x\\[ij\\]+x\\[ik\\])) Réduisez le jeu de données aux espèces CHA, TRU et VAI et aux sites 1, 2 et 3 spe.challenge &lt;- spe[1:3, 1:3] # les 3 premières lignes et 3 premières espèces (colonnes) Déterminer l’abondance totale des espèces pour chaque site d’intérêt (somme des trois lignes) qui correspondra au dénominateur de la distance de Bray-Curtis. (Abund.s1 &lt;- sum(spe.challenge[1, ])) (Abund.s2 &lt;- sum(spe.challenge[2, ])) (Abund.s3 &lt;- sum(spe.challenge[3, ])) Maintenant, calculez la différence de l’abondance des espèces pour chaque paire de sites. Par exemple, quelle est la différence entre l’abondance de CHA et TRU dans le site 1? Vous devez calculer les différences suivantes: CHA et TRU site 1 CHA et VAI site 1 TRU et VAI site 1 CHA et TRU site 2 CHA et VAI site 2 TRU et VAI site 2 CHA et TRU site 3 CHA et VAI site 3 TRU et VAI site 3 Spec.s1s2 &lt;- 0 Spec.s1s3 &lt;- 0 Spec.s2s3 &lt;- 0 for (i in 1:3) { Spec.s1s2 &lt;- Spec.s1s2 + abs(sum(spe.challenge[1, i] - spe.challenge[2, i])) Spec.s1s3 &lt;- Spec.s1s3 + abs(sum(spe.challenge[1, i] - spe.challenge[3, i])) Spec.s2s3 &lt;- Spec.s2s3 + abs(sum(spe.challenge[2, i] - spe.challenge[3, i])) } Maintenant, utilisez les différences calculées comme numérateur et l’abondance totale de l’espèce comme dénominateur pour retrouver l’équation de la distance de Bray-Curtis. (db.s1s2 &lt;- Spec.s1s2/(Abund.s1 + Abund.s2)) #1 comparé à 2 (db.s1s3 &lt;- Spec.s1s3/(Abund.s1 + Abund.s3)) #1 comparé à 3 (db.s2s3 &lt;- Spec.s2s3/(Abund.s2 + Abund.s3)) #2 comparé à 3 Vérifiez vos résultats en utilisant la fonction vegdist () : (spe.db.challenge &lt;- vegdist(spe.challenge, method = &quot;bray&quot;)) Une matrice comme celle-ci est calculée et devrait être correspondre à vos calculs manuels: Site 1 Site 2 Site 2 0.5 -- Site 3 0.538 0.0526 Pour la distance de Gower, procédez de la même façon, mais utiliser l’équation appropriée: Distance de Gower: d\\[jk\\] = (1/M) sum(abs(x\\[ij\\]-x\\[ik\\])/(max(x\\[i\\])-min(x\\[i\\]))) # Calculer le nombre de colonnes M &lt;- ncol(spe.challenge) # Calculer les différences d&#39;abondance de chaque espèce entre # paires de sites Spe1.s1s2 &lt;- abs(spe.challenge[1, 1] - spe.challenge[2, 1]) Spe2.s1s2 &lt;- abs(spe.challenge[1, 2] - spe.challenge[2, 2]) Spe3.s1s2 &lt;- abs(spe.challenge[1, 3] - spe.challenge[2, 3]) Spe1.s1s3 &lt;- abs(spe.challenge[1, 1] - spe.challenge[3, 1]) Spe2.s1s3 &lt;- abs(spe.challenge[1, 2] - spe.challenge[3, 2]) Spe3.s1s3 &lt;- abs(spe.challenge[1, 3] - spe.challenge[3, 3]) Spe1.s2s3 &lt;- abs(spe.challenge[2, 1] - spe.challenge[3, 1]) Spe2.s2s3 &lt;- abs(spe.challenge[2, 2] - spe.challenge[3, 2]) Spe3.s2s3 &lt;- abs(spe.challenge[2, 3] - spe.challenge[3, 3]) # Calculer l&#39;étendue d&#39;abondance de chaque espèces parmi les # sites Range.spe1 &lt;- max(spe.challenge[, 1]) - min(spe.challenge[, 1]) Range.spe2 &lt;- max(spe.challenge[, 2]) - min(spe.challenge[, 2]) Range.spe3 &lt;- max(spe.challenge[, 3]) - min(spe.challenge[, 3]) # Calculer la distance de Gower (dg.s1s2 &lt;- (1/M) * ((Spe2.s1s2/Range.spe2) + (Spe3.s1s2/Range.spe3))) (dg.s1s3 &lt;- (1/M) * ((Spe2.s1s3/Range.spe2) + (Spe3.s1s3/Range.spe3))) (dg.s2s3 &lt;- (1/M) * ((Spe2.s2s3/Range.spe2) + (Spe3.s2s3/Range.spe3))) # Vérifier vos résultats (spe.db.challenge &lt;- vegdist(spe.challenge, method = &quot;gower&quot;)) 7.1 Transformations des données de composition des communautés Les données de composition des communautés peuvent également être standardisées ou transformées. La fonction decostand () de vegan fournit des options de standardisation et de transformation de ce type de données Transformer les abondances en données de présence-absence: spe.pa &lt;- decostand(spe, method = &quot;pa&quot;) D’autres transformations peuvent être utilisées pour corriger l’influence d’espèces rares, par exemple, la transformation de Hellinger: # La transformation Hellinger spe.hel &lt;- decostand(spe, method = &quot;hellinger&quot;) # vous pouvez aussi simplement écrire &#39;hel&#39; # Transformation de chi-carré spe.chi &lt;- decostand(spe, method = &quot;chi.square&quot;) Défi option 2 - Niveau avancé Calculez les distances de Hellinger et de Chi-carré sur les données \"spe\" sans utiliser decostand (). Défi option 2 - Solution La transformation de Hellinger est une transformation qui diminue l’importance accordée aux espèces rares. # Hellinger Calculer l&#39;abondance des espèces par site (site.totals = apply(spe, 1, sum)) # Réduire les abondances d&#39;espèces en les divisant par les # totaux par sites (scale.spe &lt;- spe/site.totals) # Calculer la racine carrée des abondances d&#39;espèces réduites (sqrt.scale.spe &lt;- sqrt(scale.spe)) # Comparer les résultats sqrt.scale.spe spe.hel sqrt.scale.spe - spe.hel # ou: sqrt.scale.spe/spe.hel # Chi-carré Premièrement calculer le total des abondances # d&#39;espèces par site (site.totals &lt;- apply(spe, 1, sum)) # Ensuite calculer la racine carrée du total des abondances # d&#39;espèces (sqrt.spe.totals &lt;- sqrt(apply(spe, 2, sum))) # Réduire les abondances d&#39;espèces en les divisant par les # totaux par sites et les totaux par espèces scale.spe2 &lt;- spe for (i in 1:nrow(spe)) { for (j in 1:ncol(spe)) { (scale.spe2[i, j] = scale.spe2[i, j]/(site.totals[i] * sqrt.spe.totals[j])) } } # Ajuster les abondances en les multipliant par la racine # carrée du total de la matrice des espèces (adjust.scale.spe2 &lt;- scale.spe2 * sqrt(sum(rowSums(spe)))) # Vérifier les résultats adjust.scale.spe2 spe.chi adjust.scale.spe2 - spe.chi # or: adjust.scale.spe2/spe.chi "],["groupement.html", "Chapitre 8 Groupement", " Chapitre 8 Groupement Les matrices d’association nécessaires pour utiliser les méthodes de groupement. Le groupement n’est pas une méthode statistique en tant que telle puisqu’elle ne teste pas d’hypothèse, mais permet de déceler des structures dans les données en partitionnant soit les objets, soit les descripteurs. Les objets similaires sont agrégés en sous-groupes ce qui permet de mettre en relief des cassures (contrastes) entre les données. En tant que biologiste, il peut être intéressant de tenter de séparer une série de sites en groupes en fonction de leurs caractéristiques environnementales ou de leur composition en espèces. Les résultats d’un groupement sont généralement représentés sous forme de dendrogramme (arbre), dans lequel les objets sont agrégés en groupes. Il y a plusieurs familles de méthodes de groupements, mais nous présenterons uniquement un aperçu de trois méthodes : le groupement agglomératif hiérarchique à liens simples, le groupement agglomératif hiérarchique à liens complets et la méthode de Ward. Pour plus de détails sur les différentes familles de méthodes de groupement, consulter Legendre et Legendre 2012 (chapitre 8). Dans les méthodes hiérarchiques, les éléments des petits ensembles se regroupent en groupes plus vastes de rang supérieur, et ainsi de suite (par exemple : espèces, genres, familles, ordre). Avant de faire le groupement, il faut créer une matrice d’association entre les objets. Une matrice de distances est le choix par défaut des fonctions de groupement dans R. La matrice d’association est premièrement classée en ordre croissant de distances. Ensuite, les groupes sont formés de manière hiérarchique selon les critères spécifiques à chaque méthode. Prenons un exemple tout simple d’une matrice de distances euclidiennes entre 5 objets dont on a ordonné les distances en ordre croissant. Pour le groupement agglomératif à liens simples, les deux objets les plus proches se regroupent en premier. Ensuite, un deuxième groupe est formé à partir des deux objets les plus proches suivant (il se peut que ce soit deux objets différents, ou bien un objet et le groupe formé précédemment), et ainsi de suite. Cette méthode forme généralement de longues chaînes de groupes (dans l’exemple ci-haut, les objets 1 à 5 se regroupent successivement). À l’inverse, pour le groupement agglomératif à liens complet, un objet se regroupe à un autre objet/groupe seulement lorsqu’il est aussi lié à l’élément le plus éloigné de ce groupe. Ainsi, quand deux groupes fusionnent, tous les éléments des deux groupes sont liés à la distance considérée (ci-haut, le groupe 3-4 ne se lie au groupe 1-2 qu’à la distance à laquelle tous les autres éléments sont déjà liés). C’est pour cette raison que le groupement à liens complets forme généralement plusieurs petits groupes séparés et qu’elle peut être plus appropriée pour relever des contrastes ou des discontinuités dans les données. Comparons ces deux méthodes en utilisant les données d’abondances de poissons de la rivière Doubs. Les données d’abondances ont été au préalable transformées par la méthode Hellinger. Puisque les fonctions de groupement requièrent une matrice de distances, la première étape sera de générer une matrice de distances Hellinger. spe.dhel &lt;- vegdist(spe.hel, method = &quot;euclidean&quot;) #crée une matrice de distances Hellinger à partir des données d’abondance transformées # Pour voir la différence entre les deux types d’objets head(spe.hel) # données d’abondances transformées Hellingerhead(spe.dhel)# matrice de distances de Hellinger entre les sites La plupart des méthodes de groupement sont disponible dans la fonction hclust() de la librairie stats # Faire le groupement à liens simples spe.dhel.single &lt;- hclust(spe.dhel, method = &quot;single&quot;) plot(spe.dhel.single) # Faire le groupement à liens complet spe.dhel.complete &lt;- hclust(spe.dhel, method = &quot;complete&quot;) plot(spe.dhel.complete) Est-ce que les deux dendrogrammes sont très différents? On remarque que pour le groupement à liens simple, plusieurs objets s’enchaînent (par exemple les sites 19, 29, 30, 20, 26, etc.) alors que des groupes plus distincts peuvent être observés dans le groupement à liens complets. La méthode de Ward diffère légèrement des deux méthodes précédentes. Le critère utilisé est la méthode des moindres carrés (comme dans les modèles linéaires). Ainsi, des objets/groupes fusionnent de façon à minimise la variance intragroupes. Pour débuter, chaque objet est considéré comme un groupe. À chaque étape, la paire de groupes à fusionner est celle qui résulte à la plus petite augmentation de la somme des carrés des écarts intra-groupes. La méthode de Ward est également disponible sous la fonction hclust(). Par contre, le dendrogramme produit par défaut montre les distances au carré. Afin de comparer ce dendrogramme à celui du groupement à liens simples et à liens complets, il faut calculer la racine carrée des distances. # Faire le groupement de Ward spe.dhel.ward &lt;- hclust(spe.dhel, method = &quot;ward.D2&quot;) plot(spe.dhel.ward) # Refaire le dendrogramme en utilisant la racine carrée des # distances spe.dhel.ward$height &lt;- sqrt(spe.dhel.ward$height) plot(spe.dhel.ward) plot(spe.dhel.ward, hang = -1) # hang=-1 permet d’afficher les objets sur la même ligne Les groupements générés par la méthode de Ward ont tendance à être plus sphériques et à contenir des quantités plus similaires d’objets. Quelle méthode choisir? Le choix de la bonne mesure d’association et de la bonne méthode de groupement dépend de l’objectif. Qu’est-ce qu’il est plus intéressant de démontrer : des gradients? des contrastes? Il est également important de tenir en compte les propriétés de la méthode utilisée dans l’interprétation des résultats. Si plus d’une méthode semble adéquate pour répondre à une question biologique, comparer les dendrogrammes serait une bonne option. Encore une fois, le groupement n’est pas une analyse statistique, mais il est possible de tester les résultats et d’identifier des partitions ayant un sens biologique. Il est également possible de déterminer le nombre de groupes optimal et de performer des tests statistiques sur les résultats. Les méthodes de groupement peuvent aussi être combinées à une ordination pour distinguer des groupes de sites. Ces avenues ne seront pas explorées dans cet atelier. Pour aller plus loin, consulter Borcard et al. 2011. "],["le-significat-de-lordination-sans-contrainte.html", "Chapitre 9 Le significat de l’ordination “sans contrainte”", " Chapitre 9 Le significat de l’ordination “sans contrainte” Les analyses d’ordination sans contrainte permettent d’organiser des échantillons, des sites ou des espèces le long de gradients continus (ex. écologiques ou environnementaux). Les ordinations sans contrainte se différencient des analyses canoniques (voir plus loin dans cet atelier \"analyses canoniques\") par le fait que ces techniques ne tentent pas de définir une relation entre des variables dépendantes et indépendantes. L’ordination sans contrainte peut être utilisée pour: Évaluer les relations au sein d’un ensemble de variables (et non pas entre séries de variables). Trouver les éléments clés de variation au sein d’échantillons, de sites, d’espèces, etc. Réduire les dimensions d’un jeu de données multivariées sans perte importante d’informations. Créer de nouvelles variables pour une utilisation dans des analyses ultérieures (comme la régression). Les composantes principales des axes d’ordination sont en effet des combinaisons linéaires des variables d’origine. Source "],["analyses-en-composantes-principales.html", "Chapitre 10 Analyses en Composantes Principales", " Chapitre 10 Analyses en Composantes Principales L’Analyse en Composantes Principales (ou PCA) fur originellement décrite par Pearson (1901) bien qu’elle soit le plus souvent attribué à Hotelling (1933) qui l’a proposé indépendamment. Cette méthode ainsi que nombre de ces implications sont pour l’analyse de données sont présentées dans l’article fondateur de Rao (1964). La PCA est utilisée pour générer, à partir d’un large jeu de données, un nombre restreint de variables clefs qui permettent de représenter au maximum la variation présente dans le jeu de données. En d’autres termes, la PCA est utilisée pour générer des combinaisons de variables à partir d’un ensemble plus grand de variables tout en conservant la majorité de variation de l’ensemble des données. La PCA est une technique d’analyse puissante pour l’analyse dans descripteurs quantitatifs (tels que les abondances d’espèces), mais ne peut pas être appliquée aux données binaires (telles que l’absence/présence des espèces). À partir d’un jeu de données contenant des variables à distribution normale, le premier axe de PCA (ou axe de composante principale) correspond à la droite qui traverse la plus grande dimension de l’ellipsoïde décrivant la distribution multi-normale des données. Les axes suivants traversent de façon similaire cet ellipsoïde selon l’ordre décroissant de ces dimensions. Ainsi, il est possible d’obtenir un maximum de p axes principaux à partir d’un jeu de données contenant p variables. Pour cela, la PCA effectue un rotation du système d’axes originels défini par les variables de façon à ce que les axes d’ordination successifs soient orthogonaux entre eux et correspondent aux dimensions successives du maximum de variance observée dans le nuage de points (voir ci-dessus). Les nouvelles variables produites par la PCA sont non-corrélées entre elles (les axes d’ordination étant orthogonaux) et peuvent alors être utilisés dans d’autres types d’analyse telles que des régressions multiples (Gotelli et Ellison, 2004). Les composantes principales situent la position des objets dans le nouveau système de coordonnées calculé par la PCA. La PCA s’effectue sur une matrice d’association entre variables, et a pour caractéristique de préserver les distances euclidiennes et de détecter des relations linéaires, uniquement. En conséquence, les abondances brutes des espèces doivent être soumises à une pré-transformation (comme une transformation d’Hellinger) avant de réaliser une PCA. Pour faire une PCA, vous avez besoin : - Un ensemble de variables (sans distinction entre les variables indépendantes ou dépendantes, c-est-à-dire un ensemble d’espèces OU un ensemble de variables environnementales). - De sites (objets, échantillons) dans lesquels sont mesurés les mêmes variables. - En général, il est préférable d’avoir un plus grand nombre de sites que de variables dans le jeu de données (plus de lignes que de colonnes). La PCA est particulièrement utile pour des matrices de données contenant plus de deux variables, mais il est plus facile de décrire son fonctionnement avec un exemple bidimensionnel. Dans l’exemple suivant (d’après Clarke et Warwick 2001), la matrice contient les données d’abondance de deux espèces dans neuf sites: Site Espèce 1 Espèce 2 A 6 2 B 0 0 C 5 8 D 7 6 E 11 6 F 10 10 G 15 8 H 18 14 I 14 14 La représentation des sites en deux dimensions devrait ressembler à ceci: Ce nuage de points est une ordination. Il présente la distribution des espèces entre les sites, mais vous pouvez imaginer qu’il est plus difficile de visualiser un tel graphique en présence de plus de deux espèces. Dans ce cas, l’objectif est de réduire le nombre de variables en composantes principales. Pour réduire les données bidimensionnelles précédentes à une dimension, une PCA peut être effectuée : Dans ce cas, la première composante principale est orientée dans le sens de la plus grande variation dans les points, ces points étant perpendiculaires à la ligne. Une seconde composante principale est alors ajoutée perpendiculairement à la première: Dans le diagramme final, les deux axes de PCA sont pivotés et les axes sont maintenant les composantes principales (et non plus les espèces): Pour les PCA avec plus de deux variables, les composantes principales sont ajoutées de la façon suivante (Clarke et Warwick 2001): PC1 = axe qui maximise la variance des points qui sont projetées perpendiculairement à l’axe. PC2 = axe perpendiculaire à PC1, mais dont la direction est à nouveau celle maximisant la variance lorsque les points y sont projetés perpendiculairement. PC3 et ainsi de suite: perpendiculaire aux deux premiers axes dont la direction est à nouveau celle maximisant la variance lorsque les points y sont projetés perpendiculairement. Lorsqu’il y a plus de deux dimensions, la PCA produit un nouvel espace dans lequel tous les axes de PCA sont orthogonaux (ce qui signifie que la corrélation entre chaque combinaison de deux axes est nulle), et où les axes de PCA sont ordonnés selon la proportion de variance des données d’origine qu’ils expliquent. Les données \"spe\" comprennent 27 espèces de poissons. Pour simplifier cette diversité à un petit nombre de variables ou pour identifier différents groupes de sites associés à des espèces particulières, une PCA peut être effectuée. Exécuter une PCA sur les données d’abondance d’espèces soumises à la transformation d’Hellinger : # Exécuter la PCA avec la fonction rda()- cette fonction # calcule à la fois des PCA et des RDA spe.h.pca &lt;- rda(spe.hel) # Extraire les résultats summary(spe.h.pca) Résultats: Interprétation des résultats de PCA Cette sortie R contient les valeurs propres ou «eigenvalue» de la PCA. La valeur propre est la valeur de la variation ramenée à la longueur d’un vecteur, et correspond à la quantité de variation expliquée par chaque axe d’ordination de la PCA. Comme vous pouvez le voir, la fonction summary fournit de nombreuses informations. Parmi les résultats, la proportion de variance des données expliquée par les variables sans contraintes est une information importante. Dans cet exemple, la variance totale des sites expliquée par les espèces est de 0,5 (50%). Le résumé vous indique également quelle proportion de la variance totale expliquée est répartie entre chaque composantes principales de la PCA: le premier axe de PCA explique 51.33% de la variation tandis que le second axe explique 12.78%. Vous pouvez également extraire certaines parties des résultats: summary(spe.h.pca, display = NULL) # seulement les valeurs propres eigen(cov(spe.hel)) # vous pouvez aussi trouver les valeurs propres par cette ligne de code Les scores (c’est-à-dire les coordonnées) des sites ou des espèces peuvent également être extraits d’une PCA. Ces scores permettent, par exemple, d’utiliser une composante principale comme une variable dans une autre analyse, ou de faire des graphiques supplémentaires. Par exemple, vous pouvez obtenir par PCA une variable unique issue du jeu de données \"spe\" puis l’utiliser pour la corréler par régression à une autre variable, ou déterminer un gradient spatial. Pour extraire les scores d’une PCA, utiliser la fonction scores (): spe.scores &lt;- scores(spe.h.pca, display = &quot;species&quot;, choices = c(1, 2)) # scores des espèces selon les premier et deuxième axes site.scores &lt;- scores(spe.h.pca, display = &quot;sites&quot;, choices = c(1, 2)) # scores des sites selon les premier et deuxième axes # Remarque: si vous ne spécifiez pas le nombre de composantes # principales à l&#39;aide de choices = c (1,2) (ou choices = c # (1: 2)), les scores selon toutes les composantes # principales seront extraits. La PCA des données d’abondances de poissons produit autant de composantes principales qu’il y d’espèces (i.e. de colonnes dans le jeu de données), soit 27 composantes principales. Le nombre de variables à traiter n’est donc pas directement réduit par la PCA. Pour réduire le nombre de variables, il est alors nécessaire de déterminer quelles composantes principales sont significatives et doivent être conservées, par exemple à l’aide du critère de Kaiser-Guttman. Ce critère compare la variance expliquée par chaque composante principale à la moyenne de la variance expliquée par l’ensemble des composantes principales. Un histogramme illustrant la significativité des différentes composantes principale peut ensuite être tracé à l’aide du code ci-dessous : # Identification des axes significatifs de la PCA à l&#39;aide du # critère de Kaiser-Guttman ev &lt;- spe.h.pca$CA$eig ev[ev &gt; mean(ev)] n &lt;- length(ev) bsm &lt;- data.frame(j = seq(1:n), p = 0) bsm$p[1] = 1/n for (i in 2:n) { bsm$p[i] = bsm$p[i - 1] + (1/(n = 1 - i)) } bsm$p = 100 * bsm$p/n bsm barplot(ev, main = &quot;valeurs propres&quot;, col = &quot;grey&quot;, las = 2) abline(h = mean(ev), col = &quot;red&quot;) legend(&quot;topright&quot;, &quot;moyenne des valeurs propres&quot;, lwd = 1, col = 2, bty = &quot;n&quot;) Cet histogramme montre que la proportion de la variance expliquée par chaque composante chute en-dessous de la proportion moyenne expliquée par l’ensemble des composantes après le sixième axe d\"ordination PC6. En consultant le résumé de nouveau, on peut constater que la proportion cumulée de la variance expliquée par les cinq premières composantes principales est de 85%. La PCA n’est pas seulement appropriée pour les données de composition d’espèces, mais peut également être exécutée sur des variables environnementales standardisées: # Exécuter la PCA env.pca &lt;- rda(env.z) # ou rda(env, scale=TRUE) # Extraction des résultats summary(env.pca) summary(env.pca, scaling = 2) «Scaling» réfère à quelle portion de la PCA est redimensionnée aux valeurs propres. Scaling = 2 signifie que les scores des espèces sont mises à l’échelle des valeurs propres, alors que scaling = 1 signifie que les scores des sites sont mises à l’échelle des valeurs propres. Scaling = 3 signifie qu’à la fois les scores des espèces et des sites sont mis symétriquement à l’échelle de la racine carrée des valeurs propres. En scaling = 1,les distances euclidiennes entre les sites (lignes de la matrice de données) sont conservées tandis qu’en scaling = 2 les corrélations entre espèces (les colonnes de la matrice de données) sont conservées. Cela implique que lorsque vous regardez un biplot de PCA en Scaling = 2, l’angle entre les descripteurs représente leur corrélation. ev &lt;- env.pca$CA$eig ev[ev &gt; mean(ev)] n &lt;- length(ev) bsm &lt;- data.frame(j = seq(1:n), p = 0) bsm$p[1] = 1/n for (i in 2:n) { bsm$p[i] = bsm$p[i - 1] + (1/(n = 1 - i)) } bsm$p = 100 * bsm$p/n bsm barplot(ev, main = &quot;valeurs propres&quot;, col = &quot;grey&quot;, las = 2) abline(h = mean(ev), col = &quot;red&quot;) legend(&quot;topright&quot;, &quot;moyenne des valeurs propres&quot;, lwd = 1, col = 2, bty = &quot;n&quot;) Comparer cet histogramme de valeurs propres avec celui que vous avez créé pour la PCA sur les abondances d’espèces. Bien que beaucoup d’informations puissent être extraites d’une PCA par la fonction summary de la PCA, l’interpétation et la communication des résultats est souvent facilitée en traçant un biplot. Sur un biplot de PCA, l’axe des x correspond à la première composante principale et l’axe des y à la deuxième composante principale. La fonction plot () permet de tracer des biplot sur lequels les sites figurent en chiffres noirs et les espèces sont représentées en rouge. Le biplot de la PCA des abondances d’espèces peut être appelé comme suit: plot(spe.h.pca) La construction de biplots de PCA s’articule en trois étapes: plot(spe.h.pca, type=”n”) # Produit une figure vierge points(spe.h.pca, dis=”sp”, col=”blue”) # ajoute les points correspondant aux espèces #utilizer text() plutôt que points() si vous préférez que les codes des espèces s&#39;affichent (nom des colonnes) points(spe.h.pca, dis=”sites”, col=”red”) # ajoute les points correspondant aux sites Pour créer de plus beaux biplots, essayez ce code: # Scaling 1 windows() plot(spe.h.pca) windows() biplot(spe.h.pca) windows() # scaling 1 = distance biplot : distances entre les objets # est une approximation de leur distance euclidienne les # angles entre les descripteurs ne réflètent PAS leur # corrélation plot(spe.h.pca, scaling = 1, type = &quot;none&quot;, xlab &lt;- c(&quot;PC1 (%)&quot;, round((spe.h.pca$CA$eig[1]/sum(spe.h.pca$CA$eig)) * 100, 2)), ylab &lt;- c(&quot;PC2 (%)&quot;, round((spe.h.pca$CA$eig[2]/sum(spe.h.pca$CA$eig)) * 100, 2))) points(scores(spe.h.pca, display = &quot;sites&quot;, choices = c(1, 2), scaling = 1), pch = 21, col = &quot;black&quot;, bg = &quot;steelblue&quot;, cex = 1.2) text(scores(spe.h.pca, display = &quot;species&quot;, choices = c(1), scaling = 1), scores(spe.h.pca, display = &quot;species&quot;, choices = c(2), scaling = 1), labels = rownames(scores(spe.h.pca, display = &quot;species&quot;, scaling = 1)), col = &quot;red&quot;, cex = 0.8) Le code ci-dessus a produit trois biplots mais le dernier est le plus attrayant : Sur ce graphique, les sites scores sont indiqués par des points bleus et les noms d’espèces sont en rouge. Il est également possible de représenter les sites par leurs noms. Comment interpréter ce type de graphique ? Ce biplot permet d’observer qu’il existe certains groupes de sites homogènes du point de vue de la composition de leur communautés de poissons. On y voit également que l’espèce «ABL» n’a pas la même prévalence dans la majorité des sites que les autres espèces plus proches du centre du graphique. Les biplots ne doivent pas seulement être interprétés en termes de proximité, mais également d’angles. Deux variables séparées d’un angle de 90 degrés ne sont pas corrélées. Deux variables très rapprochés sont fortement corrélées. Deux variables aux directions opposées sont corrélées négativement. Maintenant regardons le biplot de la PCA environnement: # Scaling 2 windows() plot(env.pca) windows() # scaling 2 = graphique de corrélations : les distances entre # les objets ne sont PAS des approximations de leur distance # euclidienne les angles entres les descripteurs reflètent # leur corrélation plot(env.pca, scaling = 2, type = &quot;none&quot;, xlab &lt;- c(&quot;PC1 (%)&quot;, round((env.pca$CA$eig[1]/sum(env.pca$CA$eig)) * 100, 2)), ylab &lt;- c(&quot;PC2 (%)&quot;, round((env.pca$CA$eig[2]/sum(env.pca$CA$eig)) * 100, 2)), xlim &lt;- c(-1, 1), ylim = c(-1, 1)) points(scores(env.pca, display = &quot;sites&quot;, choices = c(1, 2), scaling = 2), pch = 21, col = &quot;black&quot;, bg = &quot;darkgreen&quot;, cex = 1.2) text(scores(env.pca, display = &quot;species&quot;, choices = c(1), scaling = 2), scores(env.pca, display = &quot;species&quot;, choices = c(2), scaling = 2), labels &lt;- rownames(scores(env.pca, display = &quot;species&quot;, scaling = 2)), col = &quot;red&quot;, cex = 0.8) Rappelez-vous qu’un biplot de PCA est en fait un nuage de points dans lequel les axes sont des combinaisons linéaires des variables d’origine. Il existe donc beaucoup de façons différentes de tracer un biplot. Par exemple, vous pouvez utiliser la fonction ggplot () et les compétences acquises de l’atelier 3 pour tracer votre graphique d’ordination dans ggplot. Utilisation des axes de PCA comme variable explicative composite Dans certains cas, l’utilisateur cherche à réduire un grand nombre de variables environnementales en un plus faible nombre de variables composites. Lorsque les axes de PCA représentent des gradients écologiques (i.e. lorsue les variables environnementales sont corrélées de façon cohérente avec les axes de PCA), l’utlisateur peut utiliser les scores des sites le long axes de PCA dans de nouvelles analyses (au lieu d’utiliser les variables environnementales brutes). En d’autres termes, étant donné que les scores des sites le long des axes de PCA représentent des combinaisons linéaires des descripteurs, ils peuvent être utilisés comme proxy des conditions écologiques dans de nouvelles analyses. Dans l’exemple ci-dessus, le premier axe de PCA peut être identifié comme un gradient écologique allant des sites oligotrophes riches en oxygène aux sites eutrophes pauvres en oxygène: de gauche à droite, le premier groupe de sites montrent les plus hautes altitudes (alt) et pente (slope), et les plus faibles débit (deb) et distance à la source (das). Le second groupe de sites possède les plus hautes valeurs de concentration en oxygène (oxy) et les plus faibles concentrations en nitrates (nit). Un troisième groupe de sites montrent des valeurs intermédiaire pour l’ensemble de ces variables. Dans ce cas, si l’objectif est d’identifier si une espèce particulière est associée au gradient oligotrophe-eutrophe, il est possible de corréler l’abondance de cette espèce aux scores des sites le long du premier axe de PCA. Par exemple, si l’utilisateur veut identifier si l’espèce TRU est associée à des eaux oligotrophes ou eutrophes, il lui est possible d’utiliser le modèle linéaire suivant: Sites_scores_Env_Axis1 &lt;- scores(env.pca, display = &quot;sites&quot;, choices = c(1), scaling = 2) spe$ANG plot(Sites_scores_Env_Axis1, spe$TRU) summary(lm(spe$TRU ~ Sites_scores_Env_Axis1)) abline(lm(spe$TRU ~ Sites_scores_Env_Axis1)) Ce modèle simple montre que l’abondance de l’espèce TRU est significativement liée aux scores des sites le long du premier axe de PCA (t = -5.30, p = 1.35e-05, adj-R2 = 49.22%), c’est-à-dire qu’elle dépend d’un gradient oligotrophe-eutrophe. dans ce cas l’espèce TRU préfère donc les eaux oligotrophes. Défi 3 Exécuter une PCA sur l’abondance des espèces de mites. Quels sont les axes significatifs ? Quels sont groupes de sites pouvez-vous identifier? Quelles espèces sont liées à chaque groupe de sites? mite.spe &lt;- data(mite) # données disponibles dans vegan Défi - Solution Votre code ressemble certainement à celui-ci: # Transformation de Hellinger mite.spe.hel &lt;- decostand(mite.spe, method = &quot;hellinger&quot;) mite.spe.h.pca &lt;- rda(mite.spe.hel) # Quels sont les axes significatifs? ev &lt;- mite.spe.h.pca$CA$eig ev[ev &gt; mean(ev)] n &lt;- length(ev) bsm &lt;- data.frame(j = seq(1:n), p = 0) bsm$p[1] = 1/n for (i in 2:n) { bsm$p[i] = bsm$p[i - 1] + (1/(n = 1 - i)) } bsm$p = 100 * bsm$p/n bsm barplot(ev, main = &quot;Valeurs propres&quot;, col = &quot;grey&quot;, las = 2) abline(h = mean(ev), col = &quot;red&quot;) legend(&quot;topright&quot;, &quot;Moyenne des valeurs propres&quot;, lwd = 1, col = 2, bty = &quot;n&quot;) # Résultats summary(mite.spe.h.pca, display = NULL) windows() # Représentation graphique de la PCA plot(mite.spe.h.pca, scaling = 1, type = &quot;none&quot;, xlab = c(&quot;PC1 (%)&quot;, round((mite.spe.h.pca$CA$eig[1]/sum(mite.spe.h.pca$CA$eig)) * 100, 2)), ylab = c(&quot;PC2 (%)&quot;, round((mite.spe.h.pca$CA$eig[2]/sum(mite.spe.h.pca$CA$eig)) * 100, 2))) points(scores(mite.spe.h.pca, display = &quot;sites&quot;, choices = c(1, 2), scaling = 1), pch = 21, col = &quot;black&quot;, bg = &quot;steelblue&quot;, cex = 1.2) text(scores(mite.spe.h.pca, display = &quot;species&quot;, choices = c(1), scaling = 1), scores(mite.spe.h.pca, display = &quot;species&quot;, choices = c(2), scaling = 1), labels = rownames(scores(mite.spe.h.pca, display = &quot;species&quot;, scaling = 1)), col = &quot;red&quot;, cex = 0.8) Votre graphique ressemblera à ceci. Bien que les sites soient tous de composition semblable (aucun groupe distinct de sites n’apparait sur le biplot), certaines espèces semblent souvent être présentes ensemble, par exemple Spec 01, Spec 10, Spec 14 et Spec 15. "],["analyse-des-correpondances.html", "Chapitre 11 Analyse des Correpondances", " Chapitre 11 Analyse des Correpondances L’une des hypothèses clefs de la PCA postule que les espèces sont liées les unes aux autres de façon linéaire, et qu’elles répondent de façon linéaire aux gradients écologiques. Ce n’est cependant pas nécessairement le cas dans les données écologiques (e.g. beaucoup d’espèces montrent en effet un distribution unimodale le long des gradients environnementaux). Utiliser une PCA avec des données contenant des espèces à distribution unimodale, ou un grand nombre de zéros (absence des espèces), peut conduire à un phénomène statistique appelé \"horseshoe effect\" (ou effet fer à cheval) se produisant le long de gradients écologiques. Dans de tels cas, l’Analyse des Correspondances (CA) permet de mieux représenter les données (voir Legendre et Legendre pour plus d’informations). Comme la CA préserve les distances de Chi2 entre objets (tandis que la PCA préserve les distances euclidiennes), cette technique est, en effet, plus appropriée pour ordonner les jeux de données contenant des espèces à distribution unimodale, et a, pendant longtemps, était l’une des techniques les plus employées pour analyser les données d’absence-présence ou d’abondances d’espèces. Lors d’une CA, les données brutes sont d’abord transformées en une matrice Q des contributions cellule-par-cellule à la statistique Chi2 de Pearson, puis la matrice résultante est soumise à une décomposition en valeurs singulières afin de calculer les valeurs propres et vecteurs propres de l’ordination. Le résultat d’une CA représente donc une ordination dans laquelle les distances de Chi2 entre objets sont préservées (au lieu de la distance euclidienne dans une PCA), le distance de Chi2 n’étant pas influencée par la présence de double-zéros. Ainsi, la CA constitue une méthode d’ordination puissante pour l’analyse des abondances brutes d’espèces (i.e. sans pré-transformation). Contrairement à la PCA, la CA peut être appliquée sur des données quantitatives ou binaires (telles que des abondance ou absence-présence d’espèces). Comme dans une PCA, le critère de Kaiser-Guttman peut être utilisé pour identifier les axes significatifs d’une CA, et les scores des objets le long des axes d’ordination peuvent être extraits pour être utlisés dans des régressions multiples par exemple. Exécuter une CA sur les données d’abondance d’espèces: # Effectuer une CA à l&#39;aide de la fonction cca() (NB: cca() # est utilisée à la fois pour les CA et CCA) spe.ca &lt;- cca(spe) # Identifier les axes significatifs ev &lt;- spe.ca$CA$eig ev[ev &gt; mean(ev)] n = length(ev) barplot(ev, main = &quot;Eigenvalues&quot;, col = &quot;grey&quot;, las = 2) abline(h = mean(ev), col = &quot;red&quot;) legend(&quot;topright&quot;, &quot;Average eigenvalue&quot;, lwd = 1, col = 2, bty = &quot;n&quot;) D’après cet histogramme, à partir du sixième axe d’ordination CA6, la proportion de variance expliquée diminue sous la proportion moyenne expliquée par l’ensemble des axes. La sortie R de la CA ci-dessous montre également que les cinq premiers axes d’ordination explique une proportion cumulée de variance expliquée de 84.63%. summary(spe.h.pca) summary(spe.h.pca, diplay = NULL) Les résultats d’une CA sont présentés sous R de la même façon que ceux d’une PCA. On y observe que le premier axe CA1 explique 51.50% de la variation de l’abondance des espèces tandis que le second axe CA2 explique 12.37% de la variation. par(mfrow = c(1, 2)) #### scaling 1 plot(spe.ca, scaling = 1, type = &quot;none&quot;, main = &quot;CA - biplot scaling 1&quot;, xlab = c(&quot;CA1 (%)&quot;, round((spe.ca$CA$eig[1]/sum(spe.ca$CA$eig)) * 100, 2)), ylab = c(&quot;CA2 (%)&quot;, round((spe.ca$CA$eig[2]/sum(spe.ca$CA$eig)) * 100, 2))) points(scores(spe.ca, display = &quot;sites&quot;, choices = c(1, 2), scaling = 1), pch = 21, col = &quot;black&quot;, bg = &quot;steelblue&quot;, cex = 1.2) text(scores(spe.ca, display = &quot;species&quot;, choices = c(1), scaling = 1), scores(spe.ca, display = &quot;species&quot;, choices = c(2), scaling = 1), labels = rownames(scores(spe.ca, display = &quot;species&quot;, scaling = 1)), col = &quot;red&quot;, cex = 0.8) #### scaling 2 plot(spe.ca, scaling = 1, type = &quot;none&quot;, main = &quot;CA - biplot scaling 2&quot;, xlab = c(&quot;CA1 (%)&quot;, round((spe.ca$CA$eig[1]/sum(spe.ca$CA$eig)) * 100, 2)), ylab = c(&quot;CA2 (%)&quot;, round((spe.ca$CA$eig[2]/sum(spe.ca$CA$eig)) * 100, 2)), ylim = c(-2, 3)) points(scores(spe.ca, display = &quot;sites&quot;, choices = c(1, 2), scaling = 2), pch = 21, col = &quot;black&quot;, bg = &quot;steelblue&quot;, cex = 1.2) text(scores(spe.ca, display = &quot;species&quot;, choices = c(1), scaling = 2), scores(spe.ca, display = &quot;species&quot;, choices = c(2), scaling = 2), labels = rownames(scores(spe.ca, display = &quot;species&quot;, scaling = 2)), col = &quot;red&quot;, cex = 0.8) Ces biplots montrent qu’un groupe de sites (à gauche) possède des communautés similaires de poissons caractérisées par de nombreuses espèces dont GAR, TAN, PER, ROT, PSO et CAR; dans le coin supérieur droit, un second groupe de sites se caractérisent par les espèces LOC, VAI et TRU; le dernier groupe de sites dans le coin inférieur droit montrent des communautés abondantes en BLA, CHA et OMB. Défi 4 Exécuter une CA sur les données d’abondance des espèces d’acariens (données mite). Quels sont les axes importants? Quels groupes de sites pouvez-vous identifier? Quelles espèces sont liées à chaque groupe de sites? Défi 4 - Solution Votre code devrait s’apparenter à celui-ci: # CA mite.spe.ca &lt;- cca(mite.spe) # Quels sont les axes importants? ev &lt;- mite.spe.ca$CA$eig ev[ev &gt; mean(ev)] n = length(ev) barplot(ev, main = &quot;Eigenvalues&quot;, col = &quot;grey&quot;, las = 2) abline(h = mean(ev), col = &quot;red&quot;) legend(&quot;topright&quot;, &quot;Average eigenvalue&quot;, lwd = 1, col = 2, bty = &quot;n&quot;) # Résultats summary(mite.spe.ca, display = NULL) # Biplot windows() plot(mite.spe.ca, scaling = 1, type = &quot;none&quot;, xlab = c(&quot;PC1 (%)&quot;, round((mite.spe.ca$CA$eig[1]/sum(mite.spe.ca$CA$eig)) * 100, 2)), ylab = c(&quot;PC2 (%)&quot;, round((mite.spe.ca$CA$eig[2]/sum(mite.spe.ca$CA$eig)) * 100, 2))) points(scores(mite.spe.ca, display = &quot;sites&quot;, choices = c(1, 2), scaling = 1), pch = 21, col = &quot;black&quot;, bg = &quot;steelblue&quot;, cex = 1.2) text(scores(mite.spe.ca, display = &quot;species&quot;, choices = c(1), scaling = 1), scores(mite.spe.ca, display = &quot;species&quot;, choices = c(2), scaling = 1), labels = rownames(scores(mite.spe.ca, display = &quot;species&quot;, scaling = 1)), col = &quot;red&quot;, cex = 0.8) Et votre biplot devrait ressembler à celui-ci: "],["analyse-en-coordonnées-principales.html", "Chapitre 12 Analyse en coordonnées principales", " Chapitre 12 Analyse en coordonnées principales La PCA, comme la CA, impose une préservation des distances entre objets: la distance euclidienne dans le cas de la PCA, et la distance de Chi2 dans la CA. Si l’objectif est d’ordonner les objets sur la base d’une autre mesure de distance plus appropriée au problème, la PCoA constitue une technique de choix. Dans une PCA, les données sont pivotées de façon à ce que la première composante principale (correspondant à une combinaison linéaire des descripteurs) explique la plus forte proportion de variation possible; la contribution de chaque descripteur (espèces ou variables environnementales) à chaque composante principale peut alors être évaluée d’après son score. La PCoA est une seconde méthode d’ordination sans contrainte dans laquelle les points sont ajoutés les uns après les autres à l’espace d’ordination en utilisant la distance euclidienne ou n’importe quelle mesure de distance (dissimilarité) métrique vous choisissez. Un premier point est ainsi placé dans l’espèce d’ordination, puis un second point placé à la valeur de distance du premier, puis un troisième et ainsi de suite en ajoutant autant d’axes (de dimensions) que nécessaire. Il est parfois difficile de choisir entre effectuer une PCA ou une PCoA. La PCA permet toutefois de réduire des données multivariables en un faible nombre de dimensions tandis que la PCoA est utile pour visualiser les distances entre sites (ou objets). La PCoA est aussi particulièrement adaptées pour les jeux de données présentant plus de colonnes que de lignes. Par exemple, si des centaines d’espèces ont été observées dans un petit nombree de quadrats, une approche basée sur une PCoA utilisant la distance de Bray-Curtis (voir ci-dessous) peut être plus adaptée. PCoA avec DoubsSpe (transformé Hellinger): # En utilisant la fonction cmdscale() ?cmdscale cmdscale(dist(spe.hel), k=(nrow(spe)-1), eig=TRUE) # En utilisant la fonction pcoa() ?pcoa spe.h.pcoa&lt;-pcoa(dist(spe.hel)) # Extraction des résultats spe.h.pcoa # Représentation graphique biplot.pcoa(spe .h.pcoa, spe.hel, dir.axis2=-1) Les résultats de cette PCoA sont: Et le graphique: Vous pouvez aussi exécuter cette PCoA avec une autre mesure de distance (ex. Bray-Curtis): spe.bray.pcoa &lt;- pcoa(spe.db) # il s&#39;agit de la matrice de distances de Bray-Curtis qu&#39;on a générée plus tôt spe.bray.pcoa biplot.pcoa(spe.bray.pcoa, spe.hel, dir.axis2 = -1) # Le choix d&#39;une mesure de distance est très important car ça # influence les résultats! Défi 5 Exécuter une PCoA sur les données d’abondance des espèces d’acariens transformées Hellinger (données mite). Quels sont les axes importants? Quels groupes de sites pouvez-vous identifier? Quelles espèces sont liées à chaque groupe de sites? Comment les résultats de cette PCoA se comparent-ils avec ceux de la PCA? Défi 5 - Solution mite.spe.h.pcoa &lt;- pcoa(dist(mite.spe.hel)) mite.spe.h.pcoa windows() biplot.pcoa(mite.spe.h.pcoa, mite.spe.hel, dir.axis2 = -1) Représentation graphique: Les espèces 16 et 31 sont plus éloignées des autres espèces en termes de distance, et donc leur distribution entre les sites est très différente de celle des autres espèces d’acariens. Les sites dont les étiquettes se chevauchent sont de bons exemples de sites à forte similarité en termes de communautés d’acariens. "],["positionnement-multidimensionnel-non-métrique.html", "Chapitre 13 Positionnement multidimensionnel non-métrique", " Chapitre 13 Positionnement multidimensionnel non-métrique Les méthodes d’ordination non contrainte présentées ci-dessus permettent d’organiser les objets (ex. les sites) caractérisés par des descripteurs (ex. les espèces) dans un espace comprenant l’ensemble des dimensions décrites par l’ellipsoïde représentant le nuage des points de données. En d’autres termes, la PCA, la CA et la PCoA calculent un grand nombre d’axes d’ordination (nombre proportionnel au nombre de descripteurs) représentant la variation des descripteurs entre sites et préservant les distances entre objets (distance euclidienne dans une PCA, distance de Chi2 dans une CA et distance définie par l’utilisateur dans une PCoA). L’utilisateur peut ensuite sélectionner les axes d’intérêt (généralement les deux premiers axes d’ordination) pour représenter les objets dans un biplot. Le biplot produit représente ainsi correctement les distances entre objets (ex. la similarité des sites), mais ne permet pas de représenter l’ensemble des dimensions de la variation dans l’espace d’ordinations (étant donnée que l’Axe 3, l’Axe 4,..., l’Axe n’apparaissent pas sur le biplot, mais contribuent tout de même à expliquer la variation entre objets). Dans certains cas, la priorité n’est pas de préserver la distance exacte entre les objets, mais au contraire de représenter aussi fidèlement que possible les relations entre objets selon un petit nombre d’axes (généralement deux ou trois) spécifiés par l’utilisateur. Dans de tels cas, le positionnement multidimensionnel non-métrique (NMDS) est la solution. Si l’utilisateur définit un nombre d’axe égal à deux, le biplot produit par le NMDS correspond à la meilleure solution graphique pour représenter en deux dimensions la similarité entre objets (les objets dissimilaires étant les plus éloignées, et les objets similaires étant les plus proches). De plus, le NMDS permet à l’utilisateur de choisir la mesure de distance qu’il souhaite pour ordonner les objets. Afin de trouver la meilleure représentation des objets, le NMDS applique une procédure itérative qui vise à positionner les objets dans le nombre spécifié de dimensions de façon à minimiser une fonction de stress (variant de 0 à 1) qui mesure la qualité de l’ajustement de la distance entre objets dans l’espace d’ordination. Ainsi, plus la valeur du stress sera faible, plus la représentation des objets dans l’espace d’ordination sera exacte. Un second moyen d’évaluer l’exactitude d’un NMDS consiste à construire un diagramme de Shepard qui représente les distances entre objets sur le biplot d’ordination en fonction de leurs distances réelles. Le R2 obtenu à partir de la régression entre ces deux types de distance mesure la qualité de l’ajustement du NMDS. # NMDS spe.nmds &lt;- metaMDS(spe, distance = &quot;bray&quot;, k = 2) ### Extraction des résultats spe.nmds ### Évaluation de la qualité de l&#39;ajustement et construction du ### diagramme de Shepard spe.nmds$stress stressplot(spe.nmds, main = &quot;Shepard plot&quot;) # Construction du biplot windows() plot(spe.nmds, type = &quot;none&quot;, main = paste(&quot;NMDS/Bray - Stress=&quot;, round(spe.nmds$stress, 3)), xlab = c(&quot;NMDS1&quot;), ylab = c(&quot;NMDS2&quot;)) points(scores(spe.nmds, display = &quot;sites&quot;, choices = c(1, 2)), pch = 21, col = &quot;black&quot;, bg = &quot;steelblue&quot;, cex = 1.2) text(scores(spe.nmds, display = &quot;species&quot;, choices = c(1)), scores(spe.nmds, display = &quot;species&quot;, choices = c(2)), labels = rownames(scores(spe.nmds, display = &quot;species&quot;)), col = &quot;red&quot;, cex = 0.8) Le diagramme de Shepard identifie une forte corrélation entre les distances observées et les distances de l’ordination (R2 &gt; 0.95), et donc une bonne qualité de l’ajustement du NMDS. Le biplot du NMDS identifie un groupe de sites caractérisés par les espèces BLA, TRU, VAI, LOC, CHA et OMB, tandis que les autres espèces caractérisent un groupe de sites situés dans le coin supérieur droit du biplot. Quatre sites situés dans le coin inférieur droit sont fortement différents des autres. Défi 6 Exécuter un NMDS sur les données d’abondance des espèces d’acariens (données mite) en deux dimensions à partir de distances de Bray-Curtis. Évaluer la qualité de l’ajustement et interpréter le biplot. Défi 5 - Solution ### NMDS mite.spe.nmds &lt;- metaMDS(mite.spe, distance = &quot;bray&quot;, k = 2) ### Extraction des résultats mite.spe.nmds ### Évaluation de la qualité de l&#39;ajustement mite.spe.nmds$stress stressplot(mite.spe.nmds, main = &quot;Shepard plot&quot;) ### Construction du biplot windows() plot(mite.spe.nmds, type = &quot;none&quot;, main = paste(&quot;NMDS/Bray - Stress=&quot;, round(mite.spe.nmds$stress, 3)), xlab = c(&quot;NMDS1&quot;), ylab = c(&quot;NMDS2&quot;)) points(scores(mite.spe.nmds, display = &quot;sites&quot;, choices = c(1, 2)), pch = 21, col = &quot;black&quot;, bg = &quot;steelblue&quot;, cex = 1.2) text(scores(mite.spe.nmds, display = &quot;species&quot;, choices = c(1)), scores(mite.spe.nmds, display = &quot;species&quot;, choices = c(2)), labels = rownames(scores(mite.spe.nmds, display = &quot;species&quot;)), col = &quot;red&quot;, cex = 0.8) La corrélation entre distance observée et distance d’ordination (R2 &gt; 0.91) et la valeur de stress relativement faible identifient une bonne qualité de l’ajustement du NMDS. Aucun groupe de sites ne peut être précisément identifié à partir du biplot, ce qui montre que la plupart des espèces sont présentes dans la plupart des sites, i.e. peu de sites présentent des communautés distinctes. "],["sommaire.html", "Chapitre 14 Sommaire", " Chapitre 14 Sommaire L’ordination constitue une puissante méthode d’analyse pour étudier les relations entre objets caractérisés par différents descripteurs (ex. des sites décrits par leurs communautés biologiques, ou leurs variables environnementales), mais de nombreuse méthodes d’ordination existent. Ces méthodes diffèrent principalement par le type de distance qu’elles préservent, le type de variables qu’elles autorisent, et le nombre de dimensions de l’espace d’ordination. Pour mieux guider votre choix de la méthode d’ordination à utiliser, le tableau ci-dessous identifie les caractéristiques de chacune des quatre méthodes d’ordination présentées lors de cet atelier. Lors du prochaine atelier, vous verrez comment identifier les relations entre variables environnementales et communautés biologiques décrivant un même ensemble de sites, à l’aide des méthodes d’analyses canoniques. "],["resources-additionnels.html", "Chapitre 15 Resources additionnels", " Chapitre 15 Resources additionnels "],["réferences.html", "Chapitre 16 Réferences", " Chapitre 16 Réferences "]]
