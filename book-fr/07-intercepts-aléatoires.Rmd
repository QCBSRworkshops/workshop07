# Intercepts aléatoires

Maintenant que nous avons la distribution d'erreur appropriée, nous
pouvons tester l'importance des interceptes aléatoires (pour
*population* et *génotype*) en comparant des modèles nichés avec et sans
les effets aléatoires d'intérêt en utilisant soit:

1.  l'approche théorique d'information (tel que le Critère
    d'Information d'Akaike; AIC), qui, comme nous l'avons vu dans
    [l'atelier
    6](r_workshop6#coding_potential_models_and_model_selection) examine
    plusieurs hypothèses concurrentes (modèles) simultanément pour
    identifier le modèle avec le pouvoir prédictif le plus élevé compte
    tenu des données. Nous allons encore une fois utiliser le AICc pour
    corriger les petites tailles d'échantillon.
2.  l'approche fréquentiste (test d'hypothèse nulle traditionnelle),
    où deux modèles nichés sont comparés en utilisant le tests de
    rapport de vraisemblance de la fonction `anova()`. Il est important
    de noter qu'avec cette approche, nous testons une hypothèse nulle
    d'une variance de zéro, mais étant donné que nous ne pouvons pas
    avoir un écart négatif, nous testons le paramètre à la limite de sa
    région réalisable. Par conséquent, la valeur de p rapporté est
    environ le double de ce qu'elle devrait être (c. nous avons
    tronquée la moitié des valeurs possibles ; celles qui tombent en
    dessous de 0).

``` {.rsplus|}
summary(mpl1)$varcor

# popu seulement
mpl1.popu <- glmer(total.fruits ~ nutrient*amd + rack + status + 
                     (1|X) +
                     (1|popu), 
                     data=dat.tf, family="poisson", control=glmerControl(optimizer="bobyqa"))

# gen seulement
mpl1.gen <-glmer(total.fruits ~ nutrient*amd + rack + status + 
                   (1|X) +
                   (1|gen), 
                   data=dat.tf, family="poisson", control=glmerControl(optimizer="bobyqa"))

# Approche AICc
ICtab(mpl1, mpl1.popu, mpl1.gen, type = c("AICc"))
#            dAICc df
# mpl1       0.0   10
# mpl1.popu  2.0   9 
# mpl1.gen   16.1  9 

# Approche fréquentiste (Likelihood Ratio Test)
anova(mpl1,mpl1.popu)
# Data: dat.tf
# Df         AIC  BIC      logLik  deviance  Chisq   Chi    Df    Pr(>Chisq)  
# mpl1.popu  9    5017.4   5057.4  -2499.7   4999.4                           
# mpl1       10   5015.4   5059.8  -2497.7   4995.4  4.0639  1    0.04381 *
#   ---
#   Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

anova(mpl1,mpl1.gen)
# Df        AIC  BIC     logLik deviance  Chisq    Chi     Df   Pr(>Chisq)    
# mpl1.gen  9    5031.5  5071.5 -2506.8   5013.5                             
# mpl1      10   5015.4  5059.8 -2497.7   4995.4   18.177  1   2.014e-05 ***
#   ---
#   Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
```

Notez que le modèle sans l'intercept aléatoire pour *génotype* est à
moins de deux unités AICc du modèle complet, ce qui indique que les deux
modèles sont tout aussi plausibles (i.e. peu de soutien pour inclure un
intercept aléatoire pour le génotype). Toutefois, lorsque nous utilisons
la comparaison de vraisemblance de modèles nichés (anova()), et
corrigeons pour les valeurs p gonflés par un facteur de 2, nous trouvons
que dans les deux cas, p \<0,05 et donc le modèle avec les deux effets
aléatoires (mpl1) est sélectionné.

## Représentation graphique des paramètres du modèle

Une représentation graphique des paramètres du modèle peut être obtenue
en utilisant la fonction `coefplot2`. Par exemple, pour afficher les
paramètres de variance de nos trois intercepts aléatoires:

``` {.rsplus|}
# Paramètres de la variance
coefplot2(mpl1,ptype="vcov",intercept=TRUE,main="Random effect variance")

# Effets fixes
coefplot2(mpl1,intercept=TRUE,main="Fixed effect coefficient")
```

![](images//glmm_coefplot_int.png){width="450"}
![](images//glmm_coefplot_pars.png){width="400"}

Notez que les barres d'erreur ne sont visibles que pour les effets
fixes parce `glmer` ne nous donne pas d'informations sur l'incertitude des paramètres de variance.

## Graphiques des intercepts aléatoires

Nous pouvons également extraire les prédictions des effets aléatoires en
utilisant la fonction `ranef` et les tracer en utilisant la fonction
`dotplot`, qui crée un graphique à deux facettes pour chaque effet
aléatoire (popu et gen). Notez : la fonction `grid.arrange` est utilisée
pour supprimer l'effet aléatoire au niveau de l'observation (i.e. (1
\| X)).

``` {.rsplus|}
pp <- list(layout.widths=list(left.padding=0, right.padding=0),
           layout.heights=list(top.padding=0, bottom.padding=0))
r2 <- ranef(mpl1,condVar=TRUE)
d2 <- dotplot(r2, par.settings=pp)
grid.arrange(d2$gen,d2$popu,nrow=1)
```

![](images//glmm_dtoplot.png){.align-center width="450"}

Le graphique indique un peu de variabilité régionale parmi les
populations où les populations espagnoles (SP) ont des valeurs plus
élevées que les populations suédoises (SW) et néerlandais (NL). La
différence entre les génotypes semble largement induite par le génotype
34.

## Pentes aléatoires

++++ Section bonus: Pentes aléatoires\|

**Notez**: Pour cet ensemble de données, nous ne pouvons pas tester les
pentes aléatoires, car lorsque les pentes aléatoires sont inclus dans le
modèle, on obtient une forte corrélation entre les intercepts et pentes
aléatoires. Ces fortes corrélations peuvent être dues à une
\"sur-paramétrisation\" de notre modèle. Donc, bien qu'il pourrait y
avoir une variation de l'effet nutriments ou herbivorie au niveau du
génotype ou de la population (et bien que cette variation peut être ce
qui nous intéresse le plus), il n'y a tout simplement pas suffisamment
de données pour tester ces effets avec confiance.

Regardons un exemple avec une pente aléatoire pour *clipping*:

```{r, echo = TRUE, eval = FALSE}
# Poisson-lognormal avec pentes aléatoires pour popu et amd
mpl2 <- glmer(total.fruits ~ nutrient*amd + rack + status + 
                (1|X) +
                (amd|popu) +
                (amd|gen),
              data=dat.tf, family="poisson", control=glmerControl(optimizer="bobyqa"))
```

Examinons les coefficients de variance en utilisant `summary` du modèle.
Nous pourrions aussi examiner la matrice de corrélation entre les
intercepts et pentes aléatoires. Une troisième option est d'utiliser la
fonction `printvc` qui montre les matrices de variance-covariance avec
un signe égal ( = ) à côté de toute composante de covariance avec une
forte corrélation.

```{r, echo = TRUE, eval = FALSE}
summary(mpl2) # option 1
attr(VarCorr(mpl2)$gen,"correlation") # option 2
printvc(mpl2) # option 3
```

Notez la corrélation parfaite entre (Intercept) et amdclipped (pente).
++++
