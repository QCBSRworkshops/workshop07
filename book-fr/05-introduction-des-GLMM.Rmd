# (PART\*) Modèles Linéaires Généralisés Mixtes (GLMMs) en `R` {-}

# Introduction aux GLMM

Les modèles linéaires généralisés mixtes (GLMM) sont une extension des modèles linéaires généralisés (GLM) qui prennent en compte une structure supplémentaire dans l'ensemble des données.

Ils suivent des étapes similaires à celles que nous venons de présenter avec les modèles linéaires mixtes (LMM):

- **1.** Ils incorporent les effets aléatoires (comme les LMMs)
 
- **2.** Permettent de gérer des données non-normales (en laissant les erreurs prendre différentes familles de distribution - e.g Poisson ou binomial négatif) (comme les GLMs; atelier 6)


---

Comme pour la partie LMM de cet atelier, nous allons travailler sur le matériel GLMM avec un ensemble de données afin de mieux comprendre le fonctionnement des GLMMs et comment les implémenter dans `R`.

Dans le jeu de données `Arabidopsis`, l'effet de la disponibilité des nutriments et de l'herbivorie (**effets fixes**) sur la production de fruits (**variable de réponse**) d'*Arabidopsis thaliana* a été évalué en mesurant 625 plantes dans 9 populations différentes, chacune comprenant 2 à 3 génotypes différents (**effets aléatoires**).

Chargez les données `Arabidopsis` `banta_totalfruits.csv` dans `R`.

```{r, echo = TRUE, eval = TRUE}
dat.tf <- read.csv("data/banta_totalfruits.csv")

# Dans cet ensemble de données, les en-têtes de colonne sont définis comme suit:
# popu: facteur avec un niveau pour chaque population
# gen: facteur avec un niveau pour chaque génotype
# nutrient: facteur avec niveau bas (valeur = 1) ou haut (valeur = 8)
# amd: facteur précisant l'absence ou la présence d'herbivorie
# total.fruits: nombre entier indiquant le nombre de fruits par plante
```

# Choisir la distribution des erreurs

Nous devons maintenant choisir une distribution d'erreurs. Ce choix sera informé par la structure de nos données. 

La variable réponse constitue des données d'abondance, donc nous devons choisir une **distribution de Poisson** (i.e variance égale à la moyenne)

Jetons-y un coup d'oeil:

```{r, echo = TRUE, eval = TRUE}
#Avant d'aller plus loin, nous devons choisir une distribution d'erreurs. Ce choix sera guidé par la structure de nos données. 
# Notre variable de réponse est une donnée de comptage, ce qui suggère que nous avons besoin d'une distribution de Poisson (c'est-à-dire que la variance est égale à la moyenne).
hist(dat.tf$total.fruits, breaks = 50, col = 'blue', main = '',
     xlab = 'Total fruits', ylab = 'Count')
```

Cependant, comme nous le verrons, la variance de chaque groupe augmente beaucoup plus rapidement que prévu...

---

**Exploration de la variance **

Examinons de plus près la variance au sein de nos données.

Pour illustrer l'hétérogénéité de la variance, nous allons créer des *boxplots* du **log** du nombre total de fruits (**variable réponse**) par rapport aux différents facteurs environnementaux.

Créons d'abord de nouvelles variables qui représentent toutes les combinaisons de **nutriments** x **herbivorie** x **facteur aléatoire**.

```{r, echo = TRUE, eval = TRUE}
# Explorons la variance dans nos données
# Créez de nouvelles variables qui représentent chaque combinaison de variables.
dat.tf <- within(dat.tf,
{
  # genotype x nutrient x clipping
  gna <- interaction(gen,nutrient,amd)
  gna <- reorder(gna, total.fruits, mean)
  
  # population x nutrient x clipping
  pna <- interaction(popu,nutrient,amd)
  pna <- reorder(pna, total.fruits, mean)
})
```

Maintenant, visualisons:


```{r, echo = TRUE, eval = TRUE}
# Boxplot of total fruits vs genotype x nutrient x clipping interaction
ggplot(data = dat.tf, 
       aes(factor(x = gna), y = log(total.fruits + 1))) +
  geom_boxplot(colour = "skyblue2", 
               outlier.shape = 21,
               outlier.colour = "skyblue2") +
  ylab("log (Total fruits)\n") + # \n creates a space after the title
  xlab("\nGenotype x nutrient x clipping") + # space before the title
  theme_bw() + theme(axis.text.x = element_blank()) +
  stat_summary(fun = mean, geom = "point", colour = "red")
```


De même, la variance du total de fruits montre une grande hétérogénéité entre les populations (population x nutriments x herbivorie).

---

**Retour au choix de la distribution des erreurs** 

Comme nous venons de voir, il existe une importante hétérogénéité parmi la variance de chaque groupe, même lorsque la variable réponse est transformée (i.e. log).

Pour identifier la famille de distribution la plus appropriée, nous pouvons examiner un graphique de diagnostic de **la variance de chaque groupe par rapport à leurs moyennes**. Nous présentons un exemple ci-dessous pour le regroupement par génotype x nutriments x herbivore (clipping).

- 1. Si nous observons une relation linéaire entre la variance et la moyenne avec une pente = 1, une famille de Poisson serait appropriée,

- 2. Si nous observons une relation moyenne-variance linéaire avec une pente> 1 (c. $Var = \varphi\mu$ où $\varphi > 1$), la famille quasi-Poisson (tel que présenté ci-dessus) doit être utilisée,

- 3. Enfin, une relation quadratique entre la variance et la moyenne (c. $Var = \mu(1+\alpha) or \mu(1+\mu/k)$), est caractéristique des données surdispersées résultant d'une hétérogénéité sous-jacente entre les échantillons. Dans ce cas, la distribution binomiale négative (Poisson-gamma) serait plus appropriée.

```{r, echo = TRUE, eval = TRUE}
# Figure diagnostique de variances par groupe vs moyennes par groupe (genotype x nutrient x clipping grouping). 
# Code pour créer la figure: https://github.com/QCBSRworkshops/workshop07/blob/main/pres-fr/data/glmm_e.r

# On remarque beaucoup de variation entre les variances des échantillons dans les données transformées 
# Par exemple, entre génotypes:
grpVars <- tapply(dat.tf$total.fruits, dat.tf$gna, var)

grpMeans <- tapply(dat.tf$total.fruits,dat.tf$gna, mean)

# Quasi-Poisson
lm1 <- lm(grpVars~grpMeans-1) 
phi.fit <- coef(lm1)
# Le -1 specifie un modèle avec une ordonnée à l'origine de 0

# Binomiale négative
lm2 <- lm(grpVars ~ I(grpMeans^2) + offset(grpMeans)-1)
k.fit <- 1/coef(lm2)
# offset() spécifie qu'on veut ajouter un terme pour les moyennes de groupes avec un coefficient fixé à 1

# Non-parametric loess fit
Lfit <- loess(grpVars ~ grpMeans)

# La figure
plot(grpVars ~ grpMeans, xlab = "Group means", ylab = "Group variances" )
abline(a = 0, b = 1, lty = 2)
text(105,500, "Poisson")
curve(phi.fit*x, col = 2, add = TRUE)
# bquote() remplace des valeurs numériques dans des équations avec des symboles
text(110,3900,
     bquote(paste("QP: ", sigma^2==.(round(phi.fit,1))*mu)), col = 2)
curve(x*(1+x/k.fit), col = 4, add = TRUE)
text(104,7200, paste("NB: k = ", round(k.fit, 1), sep = ""), col = 4)
mvec <- 0:120
lines(mvec, predict(Lfit, mvec), col = 5)
text(118, 2000, "loess", col = 5)
```

La figure ci-dessus montre qu'un modèle linéaire quasi-Poisson sera peut-être mieux qu'une binomiale négative, mais il faudrait *continuer le processus de modélisation*.


# GLMM Poisson 

**Compte tenu de la relation moyenne-variance, nous avons besoin d'un modèle qui tient compte de la surdispersion.**

Pour comprendre pourquoi, commençons avec un modèle avec une distribution de Poisson.

Pour lancer un GLMM dans `R`, nous faisons appel à la fonction `glmer()` de la librairie `lme4`:

```{r, echo = TRUE, eval = TRUE}
# GLMM Poisson
# Nous avons besoin d'un modèle qui tient compte de la surdispersion.
# Commençons avec un modèle Poisson
mp1 <- glmer(total.fruits ~ nutrient*amd + rack + status +
             (1|popu)+
             (1|gen),
             data = dat.tf, family = "poisson")
```

**Effets aléatoires** : `(1|popu)` et `(1|gen)`. Nous faisons varier les ordonnées à l'origine pour les différentes populations (`popu`) et génotypes (`gen`).

---

**Vérification de la surdispersion**

On vérifie la surdispersion en utilisant la fonction `overdisp_fun()` (Bolker *et al*. 2011) qui divise la déviance des résidus (de Pearson) par leurs degrés de liberté.

La fonction teste si le **rapport est plus grand que 1**.

Effectuons ce test:

```{r}
# Téléchargez le code glmm_funs.R de la page wiki et exécutez la fonction dans R
source(file = "data/glmm_funs.R")
# Surdispersion?
overdisp_fun(mp1)
# Le rapport est significativement > 1
```

**Le rapport est significativement > 1**

Comme on s'y attendait, nous devons modéliser une **distribution différente** où la variance augmente plus rapidement que la moyenne.


# GLMM binomiale négative

Une option pour une distribution où la variance augmente plus rapidement avec la moyenne est la distribution **binomiale négative** (ou Poisson-gamma). Rappelons que la distribution binomiale négative répond à l'hypothèse selon laquelle la variance est proportionnelle au carré de la moyenne.

On peut modéliser cette distribution avec la fonction `glmer.nb()`:

```{r, echo = TRUE, eval = TRUE}
# GLMM binomial négatif utilisant la fonction glmer.nb()
mnb1 <- glmer.nb(total.fruits ~ nutrient*amd + rack + status +
                 (1|popu)+
                 (1|gen),
                 data = dat.tf,
                 control = glmerControl(optimizer = "bobyqa"))
# 'control' spécifie la façon dont nous optimisons les valeurs des paramètres
```

On teste encore une fois la surdispersion du modèle:

```{r, echo = TRUE, eval = TRUE}
# Surdispersion?
overdisp_fun(mnb1)
# Le rapport est beaucoup plus près de 1 mais la valeur de p < 0.05
```

**Le rapport est beaucoup plus près de 1 mais la valeur de p < 0.05**

# GLMM Poisson-lognormale

Une deuxième option pour une distribution où la variance augmente plus rapidement avec la moyenne est la distribution **Poisson-lognormale**. Ce modèle place effectivement une priorité lognormale sur $εi$. 

Une distribution Poisson-lognormale avec une moyenne de $µ$ et une variance antérieure lognormale de $σ2$ a une variance:

$var(y) = µ + µ2 [exp(σ2) - 1]$

En revanche, nous avons vu que la distribution binomiale négative (Poisson-gamma) était donné par:

$var(y) = µ + µ2/k$

En générale, la variance $σ2$ dans la distribution Poisson-lognormal dépendra du niveau de regroupement que nous sélectionnons (i.e. au niveau individuel, génotype ou de la population). Donc, le modèle de Poisson-lognormal nous permet d'assigner l'agrégation observée à différentes sources d'hétérogénéité. 

Pour mettre en œuvre le **effet aléatoire au niveau de l'observation**, nous allons l'évaluer au niveau individuel. Pour ce faire, il suffit de placer un **effet aléatoire au niveau des observations** dans la formule du modèle.

Voir Harrison (2014) pour plus de détails https://doi.org/10.7717/peerj.616.

Pour ce faire, nous créons tout d'abord une variable nommée `X`:

```{r, echo = TRUE, eval = TRUE}
# GLMM Poisson-lognormale

# Cette variable est déjà dans vos données "dat.tf", mais voici comment la créer.
dat.tf$X <- 1:nrow(dat.tf)
```

On traite la surdispersion en ajoutant l'effet `(1|X)` dans la formule:

```{r, echo = TRUE, eval = TRUE}
# Tenir compte de la surdispersion
mpl1 <- glmer(total.fruits ~ nutrient*amd + rack + status +
              (1|X) +
              (1|popu)+
              (1|gen),
data = dat.tf, family = "poisson",
control = glmerControl(optimizer = "bobyqa"))
```

On teste finalement pour la présence de surdispersion:

```{r, echo = TRUE, eval = TRUE}
# Surdispersion?
overdisp_fun(mpl1)
# Le rapport est maintenant conforme avec notre critère, soit < 1
```

**Le rapport est maintenant conforme avec notre critère, soit < 1!**

---

## Intercepts aléatoires

Maintenant que nous avons la distribution d'erreur appropriée, nous pouvons tester l'importance des interceptes aléatoires (pour population et génotype) en comparant des modèles nichés **avec** et **sans** les effets aléatoires d'intérêt en utilisant soit:

- *1. L'approche théorique d'information (tel que le Critère d'Information d'Akaike; AIC)*, qui, comme nous l'avons vu apres examine plusieurs hypothèses concurrentes (modèles) simultanément pour identifier le modèle avec le pouvoir prédictif le plus élevé compte tenu des données. Nous allons encore une fois utiliser le AICc pour corriger les petites tailles d'échantillon.

- *2. L'approche fréquentiste (test d'hypothèse nulle traditionnelle)*, où deux modèles nichés sont comparés en utilisant le tests de rapport de vraisemblance de la fonction anova(). Il est important de noter qu’avec cette approche, nous testons une hypothèse nulle d'une variance de zéro, mais étant donné que nous ne pouvons pas avoir un écart négatif, nous testons le paramètre à la limite de sa région réalisable. Par conséquent, la valeur de p rapporté est environ le double de ce qu'elle devrait être (c. nous avons tronquée la moitié des valeurs possibles ; celles qui tombent en dessous de 0).


```{r, echo = TRUE, eval = TRUE}
# popu seulement
mpl1.popu <- glmer(total.fruits ~ nutrient*amd + rack + status + 
                     (1|X) +
                     (1|popu), 
                     data=dat.tf, family="poisson", control=glmerControl(optimizer="bobyqa"))
 
# gen seulement
mpl1.gen <-glmer(total.fruits ~ nutrient*amd + rack + status + 
                   (1|X) +
                   (1|gen), 
                   data=dat.tf, family="poisson", control=glmerControl(optimizer="bobyqa"))
 
# Approche AICc
ICtab(mpl1, mpl1.popu, mpl1.gen, type = c("AICc"))

# Approche fréquentiste (Likelihood Ratio Test)
anova(mpl1,mpl1.popu)

anova(mpl1,mpl1.gen)
```

Notez que le modèle sans l'intercept aléatoire pour génotype est à moins de deux unités AICc du modèle complet, ce qui indique que les deux modèles sont tout aussi plausibles (i.e. peu de soutien pour inclure un intercept aléatoire pour le génotype). Toutefois, lorsque nous utilisons la comparaison de vraisemblance de modèles nichés (anova()), et corrigeons pour les valeurs p gonflés par un facteur de 2, nous trouvons que dans les deux cas, p <0,05. **Donc le modèle avec les deux effets aléatoires (mpl1) est sélectionné.**

---

## Représentation graphique des paramètres du modèle

**Maintenant que nous avons choisi notre modèle, visualisons les paramètres du modèle.**

Peut être obtenu en utilisant la fonction `coefplot2()`de la librairie `coefplot2`:

*Notez: Cette librairie n'est pas sur le CRAN! On utilise la librairie `remotes` pour l'installer à partir de GitHub.*

```{R install_coefplot2, eval = TRUE, results='hide'}
# Visualisons les paramètres du modèle

# Cette librairie n'est pas sur le CRAN! On utilise la librairie `remotes` pour l'installer à partir de GitHub.
if (!require("coefplot2"))
  remotes::install_github("palday/coefplot2", subdir = "pkg")
library(coefplot2)
```


```{r, echo = TRUE, eval = TRUE}
# Effets aléatoires
coefplot2(mpl1, ptype = "vcov", intercept = TRUE, main = "Random effect variance")
```

Ici, nous pouvons voir que certains effets aléatoires présentent une plus grande variance que d'autres. 

:::explanation 
La variance des effets aléatoires (σ2i) représente la variance moyenne des effets aléatoires du modèle. Puisque cette variance reflète la variance "moyenne" des effets aléatoires pour les modèles mixtes, elle est également appropriée pour les modèles avec des structures d'effets aléatoires plus complexes, comme les pentes aléatoires ou les effets aléatoires imbriqués. 
:::


```{r, echo = TRUE, eval = TRUE}
# Effets fixes
coefplot2(mpl1, intercept = TRUE, main = "Fixed effect coefficient")
```

:::explanation 
La variance des effets fixes (σ2f) est la variance de la matrice-multiplication β∗X (vecteur de paramètres par matrice de modèle) 
:::

*Notez: Les barres d'erreur sont visibles seulement pour les effets fixes, car `glmer()` ne modélise pas d'incertitude pour les effets aléatoires.*

---

**Visualisation des effets aléatoires**

Vous pouvez extraire les effets aléatoires en utilisant la fonction `ranef()` et les tracer en utilisant un `dotplot()` de la librairie `lattice`.

On constate une variation **inter-population**: 

- Les populations espagnoles (SP) ont des valeurs plus élevées que les populations suédoises (SW) et néerlandaises (NL)

On constate une faible variation **inter-génotype** :

- Les différences entre les génotypes semblent induites par le génotype 34

```{r, echo = TRUE, eval = TRUE}
# dotplot code
pp <- list(layout.widths = list(left.padding = 0, right.padding = 0),
           layout.heights = list(top.padding = 0, bottom.padding = 0))
r2 <- ranef(mpl1, condVar = TRUE)
d2 <- dotplot(r2, par.settings = pp)

grid.arrange(d2$gen, d2$popu, nrow = 1)
```


