# (PART\*) Modèles Linéaires Généralisés Mixtes (GLMMs) en `R` {-}

# Introduction des GLMM

Les modèles linéaires généralisés mixtes (GLMM) sont une extension des modèles linéaires généralisés (GLM) qui prennent en compte une structure supplémentaire dans l'ensemble des données.

Ils suivent des étapes similaires à celles que nous venons de présenter avec les modèles linéaires mixtes (LMM):

- **1.** Ils incorporent les effets aléatoires (comme les LMMs)
 
- **2.** Permettent de gérer des données non-normales (en laissant les erreurs prendre différentes familles de distribution - e.g Poisson ou binomial négatif) (comme les GLMs; atelier 6)


---

Comme pour la partie LMM de cet atelier, nous allons travailler sur le matériel GLMM avec un ensemble de données afin de mieux comprendre le fonctionnement des GLMMs et comment les implémenter dans `R`.

Dans le jeu de données Arabidopsis, l'effet de la disponibilité des nutriments et de l'herbivorie (**effets fixes**) sur la production de fruits (**variable de réponse**) d'Arabidopsis thaliana a été évalué en mesurant 625 plantes dans 9 populations différentes, chacune comprenant 2 à 3 génotypes différents (**effets aléatoires**).

Chargez les données `Arabidopsis` `banta_totalfruits.csv` dans `R`.

```{r, echo = TRUE, eval = TRUE}
dat.tf <- read.csv("data/banta_totalfruits.csv")

## Dans cet ensemble de données, les en-têtes de colonne sont définis comme suit:
# popu facteur avec un niveau pour chaque population
# gen facteur avec un niveau pour chaque génotype
# nutrient facteur avec niveau bas (valeur = 1) ou haut (valeur = 8)
# amd facteur précisant l'absence ou la présence d'herbivorie
# total.fruits nombre entier indiquant le nombre de fruits par plante
```

# Choisir la distribution des erreurs

Nous devons maintenant choisir une distribution d'erreurs. Ce choix sera informé par la structure de nos données. 

La variable réponse constitue des données d'abondance, donc nous devons choisir une **distribution de Poisson** (i.e variance égale à la moyenne)

Let's take a look:

```{r, echo = TRUE, eval = TRUE}
#Avant d'aller plus loin, nous devons choisir une distribution d'erreurs. Ce choix sera guidé par la structure de nos données. 
# Notre variable de réponse est une donnée de comptage, ce qui suggère que nous avons besoin d'une distribution de Poisson (c'est-à-dire que la variance est égale à la moyenne).
hist(dat.tf$total.fruits, breaks = 50, col = 'blue', main = '',
     xlab = 'Total fruits', ylab = 'Count')
```

Cependant, comme nous le verrons, la variance de chaque groupe augmente beaucoup plus rapidement que prévu...

---

**Exploration de la variance **

Examinons de plus près la variance au sein de nos données.

Pour illustrer l'hétérogénéité de la variance, nous allons créer des boîtes à moustaches (boxplots) du **log** du nombre total de fruits (**variable réponse**) par rapport aux différents facteurs environnementaux.

Créons d'abord de nouvelles variables qui représentent toutes les combinaisons de **nutriments** x **herbivorie** x **facteur aléatoire**.

```{r, echo = TRUE, eval = TRUE}
# Explorons la variance dans nos données
# Créez de nouvelles variables qui représentent chaque combinaison de variables.
dat.tf <- within(dat.tf,
{
  # genotype x nutrient x clipping
  gna <- interaction(gen,nutrient,amd)
  gna <- reorder(gna, total.fruits, mean)
  # population x nutrient x clipping
  pna <- interaction(popu,nutrient,amd)
  pna <- reorder(pna, total.fruits, mean)
})
```

Maintenant, visualisons:

```{r, echo = TRUE, eval = TRUE}
library(ggplot2)
# Boxplot of total fruits vs genotype x nutrient x clipping interaction
ggplot(data = dat.tf, aes(factor(x = gna), y = log(total.fruits + 1))) +
  geom_boxplot(colour = "skyblue2", outlier.shape = 21,
  outlier.colour = "skyblue2") +
  ylab("log (Total fruits)\n") + # \n creates a space after the title
  xlab("\nGenotype x nutrient x clipping") + # space before the title
  theme_bw() + theme(axis.text.x = element_blank()) +
  stat_summary(fun = mean, geom = "point", colour = "red")

```


De même, la variance du total de fruits montre une grande hétérogénéité entre les populations (population x nutriments x herbivorie).

---

**Retour au choix de la distribution des erreurs** 

Comme nous venons de le voir, il existe une importante hétérogénéité parmi la variance de chaque groupe, même lorsque la variable réponse est transformée (i.e. log).

Pour identifier la famille de distribution la plus appropriée , nous pouvons examiner un graphique de diagnostic de **la variance de chaque groupe par rapport à leurs moyennes**. Nous présentons un exemple ci-dessous pour le regroupement par génotype x nutriments x herbivore (clipping).

- 1. Si nous observons une relation linéaire entre la variance et la moyenne avec une pente = 1, une famille de Poisson serait appropriée,

- 2. Si nous observons une relation moyenne-variance linéaire avec une pente> 1 (c. Var = φµ où φ > 1), la famille quasi-Poisson (tel que présenté ci-dessus) doit être utilisée,

- 3. Enfin, une relation quadratique entre la variance et la moyenne (c. $Var = µ(1 + α) or µ(1 + µ/k)$), est caractéristique des données surdispersées résultant d'une hétérogénéité sous-jacente entre les échantillons. Dans ce cas, la distribution binomiale négative (Poisson-gamma) serait plus appropriée.

```{r, echo = TRUE, eval = TRUE}
## Run a diagnostic lot of the group variances vs group means (genotype x nutrient x clipping grouping). 
# Code used to produce the plot : https://github.com/QCBSRworkshops/workshop07/blob/main/pres-fr/data/glmm_e.r
# Substantial variation among the sample variances on the transformed data
# For example, among genotypes:
grpVars <- tapply(dat.tf$total.fruits, dat.tf$gna, var)

grpMeans <- tapply(dat.tf$total.fruits,dat.tf$gna, mean)

# Quasi-Poisson
lm1 <- lm(grpVars~grpMeans-1) 
phi.fit <- coef(lm1)
# The -1 specifies a model with the intercept set to zero

# Negative binomial
lm2 <- lm(grpVars ~ I(grpMeans^2) + offset(grpMeans)-1)
k.fit <- 1/coef(lm2)
# The offset() is used to specify that we want the group means added as a term with its coefficient fixed to 1

# Non-parametric loess fit
Lfit <- loess(grpVars~grpMeans)

# The plot
plot(grpVars ~ grpMeans, xlab = "Group means", ylab = "Group variances" )
abline(a = 0, b = 1, lty = 2)
text(105,500, "Poisson")
curve(phi.fit*x, col = 2, add = TRUE)
# bquote() is used to substitute numeric values in equations with symbols
text(110,3900,
     bquote(paste("QP: ", sigma^2==.(round(phi.fit,1))*mu)), col = 2)
curve(x*(1+x/k.fit), col = 4, add = TRUE)
text(104,7200, paste("NB: k = ", round(k.fit, 1), sep = ""), col = 4)
mvec <- 0:120
lines(mvec, predict(Lfit, mvec), col = 5)
text(118, 2000, "loess", col = 5)
```

From the plot above we note that a linear quasi-Poisson may be better than the negative binomial, *but additional modeling is needed.*


# Poisson GLMM

**Compte tenu de la relation moyenne-variance, nous avons besoin d'un modèle qui tient compte de la surdispersion.**

Pour comprendre pourquoi, commençons avec un modèle avec une distribution de Poisson.

Pour lancer un GLMM dans `R`, nous faisons appel à la fonction `glmer()` de la librairie `lme4`:

```{r, echo = TRUE, eval = TRUE}
## Poisson GLMM
# Given the mean-variance relationship, we will most likely need a model with over-dispersion.
# To understand why, let's start with a Poisson model.
library(lme4) # Load in lme4 pkg with glmer() command for running GLMM
mp1 <- glmer(total.fruits ~ nutrient*amd + rack + status +
             (1|popu)+
             (1|gen),
             data = dat.tf, family = "poisson")
```

**Effets aléatoires** : `(1|popu)` et `(1|gen)`. Nous faisons varier les ordonnées à l'origine pour les différentes populations (`popu`) et génotypes (`gen`).

---

**Vérification de la surdispersion**

On vérifie la surdispersion en utilisant la fonction `overdisp_fun()` (Bolker *et al*. 2011) qui divise la déviance des résidus (de Pearson) par leurs degrés de liberté.

La fonction teste si le **rapport est plus grand que 1**.

Effectuons ce test:

```{r}
# Téléchargez le code glmm_funs.R de la page wiki et sourcez le pour exécuter la fonction dans R
source(file = "data/glmm_funs.R")
# Surdispersion?
overdisp_fun(mp1)
# Le rapport est significativement > 1
```

**Le rapport est significativement > 1**

Comme on s'y attendait, nous devons modéliser une **distribution différente** où la variance augmente plus rapidement que la moyenne.


# GLMM binomiale negative

Une option pour une distribution où la variance augmente plus rapidement avec la moyenne est la distribution **binomiale négative** (ou Poisson-gamma). Rappelons que la distribution binomiale négative répond à l'hypothèse selon laquelle la variance est proportionnelle au carré de la moyenne.

On peut modéliser cette distribution avec la fonction `glmer.nb()`:

```{r, echo = TRUE, eval = TRUE}
## GLMM binomial négatif utilisant la fonction glmer.nb()
mnb1 <- glmer.nb(total.fruits ~ nutrient*amd + rack + status +
                 (1|popu)+
                 (1|gen),
                 data = dat.tf,
                 control = glmerControl(optimizer = "bobyqa"))
# Control spécifie la façon dont nous optimisons les valeurs des paramètres
```

We test again for over-dispersion:

```{r, echo = TRUE, eval = TRUE}
# Surdispersion?
overdisp_fun(mnb1)
# Le rapport est beaucoup plus près de 1 mais la valeur de p < 0.05
```

**Le rapport est beaucoup plus près de 1 mais la valeur de p < 0.05**

# GLMM Poisson-lognormale

Une deuxième option pour une distribution où la variance augmente plus rapidement avec la moyenne est la distribution **Poisson-lognormale**.

On réalise cette distribution en ajoutant un **effet aléatoire de niveau d'observation** dans le modèle.

Voir Harrison (2014) pour plus de détails https://doi.org/10.7717/peerj.616.

Pour ce faire, nous créons tout d'abord une variable nommée `X`:

```{r, echo = TRUE, eval = TRUE}
## GLMM Poisson-lognormale

# Cette variable est déjà dans vos données "dat.tf", mais voici comment la créer.
dat.tf$X <- 1:nrow(dat.tf)
```

On traite la surdispersion en ajoutant l'effet `(1|X)` dans la formule:

```{r, echo = TRUE, eval = TRUE}
# Tenir compte de la surdispersion
mpl1 <- glmer(total.fruits ~ nutrient*amd + rack + status +
              (1|X) +
              (1|popu)+
              (1|gen),
data = dat.tf, family = "poisson",
control = glmerControl(optimizer = "bobyqa"))
```

On teste finalement pour la présence de surdispersion:

```{r, echo = TRUE, eval = TRUE}
# Surdispersion?
overdisp_fun(mpl1)
# Le rapport est maintenant conforme avec notre critère, soit < 1
```

**Le rapport est maintenant conforme avec notre critère, soit < 1!**

---

**Maintenant que nous avons choisi notre distribution d'erreur, visualisons les paramètres du modèle.**

Peut être obtenu en utilisant la fonction `coefplot2()`de la librairie `coefplot2`:

*Notez: Cette librairie n'est pas sur le CRAN! On utilise la librairie remotes pour l'installer à partir de GitHub.*

```{R install_coefplot2}
if (!require("coefplot2"))
  remotes::install_github("palday/coefplot2", subdir = "pkg")
library(coefplot2)
```


```{r, echo = TRUE, eval = TRUE}
# Effets aléatoires
coefplot2(mpl1, ptype = "vcov", intercept = TRUE, main = "Random effect variance")
```

```{r, echo = TRUE, eval = TRUE}
# Effets fixes
coefplot2(mpl1, intercept = TRUE, main = "Fixed effect coefficient")
```

*Notez: barres d'erreur visibles seulement pour les effets fixes car `glmer()` ne modélise pas d'incertitude pour les effets aléatoires.*

---

**Visualisation des effets aléatoires**

Vous pouvez extraire les effets aléatoires en utilisant la fonction `ranef()` et les tracer en utilisant un `dotplot()` de la librairie `lattice`.

On constate une variation **inter-population**: 

- Les populations espagnoles (SP) ont des valeurs plus élevées que les populations suédoises (SW) et néerlandaises (NL)

On constate une faible variation **inter-génotype** :

- Les différences entre les génotypes semblent induites par le génotype 34

```{r, echo = TRUE, eval = TRUE}
library(gridExtra)
library(lattice)
# dotplot code
pp <- list(layout.widths = list(left.padding = 0, right.padding = 0),
           layout.heights = list(top.padding = 0, bottom.padding = 0))
r2 <- ranef(mpl1, condVar = TRUE)
d2 <- dotplot(r2, par.settings = pp)

grid.arrange(d2$gen, d2$popu, nrow = 1)
```


