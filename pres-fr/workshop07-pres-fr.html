<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Atelier 7: Modèles linéaires et généralisés linéaires mixtes</title>
    <meta charset="utf-8" />
    <meta name="author" content="Centre de la Science de la Biodiversité du Québec" />
    <link href="assets/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css">
    <link rel="stylesheet" href="qcbsR.css" type="text/css" />
    <link rel="stylesheet" href="qcbsR-fonts.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Atelier 7: Modèles linéaires et généralisés linéaires mixtes
## Série d’ateliers R du CSBQ
### Centre de la Science de la Biodiversité du Québec

---




class: inverse, center, middle



# À propos de cet atelier

[![badge](https://img.shields.io/static/v1?style=for-the-badge&amp;label=repo&amp;message=dev&amp;color=6f42c1&amp;logo=github)](https://github.com/QCBSRworkshops/workshop07)
[![badge](https://img.shields.io/static/v1?style=for-the-badge&amp;label=wiki&amp;message=07&amp;logo=wikipedia)](https://wiki.qcbs.ca/r_atelier6)
[![badge](https://img.shields.io/static/v1?style=for-the-badge&amp;label=diapos&amp;message=07&amp;color=red&amp;logo=html5)](https://qcbsrworkshops.github.io/workshop07/pres-fr/workshop07-pres-fr.html)
[![badge](https://img.shields.io/static/v1?style=for-the-badge&amp;label=diapos&amp;message=07&amp;color=red&amp;logo=adobe-acrobat-reader)](https://qcbsrworkshops.github.io/workshop07/workshop07-fr/workshop07-fr.pdf)
[![badge](https://img.shields.io/static/v1?style=for-the-badge&amp;label=script&amp;message=07&amp;color=2a50b8&amp;logo=r)](https://qcbsrworkshops.github.io/workshop07/workshop07-fr/workshop07-fr.R)


---
# À propos de cet atelier

&lt;br&gt;

Vous verrez à travers l'atelier une série de  **défis** que vous reconnaitrez avec ce cube rubik.

.center[
![:scale 25%](images/rubicub.png)
]

&lt;br&gt;

**N'hésitez-pas à collaborer pour résoudre ces défis!**


---

# Librairies requises

* [ggplot2](https://cran.r-project.org/package=ggplot2)
* [lme4](https://cran.r-project.org/package=lme4)
* [MuMIn](https://cran.r-project.org/package=MuMIn)
* [MASS](https://cran.r-project.org/package=MASS)
* [vcdExtra](https://cran.r-project.org/package=vcdExtra)
* [bbmle](https://cran.r-project.org/package=bbmle)
* [DescTools](https://cran.r-project.org/package=DescTools)


&lt;br&gt;

Pour les installer à partir du CRAN, faire :


```r
install.packages(c("ggplot2", 
                   "lme4", 
                   "MuMIn", 
                   'MASS', 
                   'vcdExtra', 
                   'bbmle', 
                   'DescTools'))
```

---

# Objectifs d'apprentissage

**1.** Décrire les modèles (généralisés) à effets mixtes

**2.** Identifier les situations dans lesquelles l'utilisation d'effets mixtes est appropriée

**3.** Mettre en œuvre des modèles linéaires mixtes de base avec `R`

**4.** Exécuter des modèles linéaires généralisés mixtes de base avec `R`

**5.** Valider, interpréter et visualiser les modèles mixtes avec `R`


---
# Question de recherche

.alert[**Est-ce que la position trophique des poissons augmente avec leur taille?**
]

Pour répondre, nous utiliserons un jeu de données où la longueur corporelle de 3 espèces de poissons (10 individus par espèce) a été mesurée dans 6 lacs différents.

.center[ ![:scale 75%](images/fig_1_qcbs_wiki.png) ]


---
# Défi 1 ![:cube]()

**Familiarisez-vous avec le jeu de données**

**1.** Ouvrez le script de l'atelier dans `R`

**2.** Ouvrez le jeu de données dans `R`

**3.** Reproduisez les graphiques 1 à 3 (dans le script) de la relation entre la position trophique et la taille. Observez les graphiques puis evaluez ce que vous observez.


---
exclude: true
# Familiarisez-vous avec le jeu de données
&lt;br&gt;

**1.** Ouvrez le jeu de données dans `R`

**2.** Ouvrez le script de l'atelier dans `R`

**3.** Visualisez la relation entre taille et position trophique

--
exclude: true
&lt;br&gt;


```r
fish.data &lt;- read.csv('data/qcbs_w7_data.csv', stringsAsFactors = TRUE)
head(fish.data)
#   Lake Fish_Species Fish_Length Trophic_Pos
# 1   L1           S1    105.1501    2.602388
# 2   L1           S1    194.5708    2.703522
# 3   L1           S1    294.3636    2.742878
# 4   L1           S1    413.5295    2.737743
# 5   L1           S1    237.4739    2.785936
# 6   L1           S1    107.9315    2.723862
```


---
# Solution ![:cube]()

&lt;br&gt;

&lt;img src="workshop07-pres-fr_files/figure-html/unnamed-chunk-3-1.png" width="432" style="display: block; margin: auto;" /&gt;


---
# Solution ![:cube]()

&lt;br&gt;

&lt;img src="workshop07-pres-fr_files/figure-html/unnamed-chunk-4-1.png" width="432" style="display: block; margin: auto;" /&gt;


---
# Solution ![:cube]()

&lt;br&gt;

&lt;img src="workshop07-pres-fr_files/figure-html/unnamed-chunk-5-1.png" width="432" style="display: block; margin: auto;" /&gt;


---
# Discussion de groupe ![:cube]()


**Est-ce qu'on s'attend à ce que la position trophique augmente avec la longueur corporelle exactement de la même façon pour : **

* toutes les espèces?
* tous les lacs?

&lt;br&gt;

--

**Comment ces relations pourraient-elles différer?**


---
# Pourquoi choisir un MLM?

### Les données biologiques et écologiques peuvent être complexes!

* Peuvent contenir une structure hiérarchique

* Plusieurs covariables et facteurs

* Échantillons non équilibrés


---
# Pourquoi choisir un MLM?

### Comment pourrions-nous analyser ces données?

--

&lt;br&gt;

**Option 1. Séparer**

- Faire une analyse séparée pour chaque espèce et chaque lac

&lt;br&gt;

**Option 2. Regrouper**

- Faire une seule analyse en ignorant les variables espèce et lac


---
# Pourquoi choisir un MLM?

.pull-left[![](images/fig_5_w5.png) ]

.pull-right[
**Option 1. Séparer** 
&lt;br&gt;

On pourrait faire une analyse pour chaque espèce :
* Estimer 6 ordonnées à l'origine et 6 pentes pour chaque espèce (car 6 lacs)

* Taille d'échantillon *n* = 10 pour chaque analyse (i.e. 10 poissons/espèce/lac)

* Peu de chances de détecter un effet a cause de la faible taille d’échantillon *n*
]


---
# Pourquoi choisir un MLM?

.pull-left[![](images/fig_6_w5.png)]

.pull-right[
**Option 2. Regrouper**
* Très grande taille d'échantillon!

* Et la pseudoreplication? (les poissons d'un même lac et d'une même espèce sont corrélés)

* Beaucoup de bruit = Une partie pourrait être due aux **effets** de **l'espèce** et du **lac**
]


---
# Pourquoi choisir un MLM?

Pour **notre question**, on veut seulement savoir s'il y a un **effet général de la longueur corporelle sur la position trophique**.
&lt;br&gt;
&lt;br&gt;

Par contre :

* **Cette relation pourrait varier** par **espèce** à cause de différents taux de croissance et/ou par **lac** à cause de différences dans la disponibilité de nourriture 

* **On doit contrôler** pour ces effets potentiels dans le modèle

--

&lt;br&gt;

Les MLMs permettent de **séparer et regrouper** l'analyse. Ils:

1. Prennent en compte la variabilité spécifique à chaque espèce et chaque lac (**séparer**) tout en calculant moins de paramètres

2. Utilisent toutes les données disponibles (**regrouper**) tout en contrôlant les différences entre les lacs et les espèces (pseudo-replication)


---
# Pourquoi choisir un MLM?

### Effet fixe vs effet aléatoire

Dans la littérature des MLMs, vous rencontrerez souvent ces termes. 

Il existe plusieurs façons de les décrire et nous vous présenterons ici celles que nous trouvons les plus faciles à appliquer.


---
# Pourquoi choisir un MLM?

### Effet fixe : processus déterministes

Les données proviennent : 
* de tous les niveaux possibles d'un facteur (**variable qualitative**) 
* d'un prédicteur (**variable quantitative**)

&lt;br&gt;

On souhaite émettre des conclusions à propos des niveaux du facteur ou de la relation entre le prédicteur et la variable réponse.

---
# Pourquoi choisir un MLM?

### Effet aléatoire : processus stochastiques

* Seulement des **variables qualitatives** = facteur aléatoire

* Permet de structurer le processus d'erreur


---
# Pourquoi choisir un MLM?

### Comment fonctionnent les MLMs?
&lt;br&gt;

**A.** Permet aux ordonnées à l'origine et/ou aux pentes d'être considérés comme propres (c.-à.-d. de varier) à une population donnée (**effet aléatoire**), e.g. par lac et/ou par espèce.

&lt;br&gt;

**B.** Les ordonnées à l'origine, les pentes et leur intervalle de confiance sont ajustés pour **prendre en compte la structure des données**.


---
# Effet aléatoire : faire varier les ordonnées à l'origine et/ou les pentes

.pull-left[![](images/fig_7_w5.png)]
.pull-right[![](images/fig_9_w5.png)]
&lt;br&gt;

* On suppose que les ordonnées à l'origine et/ou les pentes proviennent d'une distribution normale
* Le modèle estime une ordonnée à l'origine et/ou une pente moyenne ainsi que l'écart type de l'effet aléatoire (distribution normale) 
&lt;br&gt;&lt;br&gt;

Évite d'estimer une ordonnée à l'origine et une pente par espèce (+2 paramètres par espèce) = **économise des degrés de liberté** (moins de paramètres estimés).

---
exclude: true
# Effet aléatoire sur l'ordonnée à l'origine
&lt;br&gt;

&lt;img style="float: right; width:50%;margin: 1%" src="images/fig_7_w5.png"&gt;

On fait la supposition que les ordonnées à l'origine proviennent d'une distribution normale. 

On a seulement besoin d'estimer la moyenne (ordonnée à l'origine générale) et l'écart type de la distribution normale (effet aléatoire) au lieu d'estimer une ordonnée à l'origine par espèce (ce qui ajouterait 2 paramètres).

&lt;br&gt;&lt;br&gt;

Au lieu d'estimer d'estimer une ordonnée à l'origine par espèce (3 paramètres), on en estime une générale ainsi qu'un effet aléatoire (2 paramètres). Avec `\(n\)` espèce, dans le premier cas on estime `\(n-1\)` paramètres alors qu'on reste à 2 paramètres dans le second cas!

???

Note: (MFF) Cette diapo est difficile à comprendre. Je me demande si il y aurait une façon de mieux décrire le second paragraphe.


---
exclude: true
# Effet aléatoire sur l'ordonnée à l'origine
&lt;br&gt;&lt;br&gt;

&lt;img style="float: right; width:50%;margin: 1%" src="images/fig_8_w5.png"&gt;
Même principe pour les lacs

Estime 2 paramètres (moyenne et écart-type) au lieu de 6 ordonnées à l'origine.

Cela **économise des degrés de liberté** (moins d’estimation de paramètres sont nécessaires)


---
exclude: true
# Effet aléatoire sur la pente
&lt;br&gt;&lt;br&gt;

&lt;img style="float: right; width:50%;margin: 1%" src="images/fig_9_w5.png"&gt;
Le même principe s’applique aux pentes qui varient selon un facteur donné.

Comme pour les ordonnées à l'origine, seuls la moyenne et l’écart-type des pentes sont estimés au lieu de trois pentes distinctes.


---
# Tenir compte de la structure des données
&lt;br&gt;
**Qu'arrive-t-il si j'ai peu d'échantillons (faible `\(n\)`) pour un niveau des facteurs?**

Si une espèce ou un lac est peu représenté dans les données, le modèle va accorder plus d'importance au modèle groupé pour estimer l'ordonnée à l'origine et la pente de cette espèce ou de ce lac (Processus de « shrinkage »).

Idéalement, avoir un minimum de `\(n\)`=3 par niveau d'un facteur.

.center[![:scale 60%](images/fig_12_w5.png) ]


---
# Tenir compte de la structure des données
&lt;br&gt;
**Comment évaluer l'impact d'un effet aléatoire sur le modèle?**

* Les intervalles de confiance des ordonnées à l'origine et des pentes **générales** sont ajustés pour tenir compte de la pseudo-replication basée sur le **coefficient de corrélation intra-classe (CCI)**

* Le CCI permet de savoir la proportion de variation dans la variable réponse qui est expliquée par l'effet aléatoire, tel que :

`$$CCI = \frac{\sigma_{\alpha}^2}{\sigma_{\alpha}^2 + \sigma_{\varepsilon}^2}$$`
Le CCI correspond au **ratio** entre la variance d'un effet aléatoire (e.g. ordonnées à l'origine des espèces) et la variance totale.

Le CCI nous informe donc **à quel point** la position trophique moyenne entre chaque espèce ou chaque lac (c.-à-d. les ordonnées à l'origine) **varie**.

???

Note: _Dire que différentes notations sont possibles selon le livre/article et comment l'équation du modèle est écrite._


---
# Tenir compte de la structure des données


.pull-left[
**CCI élevé**

![:scale 90%](images/CCIplot2_qcbs.png)

Le % de variance (CCI) est élevé car **les espèces diffèrent fortement** dans leur position trophique moyenne.

Les intervalles de confiance pour la pente et l'ordonnée à l'origine générale sont grands.
]

.pull-right[
**CCI faible**

![:scale 85%](images/CCIplot_qcbs.png)

Le % de variance (CCI) est faible car **les espèces diffèrent peu** dans leur position trophique moyenne.

Les intervalles de confiance pour la pente et l'ordonnée à l'origine générale sont petits.
]


---
exclude: true
# Tenir compte de la structure des données


.pull-left[
**CCI élevé**

![](images/fig_10_w5.png)

Les points provenant d'un même lac sont traités comme une seule observation car **très corrélés**.

![:faic](arrow-right) petite taille effective de l'échantillon et grands intervalles de confiance pour la pente et l'ordonnée à l'origine.
]

.pull-right[
**CCI faible**

![](images/fig_11_w5.png)

Les points provenant d'un même lac sont traités indépendamment car **peu corrélés**.

![:faic](arrow-right) grande taille effective de l'échantillon et petits intervalles de confiance pour la pente et l'ordonnée à l'origine.
]


---
# Défi 2 ![:cube]()

&lt;br&gt;

**Comment le CCI et l'intervalle de confiance seront affectés dans ces deux scénarios?**

**Q1.** Les positions trophiques des poissons ne varient pas entre les lacs

&lt;br&gt;

**Q2.** Les positions trophiques des poissons sont similaires dans les lacs mais différentes entre les lacs

---
# Solution ![:cube]()

&lt;br&gt;

**Q1.** Les positions trophiques des poissons ne varient pas entre les lacs

.alert[R1. CCI faible, petits intervalles de confiances]

&lt;br&gt;

--

**Q2.** Les positions trophiques des poissons sont similaires dans les lacs mais différentes entre les lacs

.alert[R2. CCI élevé, grands intervalles de confiance]
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;
--

**Pour plus de détails sur le CCI** : &lt;br&gt;
Nakagawa et Schielzeth (2013)
https://doi.org/10.1111/j.1469-185X.2010.00141.x
Nakagawa *et al.* (2017) 
https://doi.org/10.1098/rsif.2017.0213


---
# Comment implémenter un MLM avec R?

&lt;img style="float:right; width:32%; margin:1%" src="images/lego.jpg"&gt;

###### **Étape 1.** Construction du modèle *a priori* et exploration des données

&lt;br&gt;

**Étape 2.** Coder les modèles potentiels et sélection du meilleur modèle

&lt;br&gt;

**Étape 3.** Validation du modèle

&lt;br&gt;

**Étape 4.** Interprétation et visualisation des résultats

---
# Étape 1. construction du modèle *a priori*

**Modèle basé sur connaissance *a priori*:**

* Nous voulons déterminer si la position trophique peut être prédite par la longueur corporelle, tout en prenant en compte la variation entre les espèces et les lacs

* Donc nous voulons un modèle qui ressemble a ceci:

`$$PT_{ijk} \sim Longueur_i + Lac_j + Espèce_k + \varepsilon_{ijk}$$`
---
# Étape 1. exploration des données

**Les données ont-elles la bonne structure?**


```r
fish.data &lt;- read.csv('data/qcbs_w7_data.csv')
str(fish.data)
# 'data.frame':	180 obs. of  4 variables:
#  $ Lake        : chr  "L1" "L1" "L1" "L1" ...
#  $ Fish_Species: chr  "S1" "S1" "S1" "S1" ...
#  $ Fish_Length : num  105 195 294 414 237 ...
#  $ Trophic_Pos : num  2.6 2.7 2.74 2.74 2.79 ...
```

Il est recommandé de faire le ménage de votre espace de travail (`rm.list()`) avant de construire un modèle.

---
# Étape 1. exploration des données

**Regardez la distribution des échantillons pour chaque facteur:**


```r
table(fish.data[ , c("Lake", "Fish_Species")])
#     Fish_Species
# Lake S1 S2 S3
#   L1 10 10 10
#   L2 10 10 10
#   L3 10 10 10
#   L4 10 10 10
#   L5 10 10 10
#   L6 10 10 10
```

Ce jeu de données est parfaitement équilibré, mais les **modèles mixtes peuvent analyser des designs expérimentaux non équilibrés**, comme c'est souvent le cas en écologie!

---
# Étape 1. exploration des données

**Regardez la distribution des variables continues**


```r
par(mfrow=c(1,2), mar = c(4,4,1,1))
hist(fish.data$Fish_Length, xlab = "Length (mm)", main = "")
hist(fish.data$Trophic_Pos, xlab = "Trophic position", main = "")
```

&lt;img src="workshop07-pres-fr_files/figure-html/unnamed-chunk-8-1.png" width="720" style="display: block; margin: auto;" /&gt;

Des déviations majeures pourraient causer des problèmes d'hétéroscédasticité. Si nécessaire, faites des transformations. Dans ce cas-ci, **les données semblent correctes**.

---
# Étape 1. exploration des données

**Vérifier la colinéarité entre vos variables explicatives**

Le problème avec les prédicteurs colinéaires est simplement qu'ils expliquent la même chose, alors leur effet sur la variable réponse sera confondu dans le modèle.

Dans cet exemple, il n’y a pas de risque de colinéarité avec seulement une variable continue. Si vous aviez une autre variable continue (`Var2`), une façon simple de vérifier la colinéarité est:


```r
plot(data)

cor(var1, var2)
```

Voici un [exemple de colinéarité](https://yetanotheriteration.netlify.app/2018/01/high-collinearity-effect-in-regressions/).

---
# Défi 3 ![:cube]()

Quelles mesures supplémentaires aurions-nous pu prendre sur le terrain et qui auraient pu être fortement corrélées avec la longueur corporelle?

--

&gt; Un exemple est la masse du poisson – c’est une variable fortement corrélée avec la longueur du poisson. Par conséquent, nous ne voulons pas inclure ces deux variables dans le même modèle.

---
# Étape 1. exploration des données

**Considérez l'échelle de vos données**

* Si deux variables dans un même modèle ont des échelles très différentes, il est probable que le modèle indique un problème de convergence en essayant de calculer les paramètres.

* La &lt;a href="https://fr.wikipedia.org/wiki/Cote_Z_(statistiques)"&gt;correction Z&lt;/a&gt; standardise les variables et résout ce problème (fonction `scale()` dans `R`) :

`$$z = \frac{x-moyenne(x)}{écart.type(x)}$$`
---
# Étape 1. exploration des données

**Considérez l'échelle de vos données**

* Longueur corporelle ![:faic](arrow-right) Longue échelle

* Position trophique ![:faic](arrow-right) Courte échelle

---
# Étape 1. exploration des données

**Considérez l'échelle de vos données**

Parce que nos données ont des échelles très différentes, on applique la **correction Z**


```r
# Longueur corrigée, "à la main"
fish.data$Z_Length &lt;- (fish.data$Fish_Length - mean(fish.data$Fish_Length)) / 
                      sd(fish.data$Fish_Length)

# Position trophique corrigée, avec la fonction scale
fish.data$Z_TP     &lt;- scale(fish.data$Trophic_Pos)
```

---
# Étape 1. exploration des données

Pour savoir si un modèle mixte est nécessaire pour vos données, vous devez déterminer s'il est important de prendre en compte l'effet aléatoire de facteurs qui pourraient influencer la relation qui vous intéresse (dans notre cas, lac et espèce)

**Nous pouvons le faire en :**

1. Créant un modèle linéaire sans les facteurs qui pourraient avoir un effet aléatoire

2. Calculant les résidus de ce modèle linéaire

3. Produisant un graphique de la valeur des résidus en fonction des niveaux des facteurs potentiellement aléatoires

---
# Étape 1. exploration des données

Créer un modèle linéaire sans les facteurs

```r
lm.test &lt;- lm(Z_TP ~ Z_Length, data = fish.data)
```

Calculer les résidus de ce modèle linéaire

```r
lm.test.resid &lt;- rstandard(lm.test)
```

---
# Étape 1. exploration des données

Représentez graphiquement la valeur des résidus en fonction des niveaux des facteurs


```r
par(mfrow=c(1,2))

plot(lm.test.resid ~ as.factor(fish.data$Fish_Species),
     xlab = "Species", ylab = "Standardized residuals")

abline(0, 0, lty = 2)

plot(lm.test.resid ~ as.factor(fish.data$Lake),
     xlab = "Lake", ylab = "Standardized residuals")

abline(0, 0, lty = 2)
```

---
# Étape 1. exploration des données

Représentez graphiquement la valeur des résidus en fonction des niveaux des facteurs

&lt;img src="workshop07-pres-fr_files/figure-html/unnamed-chunk-14-1.png" width="720" style="display: block; margin: auto;" /&gt;

.alert[Ces patrons suggèrent qu'il y a de la variance résiduelle qui pourrait être expliquée par ces facteurs, et ils devraient donc être inclus dans le modèle]

---
# Comment implémenter un MLM dans R ?

&lt;img style="float: right; width:32%;margin: 1%" src="images/lego.jpg"&gt;

**Étape 1.** Construction du modèle *a priori* et exploration des données

&lt;br&gt;

###### **Étape 2.** Coder les modèles potentiels et sélection du meilleur modèle

&lt;br&gt;

**Étape 3.** Validation du modèle

&lt;br&gt;

**Étape 4.** Interprétation et visualisation des résultats

---
# Étape 2. coder le modèle

**Traduisons notre modèle...**

`$$PT_{ijk} \sim Longueur_i + Lac_j + Espèce_k + \varepsilon_{ijk}$$`

**... En code R**




```r
library(lme4)
lmer(Z_TP ~ Z_Length + (1 | Lake) + (1 | Fish_Species),
     data = fish.data, REML = TRUE)
```

--

* `lmer` ![:faic](arrow-right) fonction "linear mixed model" du package `lme4`
* `(1 | Lake)` ![:faic](arrow-right) indique que les intercepts peuvent varier entre les lacs
* `REML = TRUE` ![:faic](arrow-right) méthode d'estimation

---
# Note sur les méthodes d'estimation

REML (*Restricted Maximum Likelihood*) est la méthode par défaut dans la fonction `lmer` (voir `?lmer`).

La méthode de maximum de vraisemblance (ML, pour *Maximum Likelihood*) sous-estime les variances du modèle par un facteur `\((n-k) / n\)`, ou `\(k\)` est le nombre d'effes fixes. 

La méthode REML corrige pour ce biais.

Consultez cet [article](https://towardsdatascience.com/maximum-likelihood-ml-vs-reml-78cf79bef2cf) pour plus d'information sur la différence entre ML et REML.

---
# Note sur les méthodes d'estimation

**On devrait utiliser :**

* **REML** pour comparer des modèles avec des **effets aléatoires nichés** et la même structure d'effets fixes

* **ML** pour comparer des modèles avec des **effets fixes nichés** et la même structure d'effets aléatoires

* **ML** pour comparer des modèles **avec et sans effets aléatoires**

---
# Étape 2. coder le modèle

**Comment faire si on souhaite que la pente puisse varier?**

.center[
![](images/fig_22_w5.png)
]

---
# Étape 2. coder le modèle

**Différentes structures pour le modèle :**

- `(1 | Lake)` effet aléatoire par lac à l'intercept
- `(1 + Z_Length | Lake)` effet aléatoire par lac à l'intercept et la pente en réponse à la longueur corporelle (NB: (`Z_Length | Lake)` donne le même résultat)
- `(-1 + Z_Length | Lake)` pour avoir uniquement l'effet aléatoire sur la pente
- `(1 | Lake) + (1 | Species)`  pour des effets aléatoires croisés
- `(1 | Lake:Fish_Species)` pour utiliser l'interaction entre 2 facteurs groupant
- si votre jeu de données inclus des effets nichés, vous pouvez utiliser `/` pour les déclarer, e.g. `(1 | facteur1 / facteur2)` si `facteur2` est niché dans `facteur1` ([voir ![:faic](stack-exchange)](https://stats.stackexchange.com/questions/228800/crossed-vs-nested-random-effects-how-do-they-differ-and-how-are-they-specified))

---
# Défi 4 ![:cube]()

Réécrivez le code suivant de façon à ce que les **pentes** de la relation position trophique en fonction de longueur corporelle **varient par lac et par espèces**:


```r
lmer(Z_TP ~ Z_Length + (1 | Lake) + (1 | Fish_Species),
     data = fish.data, REML = TRUE)
# Linear mixed model fit by REML ['lmerMod']
# Formula: Z_TP ~ Z_Length + (1 | Lake) + (1 | Fish_Species)
#    Data: fish.data
# REML criterion at convergence: 72.4662
# Random effects:
#  Groups       Name        Std.Dev.
#  Lake         (Intercept) 0.4516  
#  Fish_Species (Intercept) 0.9301  
#  Residual                 0.2605  
# Number of obs: 180, groups:  Lake, 6; Fish_Species, 3
# Fixed Effects:
# (Intercept)     Z_Length  
#   9.752e-14    4.198e-01
```

---
# Solution ![:cube]()


```r
lmer(Z_TP ~ Z_Length + (1 + Z_Length | Lake) + (1 + Z_Length | Fish_Species),
     data = fish.data, REML = TRUE)
# Linear mixed model fit by REML ['lmerMod']
# Formula: 
# Z_TP ~ Z_Length + (1 + Z_Length | Lake) + (1 + Z_Length | Fish_Species)
#    Data: fish.data
# REML criterion at convergence: 20.5786
# Random effects:
#  Groups       Name        Std.Dev. Corr 
#  Lake         (Intercept) 0.45279       
#               Z_Length    0.02378  -0.82
#  Fish_Species (Intercept) 0.93103       
#               Z_Length    0.15728  1.00 
#  Residual                 0.22341       
# Number of obs: 180, groups:  Lake, 6; Fish_Species, 3
# Fixed Effects:
# (Intercept)     Z_Length  
#  -0.0009025    0.4223738  
# optimizer (nloptwrap) convergence code: 0 (OK) ; 0 optimizer warnings; 1 lme4 warnings
```

---
# Étape 2. sélectionner le meilleur modèle

* Pour déterminer si vous avez construit le meilleur modèle mixte basé sur vos connaissances a priori, vous devez comparer ce modèle aux autres modèles alternatifs.

* Avec le jeu de données sur lequel vous travaillez, il y a plusieurs modèles alternatifs qui pourraient mieux correspondre à vos données.


---
# Défi 5 ![:cube]()

Faites une liste de 7 modèles alternatifs qui pourraient être comparés à celui-ci:


```r
lmer(Z_TP ~ Z_Length + (1 | Lake) + (1 | Fish_Species),
     data = fish.data, REML = TRUE)
```

.comment[Note : si nous avions différents effets fixes entre les modèles ou un modèle sans effects aléatoires, nous aurions dû indiquer `REML = FALSE` pour les comparer avec une méthode de vraisemblance comme l'AIC.]


---
# Solution ![:cube]()

Nous allons aussi construire le **modèle linéaire de base** `lm()` parce qu'il est toujours utile de voir la variation dans les valeurs de AICc.


```r
M0 &lt;- lm(Z_TP ~ Z_Length, data = fish.data)
```

Par contre, pour comparer ce modèle aux MLMs, il est important de .alert[changer la méthode d'estimation à ML (`REML=FALSE`)] parce que `lm()` n'utilise pas la même méthode d'estimation que `lmer()`.


---
# Solution ![:cube]()


```r
# Modele linéaire de base
M0 &lt;- lm(Z_TP ~ Z_Length, data = fish.data)
# modèle complet avec variation des intercepts
M1 &lt;- lmer(Z_TP ~ Z_Length + (1 | Fish_Species) + (1 | Lake), 
           data = fish.data, REML = FALSE)
# modèle complet avec variation des intercepts et de pentes
M2 &lt;- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Fish_Species) + (1 + Z_Length | Lake),
           data = fish.data, REML = FALSE)
# Pas d'effet lac, les intercepts varient par espèces
M3 &lt;- lmer(Z_TP ~ Z_Length + (1 | Fish_Species), data = fish.data, REML = FALSE)
# Pas d'effet espèces, les intercepts varient par lac
M4 &lt;- lmer(Z_TP ~ Z_Length + (1 | Lake), data = fish.data, REML = FALSE)
# Pas d'effet de lac, les intercepts et les pentes varient par espèces
M5 &lt;- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Fish_Species), 
           data = fish.data, REML = FALSE)
# Pas d'effet de l'espèces, les intercepts et les pentes varient par lac
M6 &lt;- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Lake), data = fish.data, REML = FALSE)
# modèle complet, variation d'intercept et pente par lac
M7 &lt;- lmer(Z_TP ~ Z_Length + (1 | Fish_Species) + (1 + Z_Length | Lake),
           data = fish.data, REML = FALSE)
# modèle complet, variation d'intercept et pente par espèces
M8 &lt;- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Fish_Species) + (1 | Lake),
           data = fish.data, REML = FALSE)
```


---
# Solution ![:cube]()

Lorsqu'on ajuste des MLM avec `lmer()`, il est possible de faire face à certaines erreurs our avertissements comme: 

* `boundary (singular) fit: see ?isSingular`, voir [cette discussion ![:faic](stack-exchange)](https://stats.stackexchange.com/questions/378939/dealing-with-singular-fit-in-mixed-models)

* `Model failed to converge with max|grad| ...`, voir [cette discussion ![:faic](stack-exchange)](https://stats.stackexchange.com/questions/242109/model-failed-to-converge-warning-in-lmer)

Voici une [liste](https://rdrr.io/cran/lme4/man/troubleshooting.html) de problèmes possibles et comment les résoudre. 


---
# Étape 2. sélectionner le meilleur modèle

* Maintenant que nous avons une liste de modèles potentiels, nous voulons les comparer entre eux pour sélectionner celui(ceux) qui a(ont) le plus de pouvoir prédictif.

* Les modèles peuvent être comparés en utilisant la fonction `AICc` provenant du package `MuMIn`.

* Le critère d'information Akaike (AIC) est une **mesure de qualité du modèle** pouvant être utilisée pour comparer les modèles.

* AICc corrige pour le biais créé par les faibles tailles d'échantillon.


---
# Étape 2. sélectionner le meilleur modèle

Pour trouver la valeur AICc d'un modèle, utilisez :


```r
library(MuMIn)
MuMIn::AICc(M1)
# [1] 77.30499
```


---
# Étape 2. sélectionner le meilleur modèle

Pour regrouper toutes les valeurs d'AICc dans un seul tableau, utilisez :


```r
AIC.table  &lt;- MuMIn::model.sel(M0, M1, M2, M3, M4, M5, M6, M7, M8)
(AIC.table &lt;- AIC.table[ , c("df", "logLik", "AICc", "delta")])
#    df      logLik      AICc      delta
# M8  7   -8.597929  31.84702   0.000000
# M2  9   -8.216019  35.49086   3.643839
# M1  5  -33.480080  77.30499  45.457965
# M7  7  -33.186374  81.02391  49.176890
# M5  6 -128.310995 269.10754 237.260517
# M3  4 -134.532965 277.29450 245.447480
# M4  4 -224.715763 457.66010 425.813076
# M6  6 -224.671201 461.82795 429.980930
# M0  3 -236.861362 479.85909 448.012065
```

* `df` est le degré de liberté
* `logLik` est le log de la vraisemblance
* `delta` est la différence d'AICc avec la valeur la plus petite

Nous avons seulement affiché une partie des résultats retourné par la fonction `model.sel()`, voir `?model.sel` pour plus d'information.


---
# Étape 2. sélectionner le meilleur modèle

Que signifient ces valeurs d'AICc ?


```r
AIC.table
#    df      logLik      AICc      delta
# M8  7   -8.597929  31.84702   0.000000
# M2  9   -8.216019  35.49086   3.643839
# M1  5  -33.480080  77.30499  45.457965
# M7  7  -33.186374  81.02391  49.176890
# M5  6 -128.310995 269.10754 237.260517
# M3  4 -134.532965 277.29450 245.447480
# M4  4 -224.715763 457.66010 425.813076
# M6  6 -224.671201 461.82795 429.980930
# M0  3 -236.861362 479.85909 448.012065
```

* Le modèle avec le plus petit AICc a le plus grand pouvoir prédictif.

* Souvent on considère que deux modèles à +/- 2 unités d'AICc de différence ont un pouvoir prédictif équivalent.

* Examinons de plus proche M8 and M2. On peut exclure les autres modèles car ils ont des AICc beaucoup plus élevés.


---
# Étape 2. sélectionner le meilleur modèle


```r
M8 &lt;- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Fish_Species) + (1 | Lake),
           data = fish.data, REML = TRUE)

M2 &lt;- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Fish_Species) + (1 + Z_Length | Lake),
           data = fish.data, REML = TRUE)

MuMIn::model.sel(M2,M8)[ , c("df", "logLik", "AICc", "delta")]
#    df    logLik     AICc    delta
# M8  7 -10.84011 36.33137 0.000000
# M2  9 -10.28932 39.63747 3.306098
```

Le modèle `M8` semble être le meilleur modèle parmi ceux qu'on a testé.

Notez qu'on utilise maintenant REML (i.e. `REML=TRUE`) vu qu'on compare deux modèles avec des effets aléatoires nichés et avec la même structure d'effets fixes. 


---
# Étape 2. sélectionner le meilleur modèle

Quelle est la structure du meilleur modèle?


```r
M8 &lt;- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Fish_Species) + (1 | Lake),
           data = fish.data, REML = TRUE)
```

L'intercept et l'effet de la longueur sur la position trophique peut varier selon l'espèce de poissons, mais seulement l'intercept peut varier par lac

.pull-left[![](images/fig_9_w5.png)]
.pull-right[![](images/fig_8_w5.png)]


---
# Étape 2. sélectionner le meilleur modèle

Une fois que le meilleur modèle est sélectionné il faut remettre la méthode d'estimation a `REML = TRUE`


```r
M8 &lt;- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Fish_Species) + (1 | Lake),
           data = fish.data, REML = TRUE)
```


---
exclude: true

# Défi 5 ![:cube]()

Prenez 2 minutes avec votre voisin pour étudier la structure du modèle M2.

Comment diffère-t-il de M8 d'un point de vue écologique?

Pourquoi n'est il pas surprenant que sa valeur d'AICc était la deuxième meilleure?


```r
M8 &lt;- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Fish_Species) + (1 | Lake),
           data = fish.data, REML = TRUE)

M2 &lt;- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Fish_Species) + (1 + Z_Length | Lake),
           data = fish.data, REML = TRUE)
```


---
exclude: true

# Solution ![:cube]()

**Discussion de groupe...**

--
exclude: true

.alert[M2] La position trophique est en fonction de la longueur. L'intercept et l'effet de la longueur sur la position trophique peuvent varier selon l'espèce de poissons et le lac.

* .small[les facteurs intrinsèques des espèces et des lacs sont à la base des relations différentes entre la position trophique et la longueur (i.e. pentes et intercepts)]

.alert[M8] La position trophique est en fonction de la longueur. L'intercept et l'effet de la longueur sur la position trophique peut varier selon l’espèce de poissons, mais seulement l'intercept peut varier par lac.

* .small[seulement les facteurs intrinsèques des espèces sont responsables des différentes relations (i.e. pentes) et en moyenne, les positions trophiques pourraient être supérieures ou inférieures d’un lac à l’autre (e.g. intercepts).]


---
# Comment implémenter un MLM dans R ?

&lt;img style = "float: right; width:32%;margin: 1%" src = "images/lego.jpg"&gt;

**Étape 1.** Construction du modèle *a priori* et exploration des données

&lt;br&gt;

**Étape 2.** Coder les modèles potentiels et sélection du meilleur modèle

&lt;br&gt;

###### **Étape 3.** Validation du modèle

&lt;br&gt;

**Étape 4.** Interprétation et visualisation des résultats


---
# Étape 3. validation du modèle

**Vous devez vérifier que le modèle respecte toutes les suppositions de base :**

&lt;br&gt;

**3.1 Vérifier l'homogénéité de la variance**
  - Faire un graphique des valeurs prédites en fonction des valeurs résiduelles

&lt;br&gt;

**3.2 Vérifier l'indépendance des résidus**
  - Graphique des résidus vs chaque covariable du modèle
  - Graphique des résidus vs chaque covariable non incluse du modèle

&lt;br&gt;

**3.3 Vérifier la normalité**
  - Histogramme


---
# Étape 3. validation du modèle

**3.1 Vérifier l'homogénéité de la variance**


```r
plot(resid(M8) ~ fitted(M8), 
     xlab = 'Valeurs prédites', 
     ylab = 'Résidus normalisés')
abline(h = 0, lty = 2)
```

&lt;img src="workshop07-pres-fr_files/figure-html/unnamed-chunk-29-1.png" width="324" style="display: block; margin: auto;" /&gt;

Étendue homogène des résidus ![:faic](arrow-right) la supposition est respectée!


---
# Étape 3. validation du modèle

**3.1 Vérifier l'homogénéité de la variance**

.center[
![](images/resid-plots.gif)
]


---
# Étape 3. validation du modèle

**3.2 Vérifier l'indépendance des résidus avec chaque covariable**


```r
par(mfrow = c(1,3), mar=c(4,4,.5,.5))

plot(resid(M8) ~ fish.data$Z_Length, 
     xlab = "Longueur", ylab = "Résidus normalisés")
abline(h = 0, lty = 2)

boxplot(resid(M8) ~ Fish_Species, data = fish.data, 
        xlab = "Espèces", ylab = "Résidus normalisés")
abline(h = 0, lty = 2)

boxplot(resid(M8) ~ Lake, data = fish.data, 
        xlab = "Lacs", ylab = "Résidus normalisés")
abline(h = 0, lty = 2)
```


---
# Étape 3. validation du modèle

**3.2 Vérifier l'indépendance des résidus avec chaque covariable**

&lt;img src="workshop07-pres-fr_files/figure-html/unnamed-chunk-31-1.png" width="864" style="display: block; margin: auto;" /&gt;

Étendue homogène des résidus autour de 0 ![:faic](arrow-right) pas de patron des résidus en fonction de la variable, la supposition est respectée!

.comment[Note : les regroupements de données sont dus à la structure des données, où des poissons de seulement 5 classes de taille  (grand, petit, et trois groupes entre les deux) étaient capturés.]


---
# Étape 3. validation du modèle

**3.2 Vérifier l'indépendance des résidus avec chaque covariable**

- Graphique des résidus vs chaque covariable non incluse du modèle

  - Si vous observez des patrons dans ce graphique, vous saurez qu'il y a de la variation dans votre jeu de données qui pourrait être expliquée par ces covariables. Vous devriez considérer d'inclure ces variables dans votre modèle.

  - Puisque dans notre cas, nous avons inclus toutes les variables mesurées dans notre modèle, nous ne pouvons pas faire cette étape.


---
# Étape 3. validation du modèle

**3.3 Vérifier la normalité des résidus**

* Des résidus suivant une distribution normale indiquent que le modèle n'est pas biaisé


```r
hist(resid(M8))
```

&lt;img src="workshop07-pres-fr_files/figure-html/unnamed-chunk-32-1.png" width="360" style="display: block; margin: auto;" /&gt;


---
# Comment implémenter un MLM dans R ?

&lt;img style="float: right; width:32%;margin: 1%" src="images/lego.jpg"&gt;

**Étape 1.** Construction du modèle *a priori* et exploration des données

&lt;br&gt;

**Étape 2.** Coder les modèles potentiels et sélection du meilleur modèle

&lt;br&gt;

**Étape 3.** Validation du modèle

&lt;br&gt;

###### **Étape 4.** Interprétation et visualisation des résultats


---
# Étape 4. interprétation et visualisation


```r
(summ_M8 &lt;- summary(M8))
# Linear mixed model fit by REML ['lmerMod']
# Formula: Z_TP ~ Z_Length + (1 + Z_Length | Fish_Species) + (1 | Lake)
#    Data: fish.data
# 
# REML criterion at convergence: 21.7
# 
# Scaled residuals: 
#      Min       1Q   Median       3Q      Max 
# -2.77187 -0.60166  0.05589  0.64239  2.27776 
# 
# Random effects:
#  Groups       Name        Variance Std.Dev. Corr
#  Lake         (Intercept) 0.20504  0.4528       
#  Fish_Species (Intercept) 0.86715  0.9312       
#               Z_Length    0.02466  0.1570   1.00
#  Residual                 0.05039  0.2245       
# Number of obs: 180, groups:  Lake, 6; Fish_Species, 3
# 
# Fixed effects:
#               Estimate Std. Error t value
# (Intercept) -0.0009059  0.5687733  -0.002
# Z_Length     0.4222697  0.0922117   4.579
# 
# Correlation of Fixed Effects:
#          (Intr)
# Z_Length 0.929 
# optimizer (nloptwrap) convergence code: 0 (OK)
# boundary (singular) fit: see ?isSingular
```


---
# Étape 4. interprétation et visualisation

    # Random effects:
    #  Groups       Name        Variance Std.Dev. Corr
    #  Lake         (Intercept) 0.20500  0.4528
    #  Fish_Species (Intercept) 0.86621  0.9307
    #               Z_Length    0.02464  0.1570   1.00
    #  Residual                 0.05040  0.2245

- `Groups`: facteurs de regroupement,
- `Name`:
  - `(Intercept)` pour l'ordonnée à l'origine,
  - ou le nom de la variable sur lequel porte l'effet mixe dans le cas d'une pente aléatoire, (`Z_length` dans notre exemple)
- `Variance` la variance estimée de l'effet (`Std.Dev.` est l'écart type de cette valeur)
- `Corr` indique la corrélation entre la pente aléatoire et l'ordonnée à l'origine aléatoire pour un groupement donné (voir [cette discussion ![:faic](stack-exchange)](https://stats.stackexchange.com/questions/320978/understanding-and-coding-random-intercept-correlation-lmer))


---
# Étape 4. interprétation et visualisation

    # Fixed effects:
    #              Estimate Std. Error t value
    # (Intercept) -0.000906   0.568493  -0.002
    # Z_Length     0.422270   0.092170   4.581

Cette partie présente l'estimation des effets fixes. Une valeur de la statistique T [(test de Student)](https://en.wikipedia.org/wiki/T-statistic) est retournée **sans p-value** (c'est un choix des auteurs du package, voir pourquoi dans [cette discussion](https://stats.stackexchange.com/questions/185360/t-value-associated-with-nlme-lme4)).

Cette statistique peut être utilisée telle quelle. Vous pouvez aussi calculer
l’intervalle de confiance (IC) à 95% avec cette table en utilisant

$$ IC = Estimate \pm 1.96*Std.Error $$
Si 0 est dans cet interval, alors le paramètre n’est pas significativement
différente de zéro au seuil `\(\alpha\)` = 0.05.


---
# Étape 4. interprétation et visualisation

**Quelques fonctions utiles**

- `coef(M8)` et `ranef(M8)` retournent les effets aléatoires du modèle M8

- `coef(summary(M8))` retourne les effets fixes

- `sigma(M8)` retourne l’écart type des résidus

- `fitted(M8)` retourne les valeurs prédites par le modèle

- `residuals(M8)` retourne les résidus


---
# Défi 6 ![:cube]()

1. Quelle est la pente et son intervalle de confiance de la variable Z_Length dans le modèle M8?

2. Est-ce que la pente de Z_Length est significativement différente de 0 ?


---
# Solution ![:cube]()

1. Quelle est la pente et son intervalle de confiance de la variable Z_Length dans le modèle M8?

  - pente = 0.422;

  - limite supérieure de l’IC = 0.4223 + 0.09*1.96 = 0.5987

  - limite inférieure de l’IC = 0.4223 - 0.09*1.96 = 0.2459

2. Est-ce que la pente de Z_Length est significativement différente de 0 ?

  - Oui, car l'IC [0.2459, 0.5987] n'inclut pas 0


---
# Défi 7 ![:cube]()

Il est possible de visualiser graphiquement les différentes intercepts et pentes du modèle pour mieux interpréter les résultats

Prenez 2 minutes pour réfléchir aux différentes façons pour représenter les résultats de M8.

*Indice: considérez les différents "niveaux" du modèle*


---
# Solution ![:cube]()

a) Figure avec toutes les données regroupées

b) Figure par espèce

c) Figure par lac


---
# Solution ![:cube]()

Pour faire ces figures, il nous faut:

- Les coefficients du modèle complet qui sont dans le résumé du modèle


```r
summ_M8$coefficients
#                  Estimate Std. Error      t value
# (Intercept) -0.0009058974 0.56877327 -0.001592722
# Z_Length     0.4222697238 0.09221166  4.579352788
```

- Intercept = `\(-9.0589745\times 10^{-4}\)`
- Pente = `\(0.4222697\)`


---
# Solution ![:cube]()

Pour faire ces figures, il nous faut:

- Les coefficients pour chaque niveau du modèle qu'on obtient avec la fonction `coef`


```r
coef(M8)
# $Lake
#     (Intercept)  Z_Length
# L1 -0.085984071 0.4222697
# L2  0.002205209 0.4222697
# L3 -0.301816557 0.4222697
# L4 -0.574039728 0.4222697
# L5  0.218650140 0.4222697
# L6  0.735549622 0.4222697
# 
# $Fish_Species
#    (Intercept)  Z_Length
# S1  -1.0752985 0.2410746
# S2   0.5597871 0.5168300
# S3   0.5127938 0.5089046
# 
# attr(,"class")
# [1] "coef.mer"
```


---
# Solution ![:cube]()

a) Figure avec toutes les données regroupées

```r
library(ggplot2)

# Thème ggplot simplifié
fig &lt;- theme_bw() +
        theme(panel.grid.minor=element_blank(), 
              panel.grid.major=element_blank(),
              panel.background=element_blank()) +
        theme(strip.background=element_blank(), 
              strip.text.y = element_text()) +
        theme(legend.background=element_blank()) +
        theme(legend.key=element_blank()) +
        theme(panel.border = element_rect(colour = "black", fill=NA))

plot &lt;- ggplot(aes(Z_Length, Z_TP), data = fish.data)
Plot_AllData &lt;- plot + geom_point() +
                  xlab("Longueur (mm)") + 
                  ylab("Position trophique") +
                  labs(title = "Toutes les données") + fig

Plot_AllData + geom_abline(intercept = summ_M8$coefficients[1,1], 
                           slope     = summ_M8$coefficients[2,1])
```


---
# Solution ![:cube]()

a) Figure avec toutes les données regroupées
&lt;img src="workshop07-pres-fr_files/figure-html/unnamed-chunk-37-1.png" width="432" style="display: block; margin: auto;" /&gt;


---
# Solution ![:cube]()

b) Figure par espèce


```r
# mettre les coefs dans un tableau pour les rendre plus faciles à manipuler
Lake.coef              &lt;- coef(M8)$Lake
colnames(Lake.coef)    &lt;- c("Intercept", "Slope")
Species.coef           &lt;- coef(M8)$Fish_Species
colnames(Species.coef) &lt;- c("Intercept", "Slope")

Plot_BySpecies &lt;- plot + 
                    geom_point(aes(colour = factor(Fish_Species)), size = 4) +
                    xlab("Longueur (mm)") + ylab("Position trophique") +
                    labs(title = "Par espèce") + fig

# Ajoutez les lignes de régression pour chaque espèce
Plot_BySpecies +
  geom_abline(intercept = Species.coef[1,1], 
              slope     = Species.coef[1,2], col = "coral2") +
  geom_abline(intercept = Species.coef[2,1], 
              slope     = Species.coef[2,2], col = "green4") +
  geom_abline(intercept = Species.coef[3,1], 
              slope     = Species.coef[3,2], col = "blue1")

```


---
# Solution ![:cube]()

b) Figure par espèce

&lt;img src="workshop07-pres-fr_files/figure-html/unnamed-chunk-39-1.png" width="576" style="display: block; margin: auto;" /&gt;


---
# Solution ![:cube]()

c) Figure par lac

```r

Plot_ByLake &lt;- plot + 
                geom_point(aes(colour = factor(Lake)), size = 4) +
                xlab("Length (mm)") + ylab("Trophic Position") +
                labs(title = "By Lake") + fig

# Ajouter les lignes de régression avec les intercepts spécifiques à chaque lac
Plot_ByLake +
  geom_abline(intercept = Lake.coef[1,1], 
              slope     = Lake.coef[1,2], col = "coral2") +
  geom_abline(intercept = Lake.coef[2,1], 
              slope     = Lake.coef[2,2], col = "khaki4") +
  geom_abline(intercept = Lake.coef[3,1], 
              slope     = Lake.coef[3,2], col = "green4") +
  geom_abline(intercept = Lake.coef[4,1], 
              slope     = Lake.coef[4,2], col = "darkgoldenrod") +
  geom_abline(intercept = Lake.coef[5,1], 
              slope     = Lake.coef[5,2], col = "royalblue1") +
  geom_abline(intercept = Lake.coef[6,1], 
              slope     = Lake.coef[6,2], col = "magenta3")

```


---
# Solution ![:cube]()

c) Figure par lac
&lt;img src="workshop07-pres-fr_files/figure-html/unnamed-chunk-41-1.png" width="576" style="display: block; margin: auto;" /&gt;


---

exclude: true

# Modèle mixtes et données en écologie

Les modèles mixtes sont très utiles pour prendre en compte la structure complexe des données en écologie tout en permettant de ne pas perdre beaucoup de degrés de liberté

.center[
![](images/fig_1_qcbs_wiki.png)
]


---
# Défi 8 ![:cube]()

**Situation:**

* Vous avez inventorié la richesse **dans 1000 quadrats** qui sont dans **10 sites différents** qui sont également dans **10 forêts différentes**.

* Vous avez de plus **mesuré la productivité** dans chaque **quadrat**.

* Vous désirez savoir si la productivité est un bon prédicteur de biodiversité

.alert[Quel modèle mixte pourriez-vous utiliser pour ce jeu de données?]


---
# Solution ![:cube]()


```r
lmer(Biodiv ~ Productivite + (1 | Foret / Site))
```

Ici les effets aléatoires sont nichés (i.e. Sites dans forêt) et non croisés.

Pourquoi utiliser `(1 | Foret / Site)` plutôt que `(1 | Foret) + (1 | Site)` ? Regardez [cette réponse sur ![:faic](stack-exchange)](https://stats.stackexchange.com/questions/228800/crossed-vs-nested-random-effects-how-do-they-differ-and-how-are-they-specified)!


---
exclude: true

# Défi 8 ![:cube]()

**Situation:**

* Vous avez récolté **200 poissons** dans **12 sites différents** distribués également dans **4 habitats** différents qui se retrouvent dans **un même lac**.

* Vous avez mesuré la **longueur de chaque poisson** et la **quantité de mercure dans ses tissus**.

* Vous désirez savoir si l'habitat est un bon prédicteur de la concentration en mercure.

.alert[Quel modèle mixte pourriez-vous utiliser pour ce jeu de données?]

---
exclude: true

# Solution ![:cube]()


```r
lmer(Mercure ~ Longueur * Habitat + (1 | Site))
```

---
exclude: true

# Défi 9 ![:cube]()

* Discutez du jeu de données sur lequel vous travaillez avec votre voisin et déterminez si un modèle mixte serait approprié.

* Si oui, travaillez ensemble pour écrire le code que vous utiliseriez pour faire ce modèle dans R.

* Si non, imaginez un jeu de données fictif pour lequel un modèle mixte serait approprié et codez ce modèle.


---
class: inverse, center, middle

# GLMMs


---
# Modèles Linéaires Généralisés Mixtes (GLMMs)

**Extension des GLMs tenant compte de structures supplémentaires dans les données**

Suivent les étapes similaires à celles introduites lors de la section sur les LMMs :

**1.** Ils incorporent les effets aléatoires (comme les LMMs)

**2.** Permettent de gérer des données non-normales (en laissant les erreurs prendre différentes familles de distribution - e.g Poisson ou binomial négatif) (comme les GLMs)


---
# Comment modéliser un GLMM avec R

Chargez les données `Arabidopsis` `banta_totalfruits.csv` dans `R`.



```r
dat.tf &lt;- read.csv("banta_totalfruits.csv")
```
```r
# popu facteur avec un niveau pour chaque population
# gen facteur avec un niveau pour chaque génotype
# nutrient facteur avec niveau bas (valeur = 1) ou haut (valeur = 8)
# amd facteur précisant l'absence ou la présence d'herbivorie
# total.fruits nombre entier indiquant le nombre de fruits par plante
```

L'effet de la disponibilité de nutriments et d'herbivorie (**effets fixes**) sur la production de fruits d'*Arabidopsis thaliana* (**variable réponse**) a été évalué en mesurant 625 plantes à travers neuf populations différentes, constituées chacune de 2 à 3 génotypes (**effets aléatoires**).


---
# Choisir la distribution des erreurs

La variable réponse constitue des données d'abondance, donc nous devons choisir une **distribution de Poisson** (i.e variance égale à la moyenne)

&lt;img src="workshop07-pres-fr_files/figure-html/unnamed-chunk-45-1.png" width="432" style="display: block; margin: auto;" /&gt;
Cependant, comme nous le verrons, la variance de chaque groupe augmente beaucoup plus rapidement que prévu...


---
# Exploration de la variance

Pour illustrer l'hétérogénéité de la variance, nous allons créer des boîtes à moustaches (boxplots) du **log** du nombre total de fruits (**variable réponse**) par rapport aux différents facteurs environnementaux.

Créons d'abord de nouvelles variables qui représentent toutes les combinaisons de **nutriments** x **herbivorie** x **facteur aléatoire**.


```r
dat.tf &lt;- within(dat.tf,
{
  # génotype x nutriment x herbivorie
  gna &lt;- interaction(gen, nutrient, amd)
  gna &lt;- reorder(gna, total.fruits, mean)
  # population x nutriment x herbivorie
  pna &lt;- interaction(popu, nutrient, amd)
  pna &lt;- reorder(pna, total.fruits, mean)
})
```


---
# Exploration de la variance

.small[

```r
# Boxplot du total des fruits vs interaction génotype x nutriment x herbivorie
ggplot(data = dat.tf, aes(factor(x = gna), y = log(total.fruits + 1))) +
  geom_boxplot(colour = "skyblue2", outlier.shape = 21,
  outlier.colour = "skyblue2") +
  ylab("log (Fruits totaux)\n") + # \n créé un espace après le titre
  xlab("\nGénotype x nutriment x herbivorie") + # espace avant le titre
  theme_bw() + theme(axis.text.x = element_blank()) +
  stat_summary(fun = mean, geom = "point", colour = "red")
```

&lt;img src="workshop07-pres-fr_files/figure-html/unnamed-chunk-47-1.png" width="576" style="display: block; margin: auto;" /&gt;
]

.comment[De même, la variance du total de fruits montre une grande hétérogénéité entre les populations (population x nutriments x herbivorie).]


---
# Choisir la distribution des erreurs

Comme nous venons de le voir, il existe une importante hétérogénéité parmi la variance de chaque groupe, même lorsque la variable réponse est transformée (i.e. log).

Si nous représentons graphiquement les **écarts vs moyennes par groupes** (génotypes x nutriment x herbivorie), on voit que la distribution de Poisson est la moins appropriée (i.e. car les écarts augmentent beaucoup plus vite que la moyenne).

&lt;img src="workshop07-pres-fr_files/figure-html/unnamed-chunk-48-1.png" width="576" style="display: block; margin: auto;" /&gt;


---
# GLMM Poisson

**Compte tenu de la relation moyenne-variance, nous avons besoin d'un modèle qui tient compte de la surdispersion.**

Pour comprendre pourquoi, commençons avec un modèle avec une distribution de Poisson.

--

Pour lancer un GLMM dans `R`, nous faisons appel à la fonction `glmer()` de la librairie `lme4` :


```r
library(lme4)
mp1 &lt;- glmer(total.fruits ~ nutrient*amd + rack + status +
             (1|popu)+
             (1|gen),
             data = dat.tf, family = "poisson")
```

**Effets aléatoires** : `(1|popu)` et `(1|gen)`. Nous faisons varier les ordonnées à l'origine pour les différentes populations (`popu`) et génotypes (`gen`).


---
# Vérification de la surdispersion

On vérifie la surdispersion en utilisant la fonction `overdisp_fun()` (Bolker *et al*. 2011) qui divise la déviance des résidus (de Pearson) par leurs degrés de liberté.

La fonction teste si le **rapport est plus grand que 1**.

--

Effectuons ce test :

```r
# Téléchargez le code glmm_funs.R de la page wiki et sourcez le pour exécuter la fonction dans R
source(file = "data/glmm_funs.R")
# Surdispersion?
overdisp_fun(mp1)
#       chisq       ratio           p        logp 
# 15755.86829    25.57771     0.00000 -6578.47025
```
--
.alert[Le rapport est significativement &gt; 1]
&lt;br&gt;&lt;br&gt;

Comme on s'y attendait, nous devons modéliser une **distribution différente** où la variance augmente plus rapidement que la moyenne.


---
# GLMM binomiale negative .small[(Poisson-gamma)]

**Option 1.** La distribution **binomiale négative** satisfait la supposition que la variance est proportionnelle au carré de la moyenne

&lt;br&gt;
--
On peut modéliser cette distribution avec la fonction `glmer.nb()` :

```r
mnb1 &lt;- glmer.nb(total.fruits ~ nutrient*amd + rack + status +
                 (1|popu) +
                 (1|gen),
                 data = dat.tf, control = glmerControl(optimizer = "bobyqa"))
# Control spécifie la façon dont nous optimisons les valeurs des paramètres
```
--
On teste à nouveau pour la présence de surdispersion :

```r
# Surdispersion?
overdisp_fun(mnb1)
#         chisq         ratio             p          logp 
# 721.034466390   1.170510497   0.002143424  -6.145350714
```

.alert[Le rapport est beaucoup plus près de 1 mais la valeur de p &lt; 0.05]


---
# GLMM Poisson-lognormale

**Option 2.** La distribution **Poisson-lognormale**
&lt;br&gt;

On réalise cette distribution en ajoutant un **effet aléatoire de niveau d'observation** dans le modèle.

Voir Harrison (2014) pour plus de détails https://doi.org/10.7717/peerj.616.

&lt;br&gt;
--
Pour ce faire, nous créons tout d'abord une variable nommée `X` :

```r
# Cette variable est déjà dans vos données "dat.tf", mais voici comment la créer.
dat.tf$X &lt;- 1:nrow(dat.tf)
```

On traite la surdispersion en ajoutant l'effet `(1|X)` dans la formule :

```r
mpl1 &lt;- glmer(total.fruits ~ nutrient*amd + rack + status +
              (1|X) +
              (1|popu) +
              (1|gen),
data = dat.tf, family = "poisson",
control = glmerControl(optimizer = "bobyqa"))
```


---
# GLMM Poisson-lognormale
&lt;br&gt;&lt;br&gt;&lt;br&gt;

On teste finalement pour la présence de surdispersion :

```r
overdisp_fun(mpl1)
#         chisq         ratio             p          logp 
#  1.775360e+02  2.886764e-01  1.000000e+00 -3.754681e-73
```

.alert[Le rapport est maintenant conforme avec notre critère, soit &lt; 1]


---
# GLMM Poisson-lognormale

**Représentons graphiquement les paramètres du modèle** 

Peut être obtenu en utilisant la fonction `coefplot2()`de la librairie `coefplot2` :
&lt;br&gt;&lt;br&gt;


.alert[![:faic](warning) Cette librairie n'est pas sur le CRAN! On utilise la librairie remotes pour l'installer à partir de GitHub]


```r
if (!require("coefplot2"))
  remotes::install_github("palday/coefplot2", subdir = "pkg")
# reshape (NA -&gt; 0.8.8) [CRAN]
#   
   checking for file ‘/tmp/RtmppbXEi1/remotes350c1296c667/palday-coefplot2-23b7dcb/pkg/DESCRIPTION’ ...
  
✔  checking for file ‘/tmp/RtmppbXEi1/remotes350c1296c667/palday-coefplot2-23b7dcb/pkg/DESCRIPTION’
# 
  
─  preparing ‘coefplot2’:
#    checking DESCRIPTION meta-information ...
  
✔  checking DESCRIPTION meta-information
# 
  
─  checking for LF line-endings in source and make files and shell scripts
# 
  
─  checking for empty or unneeded directories
# 
  
─  building ‘coefplot2_0.1.3.3.tar.gz’
# 
  
   
# 
library(coefplot2)
```


---
# GLMM Poisson-lognormale


.pull-left[

```r
# Effets aléatoires
coefplot2(mpl1, ptype = "vcov", intercept = TRUE, main = "Variance des effets aléatoires")
```

&lt;img src="workshop07-pres-fr_files/figure-html/unnamed-chunk-56-1.png" width="432" style="display: block; margin: auto;" /&gt;
]
.pull-right[

```r
# Effets fixes
coefplot2(mpl1, intercept = TRUE, main = "Coefficients des effets fixes")
```

&lt;img src="workshop07-pres-fr_files/figure-html/unnamed-chunk-57-1.png" width="432" style="display: block; margin: auto;" /&gt;
]

.comment[Note : barres d'erreur visibles seulement pour les effets fixes car `glmer()` ne modélise pas d'incertitude pour les effets aléatoires.]


---
# GLMM Poisson-lognormale

**Visualisation des effets aléatoires**

Vous pouvez extraire les effets aléatoires en utilisant la fonction `ranef()` et les tracer en utilisant un `dotplot()` de la librairie `lattice`.

&lt;br&gt;
--
On constate une variation **inter-population** :

- Les populations espagnoles (SP) ont des valeurs plus élevées que les populations suédoises (SW) et néerlandaises (NL)

On constate une faible variation **inter-génotype** :
- Les différences entre les génotypes semblent induites par le génotype 34

```r
library(gridExtra)
library(lattice)
# dotplot code
pp &lt;- list(layout.widths = list(left.padding = 0, right.padding = 0),
           layout.heights = list(top.padding = 0, bottom.padding = 0))
r2 &lt;- ranef(mpl1, condVar = TRUE)
d2 &lt;- dotplot(r2, par.settings = pp)
grid.arrange(d2$gen, d2$popu, nrow = 1)
```


---
# GLMM Poisson-lognormale

**Visualisation des effets aléatoires**

&lt;br&gt;

&lt;img src="workshop07-pres-fr_files/figure-html/unnamed-chunk-58-1.png" width="648" style="display: block; margin: auto;" /&gt;


---
# Sélection du modèle

Les même méthodes peuvent être utilisées avec un glmm ou lmm pour choisir entre des modèles avec différentes ordonnées à l'origine et/ou pentes aléatoires ainsi que pour choisir les effets fixes à conserver dans le modèle final.

&lt;br&gt;

En voici deux :

- une **approche de la théorie de l'information** (e.g., AICc - Atelier 5)
- une **approche fréquentiste** (où l'importance de chaque terme est évaluée en faisant un test de rapport de vraisemblance; LRT, avec la fonction `anova()`)


---
# Sélection du modèle

Nous dérivons d'abord les modèles potentiels et les comparons en utilisant l'AICc.comment[*] :


```r
mpl2 &lt;- update(mpl1, . ~ . - rack) # modèle sans rack
mpl3 &lt;- update(mpl1, . ~ . - status) # modèle sans status
mpl4 &lt;- update(mpl1, . ~ . - amd:nutrient) # modèle sans interaction amd:nutrient

aic_tab  &lt;- MuMIn::model.sel(mpl1, mpl2, mpl3, mpl4)
(round(aic_table &lt;- aic_tab[ , c("AICc", "delta", "df")], digits = 2))
#         AICc delta df
# mpl1 5015.73  0.00 10
# mpl4 5017.11  1.38  9
# mpl3 5017.22  1.49  8
# mpl2 5070.75 55.02  9
```

.comment[*NB: Nous ne couvrons pas tous les modèles possibles ci-dessus, cependant, l'interaction `amd:nutriments` ne peut être évaluée que si les effets additifs de amd et de nutriments sont présents dans le modèle.
]


---
# Sélection du modèle

Nous pouvons aussi utiliser les fonctions `drop1()` et `dfun()` pour évaluer nos effets fixes (`dfun()` convertit les valeurs AIC retournées par `drop1()` en valeurs `\(\Delta\)`AIC)

.small[

```r
dd_LRT &lt;- drop1(mpl1, test = "Chisq")
(dd_AIC &lt;- dfun(drop1(mpl1)))
# Single term deletions
# 
# Model:
# total.fruits ~ nutrient * amd + rack + status + (1 | X) + (1 | 
#     popu) + (1 | gen)
#              npar   dAIC
# &lt;none&gt;             0.000
# rack            1 55.083
# status          2  1.612
# nutrient:amd    1  1.444
```
]

--

- Fort effet de **rack** (dAIC = 55.08 si on enlève cette variable)
- Effets de **status** et de l'**interaction** sont faibles (dAIC &lt; 2)


---
# Sélection du modèle
Commençons par **enlever l'interaction non significative** afin de tester les effets principaux de nutriments et d'herbivorie.

```r
mpl2 &lt;- update(mpl1, . ~ . - amd:nutrient)

mpl3 &lt;- update(mpl2, . ~ . - rack) # pas de rack ou d'interaction
mpl4 &lt;- update(mpl2, . ~ . - status) # pas de status ou d'interaction
mpl5 &lt;- update(mpl2, . ~ . - nutrient) # pas de nutrient ou d'interaction
mpl6 &lt;- update(mpl2, . ~ . - amd) # pas d'herbivorie ou d'interaction
```

Sélectionnez le meilleur modèle avec la méthode de votre choix :
.pull-left2[ Méthode par AICc

```r
aic_tab2  &lt;- MuMIn::model.sel(mpl2, mpl3, mpl4, mpl5, mpl6)
(round(aic_table2 &lt;- aic_tab2[ , c("AICc", "delta", "df")], digits = 2))
#         AICc  delta df
# mpl2 5017.11   0.00  9
# mpl4 5018.28   1.17  7
# mpl6 5027.27  10.16  8
# mpl3 5071.28  54.17  8
# mpl5 5152.74 135.63  8
```
]
.pull-right2[ Méthode avec `drop1()`

```r
dd_LRT2 &lt;- drop1(mpl2, test = "Chisq")
dd_AIC2 &lt;- dfun(drop1(mpl2))
```
]


---
# Sélection du modèle
**Quels sont nos constats ?**
&lt;br&gt;

Les **nutriments** et l'**herbivorie** ont un effet important (grand changement d'AIC de `\(135.6\)` (`mpl5`) et `\(10.2\)` (`mpl6`) si l'un ou l'autre sont supprimés, respectivement)

&lt;br&gt;

**Notre modèle final inclut donc :**

Effets fixes
* nutriments, 
* herbivorie
* la variable nuisance de rack. 

Effets aléatoires 
* effet du niveau d'observation `(1|X)` 
* populations `(1|popu)` 
* génotypes `(1|gen)`


---
# Défi 9 ![:cube]()

En utilisant l'ensemble de données `inverts` (temps de développement larvaire (`PLD`) de 74 espèces d'invertébrés et vertébrés marins élevés à différentes températures et temps), répondez aux questions suivantes:

- Quel est l'effet du type d'alimentation et du climat (**effets fixes**) sur `PLD`?
- Est-ce que cette relation varie selon les taxons (**effets aléatoires**)?
- Quelle est la **meilleure famille de distributions** pour ces données?
- Finalement, une fois que vous avez déterminé la meilleure famille de distribution, re-évaluez vos effets fixes et aléatoires.


---
# Solution ![:cube]()


```r
# inverts &lt;- read.csv('data/inverts.csv', header = TRUE)
# head(inverts)
# table(inverts$temp, inverts$feeding.type)

# mod.glm &lt;- glm(PLD ~ temp + feeding.type, family = poisson(), data = inverts)
# summary(mod.glm)
# drop1(mod.glm, test = "Chisq")

# boxplot(PLD ~ temp,  data = inverts)
# boxplot(PLD ~ feeding.type ,  data = inverts)

# boxplot(predict(mod.glm, type = "response")~inverts$temp)

# plot()

# modglm &lt;- glm(PLD ~ temp + feeding.type, family = poisson(), data = inverts)
```


---
# Solution ![:cube]()

```r
# r2 &lt;- ranef(mpl1, condVar = TRUE)
# d2 &lt;- dotplot(r2, par.settings = pp)

# plot(aggregate(PLD ~ taxon, FUN = mean, data = inverts)[,2], aggregate(PLD ~ taxon, FUN = var, data = inverts)[,2], pch = 19)
# abline(a = 0, b = 1, lty = 2)

# mod.glmer &lt;- glmer.nb(PLD ~ temp + feeding.type + (1|taxon), data = inverts)
# mod.glm &lt;- glm.nb(PLD ~ temp + feeding.type, family = poisson(), data = inverts)

# plot(aggregate(PLD ~ taxon, FUN = var, data = inverts)[,2], aggregate(PLD ~ taxon, FUN = mean, data = inverts)[,2])
# abline(a = 0, b = 1, lty = 2 )
```


---
# Ressources additionnelles

.center[
![:scale 16%](images/book1.jpg) ![:scale 18%](images/book2.jpg) ![:scale 16%](images/book3.jpg)
]

**Libraries connues pour des (G)LMM** 

* Fréquentiste : `nlme`, `lme4`, `glmmTMB`
* Bayésien : `brms`, `rstan`, `rstanarm`, `MCMCglmm`

**Articles**
* [Harrison *et al.* (2018), *PeerJ*, DOI 10.7717/peerj.4794
](http://dx.doi.org/10.7717/peerj.4794)
* [Silk *et al.* (2020), *PeerJ*,  DOI 10.7717/peerj.9522
](https://doi.org/10.7717/peerj.9522)
* [Schielzeth *et al.* (2020), *Methods Ecol Evol.*,  DOI: 10.1111/2041-210X.13434
]( https://doi.org/10.1111/2041-210X.13434)
* [Zuur &amp; Ieno (2016), *Methods Ecol Evol.*,  DOI: 10.1111/2041-210X.12577
]( https://doi.org/10.1111/2041-210X.12577)


---
class: inverse, center, bottom

# Merci de votre participation à cet atelier!

![:scale 50%](images/qcbs_logo.png)


&lt;!-- https://stats.stackexchange.com/questions/64226/lme-and-lmer-comparison --&gt;
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="qcbsR-macros.js"></script>
<script>var slideshow = remark.create({
"highlightLines": true,
"highlightStyle": "github"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
