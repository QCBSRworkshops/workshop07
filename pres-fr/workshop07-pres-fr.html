<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Atelier 7: Modèles generales et generalisés à effets mixtes</title>
    <meta charset="utf-8" />
    <meta name="author" content="Centre de la science de la biodiversité du Québec" />
    <link href="assets/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css">
    <link rel="stylesheet" href="qcbsR.css" type="text/css" />
    <link rel="stylesheet" href="qcbsR-fonts.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Atelier 7: Modèles generales et generalisés à effets mixtes
## Série d’ateliers R du CSBQ
### Centre de la science de la biodiversité du Québec

---




class: inverse, center, middle



# À propos de cet atelier

[![badge](https://img.shields.io/static/v1?style=for-the-badge&amp;label=repo&amp;message=dev&amp;color=6f42c1&amp;logo=github)](https://github.com/QCBSRworkshops/workshop07)
[![badge](https://img.shields.io/static/v1?style=for-the-badge&amp;label=wiki&amp;message=07&amp;logo=wikipedia)](https://wiki.qcbs.ca/r_atelier7)
[![badge](https://img.shields.io/static/v1?style=for-the-badge&amp;label=diapos&amp;message=07&amp;color=red&amp;logo=html5)](https://qcbsrworkshops.github.io/workshop07/pres-fr/workshop07-pres-fr.html)
[![badge](https://img.shields.io/static/v1?style=for-the-badge&amp;label=diapos&amp;message=07&amp;color=red&amp;logo=adobe-acrobat-reader)](https://qcbsrworkshops.github.io/workshop07/workshop07-fr/workshop07-fr.pdf)
[![badge](https://img.shields.io/static/v1?style=for-the-badge&amp;label=script&amp;message=07&amp;color=2a50b8&amp;logo=r)](https://qcbsrworkshops.github.io/workshop07/workshop07-fr/workshop07-fr.R)

---

# Packages requis

* [ggplot2](https://cran.r-project.org/package=ggplot2)
* [lme4](https://cran.r-project.org/package=lme4)
* [AICcmodavg](https://cran.r-project.org/package=AICcmodavg)
* [MASS](https://cran.r-project.org/package=MASS)
* [vcdExtra](https://cran.r-project.org/package=vcdExtra)
* [bbmle](https://cran.r-project.org/package=bbmle)
* [DescTools](https://cran.r-project.org/package=DescTools)


&lt;br&gt;


```r
install.packages(c("ggplot2", 
                   "lme4", 
                   "AICcmodavg", 
                   'MASS', 
                   'vcdExtra', 
                   'bbmle', 
                   'DescTools'))
```

---

# Objectifs d'apprentissage

1. Décrivez ce que sont les modèles à effets mixtes ;

2. Identifier les situations dans lesquelles l'utilisation d'effets mixtes est appropriée ;

3. Mettre en œuvre les modèles mixtes linéaires de base en `R` ;

4. Exécuter les modèles linéaires mixtes généralisés de base dans `R` ;

5. Valider, interpréter et visualiser les modèles mixtes dans  `R`.


---
# Question

.alert[**Est-ce que la position trophique des poissons augmente avec leur taille?**
]

Pour répondre, 3 espèces ont été sélectionnées et dix individus par espèce ont été mesurés (longueur corporelle) dans six lacs différents.

.center[ ![:scale 75%](images/fig_1_qcbs_wiki.png) ]



---
# Familiarisez vous avec le jeu de données
&lt;br&gt;

1. Ouvrez le jeu de données,

2. Ouvrez le script de l'atelier dans R,

3. Visualisez la relation entre taille et position trophique.

--

&lt;br&gt;


```r
fish.data &lt;- read.csv('data/qcbs_w7_data.csv', stringsAsFactors = TRUE)
head(fish.data)
#   Lake Fish_Species Fish_Length Trophic_Pos
# 1   L1           S1    105.1501    2.602388
# 2   L1           S1    194.5708    2.703522
# 3   L1           S1    294.3636    2.742878
# 4   L1           S1    413.5295    2.737743
# 5   L1           S1    237.4739    2.785936
# 6   L1           S1    107.9315    2.723862
```


---
# Visualisation avec toutes les données

&lt;br&gt;

&lt;img src="workshop07-pres-fr_files/figure-html/unnamed-chunk-3-1.png" width="432" style="display: block; margin: auto;" /&gt;

---
# Visualisation de l'ensemble des données

&lt;br&gt;


```r
# thème simplifié
fig &lt;- theme_bw() + theme(panel.grid.minor=element_blank(),
    panel.grid.major=element_blank(), panel.background=element_blank()) +
    theme(strip.background=element_blank(), strip.text.y = element_text()) +
    theme(legend.background=element_blank()) +
    theme(legend.key=element_blank()) +
    theme(panel.border = element_rect(colour="black", fill=NA))

# Faites les trois graphiques suivants pour explorer les données
plot &lt;- ggplot(aes(Fish_Length,Trophic_Pos),data = fish.data)

# Graphique 1 - Toutes les données
plot + geom_point() + xlab("Length (mm)") + ylab("Trophic Position") + labs(title="All Data") + fig
```


---
# Visualisation par espèce


```r
# Graphique 2 - Par espèce
plot + geom_point() + facet_wrap(~ Fish_Species) + xlab("Length (mm)") + ylab("Trophic Position") +
   labs(title="By Species") + fig
```

&lt;img src="workshop07-pres-fr_files/figure-html/unnamed-chunk-5-1.png" width="432" style="display: block; margin: auto;" /&gt;

---
# Visualisation par Lake


```r
# Graphique 3 – Par lac
plot + geom_point() + facet_wrap(~ Lake) + xlab("Length (mm)") + ylab("Trophic Position") +
   labs(title="By Lake") + fig
```

&lt;img src="workshop07-pres-fr_files/figure-html/unnamed-chunk-6-1.png" width="432" style="display: block; margin: auto;" /&gt;


---
# Pourquoi choisir un MLM?

**Discussion de groupe**

* Est-ce qu'on s'attend à ce que, pour toutes les espèces, la position trophique augmente avec la longueur corporelle?

    * Exactement de la même façon?

&lt;br&gt;

--

* Est-ce qu'on s'attend à ce que ces relations soient pareilles entre les lacs?

    * Comment pourraient-elles différer?

---
# Pourquoi choisir un MLM?

&lt;br&gt;

.large[**Comment pourrions-nous analyser ces données?**]

--

&lt;br&gt;

**Option 1. Séparer**:

- Faire une analyse séparée pour chaque espèces et chaque lac

&lt;br&gt;

**Option 2. Regrouper**:

- Faire une seule analyse en ignorant les variables espèces et lac


---
# Pourquoi choisir un MLM?

.pull-left[![](images/fig_5_w5.png) ]

.pull-right[
**Option 1. Séparer**
* Estime 6 intercepts et 6 pentes pour chaque espèces (i.e. 6 lacs)

* Taille d'échantillon *n* = 10 pour chaque analyse (i.e. 10 poissons/espèces/lac)

* Peu de chances de détecter un effet a cause de la faible taille d’échantillon *n*
]

---
# Pourquoi choisir un MLM?

.pull-left[![](images/fig_6_w5.png)]

.pull-right[
**Option 2. Regrouper:**
* Très grande taille d'échantillon!

* Et la pseudoreplication? (les poissons d'un même lac et d'une même espèce sont corrélés).

* Beaucoup de bruit! Une partie doit être due aux effets de l'espèce et du lac.
]

---
# Pourquoi choisir un MLM?


* Pour **notre question**, on veut seulement savoir s'il y a un **effet général de la longueur corporelle sur la position trophique**,

* Ceci pourrait varier faiblement par espèce à cause de différents taux de croissance et/ou par lac à cause de différences dans la disponibilité de nourriture. **On ne s'intéresse pas directement à ces facteurs non mesurés, mais on doit contrôler leur effet dans le modèle**.

--

&lt;br&gt;

Les MLMs sont un **compromis entre séparer et regrouper**. Ils:

1. Prendre entre compte de la variabilité spécifique pour chaque espèce et chaque lac (séparer) mais en calculant moins de paramètres;

2. Utilisent toutes les données disponibles (regrouper) tout en contrôlant les différences entre les lacs et les espèces (pseudo-replication).

---
# Pourquoi choisir un MLM?

#### Effet fixe VS effet aléatoire

Dans la littérature des MLMs, vous rencontrerez souvent ces termes souvent. Il existe plusieurs façon de les présenter et nous vous présenterons ici celles que nous trouvons les plus faciles à appliquer.

--

##### Effet fixe

* Les données proviennent de tous les niveaux possibles d'un facteur (variable qualitative),

* On souhaite émettre des conclusions à propos des niveaux du facteur d'où les données proviennent.

--

##### Effet aléatoire

* Seulement des variables qualitatives = facteur aléatoire;

* Permet de structurer le processus d'erreur.

---
# Pourquoi choisir un MLM?
&lt;br&gt;

#### Comment fonctionnent les MLMs?
&lt;br&gt;

**A.** Permet aux intercepts et/ou aux pentes d'être considérés comme propre à une population donnée (**effet aléatoire**), e.g. par lac et/ou par espèce

&lt;br&gt;

**B.** Les intercepts, les pentes et leur intervalle de confiance sont ajustés pour **prendre en compte la structure des données**.


---
# Effet aléatoire sur l'intercept
&lt;br&gt;

&lt;img style="float: right; width:50%;margin: 1%" src="images/fig_7_w5.png"&gt;

On fait la supposition que les intercepts proviennent d'une distribution normale et on a seulement besoin d'estimer la moyenne (intercept général) et l'écart type de la distribution normale (effet aléatoire) au lieu d'estimer un intercept par espèce (ce qui rajoute 2 paramètres).

&lt;br&gt;&lt;br&gt;

Au lieu d'estimer d'estimer un intercept par espèce (trois paramètres pour 3 espèces) on estime un intercept générale et un effet aléatoire soit 2 paramètres. Avec `\(n\)` espèce, dans le premier cas on estime `\(n-1\)` paramètres
alors qu'on reste à 2 paramètres dans le second cas!




---
# Effet aléatoire sur l'intercept
&lt;br&gt;&lt;br&gt;

&lt;img style="float: right; width:50%;margin: 1%" src="images/fig_8_w5.png"&gt;
Même principe pour les lacs

Estime 2 paramètres (moyenne et écart-type) au lieu de 6 intercepts.

Cela économise des degrés de liberté (moins d’estimation de paramètres sont nécessaires)



---
# Effet aléatoire sur la pente
&lt;br&gt;&lt;br&gt;

&lt;img style="float: right; width:50%;margin: 1%" src="images/fig_9_w5.png"&gt;
Le même principe s’applique aux pentes qui varient selon un facteur donné, juste plus difficile à visualiser.

Comme pour les intercepts, seuls la moyenne et l’écart-type des pentes sont estimés au lieu de trois pentes distinctes.

---
# Tenir compte de la structure des données
&lt;br&gt;

Si une certaine espèce ou un lac est peu représenté (faible `\(n\)`) dans les données, le modèle va accorder plus d'importance au modèle groupé pour estimer l'intercept et la pente de cette espèce ou de ce lac.

.center[![:scale 60%](images/fig_12_w5.png) ]

---
# Tenir compte de la structure des données
&lt;br&gt;&lt;br&gt;

* Les intervalles de confiance des intercepts et pentes sont ajustés pour tenir compte de la pseudo-replication basée sur le **coefficient de corrélation intra-classe (CCI)**.

* Combien de variation y a-t-il dans chaque groupe VS entre les groupes ?


---
# Tenir compte de la structure des données


.pull-left[
**CIC élevé**

![](images/fig_10_w5.png)

les points provenant d'un même lac sont traités comme une seule observation car très corrélés

![:faic](arrow-right) petite taille effective de l'échantillon et grands intervalles de confiance pour la pente et l'intercept.
]

.pull-right[
**CIC faible**

![](images/fig_11_w5.png)

les points provenant d'un même lac sont traités indépendamment car peu corrélés

![:faic](arrow-right) grande taille effective de l'échantillon et petits intervalles de confiance pour la pente et l'intercept.
]

---
# Question / défi ![:cube]()

&lt;br&gt;

**Comment le CIC et l'intervalle de confiance seront affectés dans ces deux scénarios ?**

**Q1.** Les positions trophiques des poissons ne varient pas entre les lacs

&lt;br&gt;

**Q2.** Les positions trophiques des poissons sont similaires dans les lacs mais différentes entre les lacs

---
# Solution ![:cube]()

&lt;br&gt;

**Q1.** La position trophique ne varie pas entre les lacs?

.alert[R1. CIC faible, petits intervalles de confiances]

&lt;br&gt;

--

**Q2.** La position trophique est similaire dans un lac mais différente entre les lacs ?

.alert[R2. CIC élevé, grands intervalles de confiance]

---
# Comment implémenter un MLM dans R ?

&lt;img style="float:right; width:32%; margin:1%" src="images/lego.jpg"&gt;

###### **Étape 1:** Construction du modèle *a priori* et exploration des données

&lt;br&gt;

**Étape 2:** Coder les modèles potentiels et sélection du meilleur modèle

&lt;br&gt;

**Étape 3:** Validation du modèle

&lt;br&gt;

**Étape 4:** Interprétation et visualisation des résultats

---
# Étape 1 - construction du modèle *a priori*

**Modèle basé sur connaissance *a priori*:**

* Nous voulons déterminer si la position trophique peut être prédite par la longueur corporelle, tout en prenant en compte la variation entre les espèces et les lacs

* Donc nous voulons un modèle qui ressemble a ceci:

`$$PT_{ijk} \sim Longueur_i + Lac_j + Espèce_k + \varepsilon_{ijk}$$`
---
# Étape 1 - exploration des données

**Les données ont-elles la bonne structure?**


```r
fish.data &lt;- read.csv('data/qcbs_w7_data.csv')
str(fish.data)
# 'data.frame':	180 obs. of  4 variables:
#  $ Lake        : chr  "L1" "L1" "L1" "L1" ...
#  $ Fish_Species: chr  "S1" "S1" "S1" "S1" ...
#  $ Fish_Length : num  105 195 294 414 237 ...
#  $ Trophic_Pos : num  2.6 2.7 2.74 2.74 2.79 ...
```

Il est recommandé de faire le ménage de votre espace de travail (`rm.list()`) avant de construire un modèle.

---
# Étape 1 - exploration des données

**Regardez la distribution des échantillons pour chaque facteur:**


```r
table(fish.data[ , c("Lake", "Fish_Species")])
#     Fish_Species
# Lake S1 S2 S3
#   L1 10 10 10
#   L2 10 10 10
#   L3 10 10 10
#   L4 10 10 10
#   L5 10 10 10
#   L6 10 10 10
```

Ce jeu de données est parfaitement équilibré, mais les **modèles mixtes peuvent analyser des designs expérimentaux non équilibrés**, comme c'est souvent le cas en écologie!

---
# Étape 1 - exploration des données

**Regardez la distribution des variables continues**


```r
par(mfrow=c(1,2), mar = c(4,4,1,1))
hist(fish.data$Fish_Length, xlab = "Length (mm)", main = "")
hist(fish.data$Trophic_Pos, xlab = "Trophic position", main = "")
```

&lt;img src="workshop07-pres-fr_files/figure-html/unnamed-chunk-9-1.png" width="720" style="display: block; margin: auto;" /&gt;

Des déviations majeures pourraient causer des problèmes d'hétéroscédasticité. Si nécessaire, faites des transformations. Dans ce cas-ci, **les données semblent correctes**.

---
# Étape 1 - exploration des données

**Vérifier la colinéarité entre vos variables explicatives**

Le problème avec les prédicteurs colinéaires est simplement qu'ils expliquent la même chose, alors leur effet sur la variable réponse sera confondu dans le modèle.

Dans cet exemple, il n’y a pas de risque de colinéarité avec seulement une variable continue. Si vous aviez une autre variable continue (`Var2`), une façon simple de vérifier la colinéarité est:


```r
plot(data)

cor(var1, var2)
```

---
# Défi 3 ![:cube]()

Quelles mesures supplémentaires aurions-nous pu prendre sur le terrain et qui auraient pu être fortement corrélées avec la longueur corporelle?

--

&gt; Un exemple est la masse du poisson – c’est une variable fortement corrélée avec la longueur du poisson. Par conséquent, nous ne voulons pas inclure ces deux variables dans le même modèle.

---
# Étape 1 - exploration des données

**Considérez l'échelle de vos données**

* Si deux variables dans un même modèle ont des échelles très différentes, il est probable que le modèle indique un problème de convergence en essayant de calculer les paramètres.

* La &lt;a href="https://fr.wikipedia.org/wiki/Cote_Z_(statistiques)"&gt;correction Z&lt;/a&gt; standardise les variables et résout ce problème (fonction `scale()` dans `R`) :

`$$z = \frac{x-moyenne(x)}{écart.type(x)}$$`
---
# Étape 1 - exploration des données

**Considérez l'échelle de vos données**

* Longueur corporelle ![:faic](arrow-right) Longue échelle

* Position trophique ![:faic](arrow-right) Courte échelle

---
# Étape 1 - exploration des données

**Considérez l'échelle de vos données**

Parce que nos données ont des échelles très différentes, on applique la **correction Z**


```r
# Longueur corrigée, "à la main"
fish.data$Z_Length &lt;- (fish.data$Fish_Length - mean(fish.data$Fish_Length)) / 
                      sd(fish.data$Fish_Length)

# Position trophique corrigée, avec la fonction scale
fish.data$Z_TP     &lt;- scale(fish.data$Trophic_Pos)
```

---
# Étape 1 - exploration des données

Pour savoir si un modèle mixte est nécessaire pour vos données, vous devez déterminer s'il est important de prendre en compte l'effet aléatoire de facteurs qui pourraient influencer la relation qui vous intéresse (dans notre cas, lac et espèce)

Nous pouvons le faire en :

1. Créant un modèle linéaire sans les facteurs qui pourraient avoir un effet aléatoire

2. Calculant les résidus de ce modèle linéaire

3. Produisant un graphique de la valeur des résidus en fonction des niveaux des facteurs potentiellement aléatoires

---
# Étape 1 - exploration des données

Créer un modèle linéaire sans les facteurs

```r
lm.test &lt;- lm(Z_TP ~ Z_Length, data = fish.data)
```

Calculer les résidus de ce modèle linéaire

```r
lm.test.resid &lt;- rstandard(lm.test)
```

---
# Étape 1 - exploration des données

Représentez graphiquement la valeur des résidus en fonction des niveaux des facteurs


```r
par(mfrow=c(1,2))

plot(lm.test.resid ~ as.factor(fish.data$Fish_Species),
     xlab = "Species", ylab = "Standardized residuals")

abline(0, 0, lty = 2)

plot(lm.test.resid ~ as.factor(fish.data$Lake),
     xlab = "Lake", ylab = "Standardized residuals")

abline(0, 0, lty = 2)
```

---
# Étape 1 - Exploration des données

Représentez graphiquement la valeur des résidus en fonction des niveaux des facteurs

&lt;img src="workshop07-pres-fr_files/figure-html/unnamed-chunk-15-1.png" width="720" style="display: block; margin: auto;" /&gt;

.alert[Ces patrons suggèrent qu'il y a de la variance résiduelle qui pourrait être expliquée par ces facteurs, et ils devraient donc être inclus dans le modèle]

---
# Comment implémenter un MLM dans R ?

&lt;img style="float: right; width:32%;margin: 1%" src="images/lego.jpg"&gt;

**Étape 1:** Construction du modèle *a priori* et exploration des données

&lt;br&gt;

###### **Étape 2:** Coder les modèles potentiels et sélection du meilleur modèle

&lt;br&gt;

**Étape 3:** Validation du modèle

&lt;br&gt;

**Étape 4:** Interprétation et visualisation des résultats

---
# Étape 2 - coder le modèle

**Traduisons notre modèle...**

`$$PT_{ijk} \sim Longueur_i + Lac_j + Espèce_k + \varepsilon_{ijk}$$`

**... En code R**




```r
library(lme4)
lmer(Z_TP ~ Z_Length + (1 | Lake) + (1 | Fish_Species),
     data = fish.data, REML = TRUE)
```

--

* `lmer` ![:faic](arrow-right) fonction "linear mixed model" du package `lme4`
* `(1 | Lake)` ![:faic](arrow-right) indique que les intercepts peuvent varier entre les lacs
* `REML = TRUE` ![:faic](arrow-right) méthode d'estimation

---
# Note à propos de la méthode d'estimation

REML (Restricted Maximum Likelihood) est la méthode par défaut dans la fonction `lmer` (voir `?lmer`).

Notez que l'estimateur de l’écart-type du maximum de vraisemblance (ML, pour Maximum Likelihood) est biaisé d’un facteur `\((n-2) / n\)`. La méthode REML corrige ce biais.

On devrait utiliser:
- **REML** pour comparer des modèles avec des **effets aléatoires imbriqués** 
- et **ML** pour comparer des modèles avec des **effets fixes imbriqués**.

---
# Étape 2 - coder le modèle

**Comment faire si on souhaite que la pente puisse varier ?**

.center[
![](images/fig_22_w5.png)
]

---
# Étape 2 - coder le modèle

**Plus généralement**

- `(1 | Lake)` effet aléatoire par lac à l'intercept
- `(1 + Z_Length | Lake)` effet aléatoire par lac à l'intercept et la pente en réponse à la longueur corporelle (NB: (`Z_Length | Lake)` donne le même résultat)
- `(-1 + Z_Length | Lake)` pour avoir uniquement l'effet aléatoire sur la pente
- `(1 | Lake) + (1 | Species)`  pour des effets aléatoires croisés
- `(1 | Lake:Fish_Species)` pour utiliser l'interaction entre 2 facteurs groupant
- si votre jeu de données inclus des effets imbriqués, vous pouvez utiliser `/` pour les déclarer, e.g. `(1 | facteur1 / facteur2)` si `facteur2` est imbriqué dans `facteur1` ([voir ![:faic](stack-exchange)](https://stats.stackexchange.com/questions/228800/crossed-vs-nested-random-effects-how-do-they-differ-and-how-are-they-specified))

---
# Défi 4 ![:cube]()

Réécrivez le code suivant de façon à ce que les **pentes** de la relation position trophique en fonction de longueur corporelle **varient par lac et par espèces**:


```r
lmer(Z_TP ~ Z_Length + (1 | Lake) + (1 | Fish_Species),
     data = fish.data, REML = TRUE)
# Linear mixed model fit by REML ['lmerMod']
# Formula: Z_TP ~ Z_Length + (1 | Lake) + (1 | Fish_Species)
#    Data: fish.data
# REML criterion at convergence: 72.4662
# Random effects:
#  Groups       Name        Std.Dev.
#  Lake         (Intercept) 0.4516  
#  Fish_Species (Intercept) 0.9301  
#  Residual                 0.2605  
# Number of obs: 180, groups:  Lake, 6; Fish_Species, 3
# Fixed Effects:
# (Intercept)     Z_Length  
#   9.752e-14    4.198e-01
```

---
# Solution ![:cube]()


```r
lmer(Z_TP ~ Z_Length + (1 + Z_Length | Lake) + (1 + Z_Length | Fish_Species),
     data = fish.data, REML = TRUE)
# Linear mixed model fit by REML ['lmerMod']
# Formula: 
# Z_TP ~ Z_Length + (1 + Z_Length | Lake) + (1 + Z_Length | Fish_Species)
#    Data: fish.data
# REML criterion at convergence: 20.5786
# Random effects:
#  Groups       Name        Std.Dev. Corr 
#  Lake         (Intercept) 0.45279       
#               Z_Length    0.02378  -0.82
#  Fish_Species (Intercept) 0.93103       
#               Z_Length    0.15728  1.00 
#  Residual                 0.22341       
# Number of obs: 180, groups:  Lake, 6; Fish_Species, 3
# Fixed Effects:
# (Intercept)     Z_Length  
#  -0.0009025    0.4223738  
# optimizer (nloptwrap) convergence code: 0 (OK) ; 0 optimizer warnings; 1 lme4 warnings
```

---
# Étape 2 - sélectionner le meilleur modèle

* Pour déterminer si vous avez construit le meilleur modèle mixte basé sur vos connaissances a priori, vous devez comparer ce modèle aux autres modèles alternatifs.

* Avec le jeu de données sur lequel vous travaillez, il y a plusieurs modèles alternatifs qui pourraient mieux correspondre à vos données.

---
# Défi 5 ![:cube]()

Faites une liste de 7 modèles alternatifs qui pourraient être comparés à celui-ci:


```r
lmer(Z_TP ~ Z_Length + (1 | Lake) + (1 | Fish_Species),
     data = fish.data, REML = TRUE)
```

Note: Si nous avions différents effets fixes entre les modèles, nous aurions dû indiquer `REML=FALSE` pour les comparer avec une méthode de vraisemblance comme l'AIC. Ici, vous devez rapporter les estimations des paramètres du "meilleur" modèle en utilisant `REML=TRUE`.

---
# Solution ![:cube]()

Nous allons aussi construire le **modèle linéaire de base** `lm()` parce qu'il est toujours utile de voir la variation dans les valeurs de AICc.


```r
M0 &lt;- lm(Z_TP ~ Z_Length, data = fish.data)
```

Par contre, pour comparer ce modèle aux MLMs, il est important de .alert[changer la méthode d'estimation à ML (`REML=FALSE`)] parce que `lm()` n'utilise pas la même méthode d'estimation que `lmer()`.

---
# Solution


```r
# Modele linéaire de base
M0 &lt;- lm(Z_TP ~ Z_Length, data = fish.data)
# modèle complet avec variation des intercepts
M1 &lt;- lmer(Z_TP ~ Z_Length + (1 | Fish_Species) + (1 | Lake), 
           data = fish.data, REML = FALSE)
# modèle complet avec variation des intercepts et de pentes
M2 &lt;- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Fish_Species) + (1 + Z_Length | Lake),
           data = fish.data, REML = FALSE)
# Pas d'effet lac, les intercepts varient par espèces
M3 &lt;- lmer(Z_TP ~ Z_Length + (1 | Fish_Species), data = fish.data, REML = FALSE)
# Pas d'effet espèces, les intercepts varient par lac
M4 &lt;- lmer(Z_TP ~ Z_Length + (1 | Lake), data = fish.data, REML = FALSE)
# Pas d'effet de lac, les intercepts et les pentes varient par espèces
M5 &lt;- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Fish_Species), 
           data = fish.data, REML = FALSE)
# Pas d'effet de l'espèces, les intercepts et les pentes varient par lac
M6 &lt;- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Lake), data = fish.data, REML = FALSE)
# modèle complet, variation d'intercept et pente par lac
M7 &lt;- lmer(Z_TP ~ Z_Length + (1 | Fish_Species) + (1 + Z_Length | Lake),
           data = fish.data, REML = FALSE)
# modèle complet, variation d'intercept et pente par espèces
M8 &lt;- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Fish_Species) + (1 | Lake),
           data = fish.data, REML = FALSE)
```

---
# Solution

![:faic](question) `boundary (singular) fit: see ?isSingular`, voir [cette discussion ![:faic](stack-exchange)](https://stats.stackexchange.com/questions/378939/dealing-with-singular-fit-in-mixed-models)

---
# Étape 2 - sélectionner le meilleur modèle

* Maintenant que nous avons une liste de modèles potentiels, nous voulons les comparer entre eux pour sélectionner celui(ceux) qui a(ont) le plus de pouvoir prédictif.

* Les modèles peuvent être comparés en utilisant la fonction `AICc` provenant du package `AICcmodavg`.

* Le critère d'information Akaike (AIC) est une **mesure de qualité du modèle** pouvant être utilisée pour comparer les modèles.

* AICc corrige pour le biais créé par les faibles tailles d'.

---
# Étape 2 - sélectionner le meilleur modèle

Pour trouver la valeur AICc d'un modèle, utilisez :


```r
library(AICcmodavg)
AICcmodavg::AICc(M1)
# [1] 77.30499
```

---
# Étape 2 - sélectionner le meilleur modèle

Pour regrouper toutes les valeurs d'AICc dans un seul tableau, utilisez :


```r
AIC.table &lt;- data.frame(Model = c("M0", "M1", "M2", "M3", 
                                  "M4", "M5", "M6", "M7", "M8"),
                        AICc = c(AICcmodavg::AICc(M0), 
                                 AICcmodavg::AICc(M1), 
                                 AICcmodavg::AICc(M2), 
                                 AICcmodavg::AICc(M3),
                                 AICcmodavg::AICc(M4), 
                                 AICcmodavg::AICc(M5), 
                                 AICcmodavg::AICc(M6),
                                 AICcmodavg::AICc(M7), 
                                 AICcmodavg::AICc(M8)))

# ordonner la table en ordre croissant d'AICc
AIC.table &lt;- AIC.table[order(AIC.table$AICc), ]

# rajouter la différence d'AICc avec la valeur d'AICc la plus petite (delta AICc)
AIC.table$delta_AICc &lt;- AIC.table$AICc - AIC.table$AICc[1]
```

---
# Étape 2 - sélectionner le meilleur modèle

Que signifient ces valeurs d'AICc ?


```r
AIC.table
#   Model      AICc delta_AICc
# 9    M8  31.84702   0.000000
# 3    M2  35.49086   3.643839
# 2    M1  77.30499  45.457965
# 8    M7  81.02391  49.176890
# 6    M5 269.10754 237.260517
# 4    M3 277.29450 245.447480
# 5    M4 457.66010 425.813076
# 7    M6 461.82795 429.980930
# 1    M0 479.85909 448.012065
```

Le modèle avec le plus petit AICc a le plus grand pouvoir prédictif.

Souvent on considère que deux modèles à +/- 2 unités d'AICc de différence ont un pouvoir prédictif équivalent.

---
# Étape 2 - sélectionner le meilleur modèle

Quelle est la structure du meilleur modèle?


```r
M8 &lt;- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Fish_Species) + (1 | Lake),
           data = fish.data, REML = FALSE)
```

L'intercept et l'effet de la longueur sur la position trophique peut varier selon l'espèce de poissons, mais seulement l'intercept peut varier par lac

.pull-left[![](images/fig_9_w5.png)]
.pull-right[![](images/fig_8_w5.png)]

---
# Étape 2 - sélectionner le meilleur modèle

Une fois que le meilleur modèle est sélectionné il faut remettre la méthode d'estimation a `REML=TRUE`


```r
M8 &lt;- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Fish_Species) + (1 | Lake),
           data = fish.data, REML = TRUE)
```

---
exclude: true

# Défi 5 ![:cube]()

Prenez 2 minutes avec votre voisin pour étudier la structure du modèle M2.

Comment diffère-t-il de M8 d'un point de vue écologique?

Pourquoi n'est il pas surprenant que sa valeur d'AICc était la deuxième meilleure?


```r
M8 &lt;- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Fish_Species) + (1 | Lake),
           data = fish.data, REML = TRUE)

M2 &lt;- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Fish_Species) + (1 + Z_Length | Lake),
           data = fish.data, REML = TRUE)
```

---
exclude: true

# Solution

**Discussion de groupe...**

--
exclude: true

.alert[M2] La position trophique est en fonction de la longueur. L'intercept et l'effet de la longueur sur la position trophique peuvent varier selon l'espèce de poissons et le lac.

* .small[les facteurs intrinsèques des espèces et des lacs sont à la base des relations différentes entre la position trophique et la longueur (i.e. pentes et intercepts)]

.alert[M8] La position trophique est en fonction de la longueur. L'intercept et l'effet de la longueur sur la position trophique peut varier selon l’espèce de poissons, mais seulement l'intercept peut varier par lac.

* .small[seulement les facteurs intrinsèques des espèces sont responsables des différentes relations (i.e. pentes) et en moyenne, les positions trophiques pourraient être supérieures ou inférieures d’un lac à l’autre (e.g. intercepts).]

---
# Comment implémenter un MLM dans R ?

&lt;img style="float: right; width:32%;margin: 1%" src="images/lego.jpg"&gt;

**Étape 1:** Construction du modèle *a priori* et exploration des données

&lt;br&gt;

**Étape 2:** Coder les modèles potentiels et sélection du meilleur modèle

&lt;br&gt;

###### **Étape 3:** Validation du modèle

&lt;br&gt;

**Étape 4:** Interprétation et visualisation des résultats

---
# Étape 3 - validation du modèle

Vous devez vérifier que le modèle respecte toutes les suppositions de base:

1. Vérifier l'homogénéité de la variance
  - Faire un graphique des valeurs prédites en fonction des valeurs résiduelles

2. Vérifier l'indépendance des résidus
  - Graphique des résidus VS chaque covariable du modèle
  - Graphique des résidus VS chaque covariable non incluse du modèle

3. Vérifier la normalité
  - Histogramme

---
# Étape 3 - validation du modèle

1- Vérifier l'homogénéité de la variance


```r
plot(resid(M8) ~ fitted(M8), 
     xlab = 'Valeurs prédites', 
     ylab = 'Résidus normalisés')
abline(h = 0, lty = 2)
```

&lt;img src="workshop07-pres-fr_files/figure-html/unnamed-chunk-29-1.png" width="324" style="display: block; margin: auto;" /&gt;

Étendue homogène des résidus ![:faic](arrow-right) la supposition est respectée!

---
# Étape 3 - validation du modèle

1- Vérifier l'homogénéité de la variance

.center[
![](images/resid-plots.gif)
]

---
# Étape 3 - validation du modèle

2- Vérifier l'indépendance des résidus avec chaque covariable


```r
par(mfrow = c(1,3), mar=c(4,4,.5,.5))

plot(resid(M8) ~ fish.data$Z_Length, 
     xlab = "Longueur", ylab = "Résidus normalisés")
abline(h = 0, lty = 2)

boxplot(resid(M8) ~ Fish_Species, data = fish.data, 
        xlab = "Espèces", ylab = "Résidus normalisés")
abline(h = 0, lty = 2)

boxplot(resid(M8) ~ Lake, data = fish.data, 
        xlab = "Lacs", ylab = "Résidus normalisés")
abline(h = 0, lty = 2)
```

---
# Étape 3 - validation du modèle

2- Vérifier l'indépendance des résidus avec chaque covariable

&lt;img src="workshop07-pres-fr_files/figure-html/unnamed-chunk-31-1.png" width="864" style="display: block; margin: auto;" /&gt;

Étendue homogène des résidus autour de 0 ![:faic](arrow-right) pas de patron des résidus en fonction de la variable, la supposition est respectée!

Note: Les regroupements de données sont dus à la structure des données, où des poissons de seulement 5 classes de taille  (grand, petit, et trois groupes entre les deux) étaient capturés.

---
# Étape 3 - validation du modèle

2- Vérifier l'indépendance des résidus avec chaque covariable

- Graphique des résidus VS chaque covariable non incluse du modèle

  - Si vous observez des patrons dans ce graphique, vous saurez qu'il y a de la variation dans votre jeu de données qui pourrait être expliquée par ces covariables. Vous devriez considérer d'inclure ces variables dans votre modèle.

  - Puisque dans notre cas, nous avons inclus toutes les variables mesurées dans notre modèle, nous ne pouvons pas faire cette étape.

---
# Étape 3 - validation du modèle

3- Vérifier la normalité des résidus

* Des résidus suivant une distribution normale indiquent que le modèle n'est pas biaisé


```r
hist(resid(M8))
```

&lt;img src="workshop07-pres-fr_files/figure-html/unnamed-chunk-32-1.png" width="360" style="display: block; margin: auto;" /&gt;

---
# Comment implémenter un MLM dans R ?

&lt;img style="float: right; width:32%;margin: 1%" src="images/lego.jpg"&gt;

**Étape 1:** Construction du modèle *a priori* et exploration des données

&lt;br&gt;

**Étape 2:** Coder les modèles potentiels et sélection du meilleur modèle

&lt;br&gt;

**Étape 3:** Validation du modèle

&lt;br&gt;

###### **Étape 4:** Interprétation et visualisation des résultats

---
# Étape 4 - interprétation et visualisation


```r
(summ_M8 &lt;- summary(M8))
# Linear mixed model fit by REML ['lmerMod']
# Formula: Z_TP ~ Z_Length + (1 + Z_Length | Fish_Species) + (1 | Lake)
#    Data: fish.data
# 
# REML criterion at convergence: 21.7
# 
# Scaled residuals: 
#      Min       1Q   Median       3Q      Max 
# -2.77187 -0.60166  0.05589  0.64239  2.27776 
# 
# Random effects:
#  Groups       Name        Variance Std.Dev. Corr
#  Lake         (Intercept) 0.20504  0.4528       
#  Fish_Species (Intercept) 0.86715  0.9312       
#               Z_Length    0.02466  0.1570   1.00
#  Residual                 0.05039  0.2245       
# Number of obs: 180, groups:  Lake, 6; Fish_Species, 3
# 
# Fixed effects:
#               Estimate Std. Error t value
# (Intercept) -0.0009059  0.5687733  -0.002
# Z_Length     0.4222697  0.0922117   4.579
# 
# Correlation of Fixed Effects:
#          (Intr)
# Z_Length 0.929 
# optimizer (nloptwrap) convergence code: 0 (OK)
# boundary (singular) fit: see ?isSingular
```

---
# Étape 4 - interprétation et visualisation

    # Random effects:
    #  Groups       Name        Variance Std.Dev. Corr
    #  Lake         (Intercept) 0.20500  0.4528
    #  Fish_Species (Intercept) 0.86621  0.9307
    #               Z_Length    0.02464  0.1570   1.00
    #  Residual                 0.05040  0.2245

- `Groups`: facteurs groupant,
- `Name`:
  - `(Intercept)` pour l'ordonnée à l'origine,
  - ou le nom de la variable sur lequel porte l'effet mixe dans le cas d'une pente aléatoire, (`Z_length` dans notre exemple)
- `Variance` la variance estimée de l'effet (`Std.Dev.` est l'écart type de cette valeur)
- `Corr` indique la corrélation entre la pente aléatoire et l'ordonnée à l'origine aléatoire pour un groupement donné (voir [cette discussion ![:faic](stack-exchange)](https://stats.stackexchange.com/questions/320978/understanding-and-coding-random-intercept-correlation-lmer))

---
# Étape 4 - interprétation et visualisation

    # Fixed effects:
    #              Estimate Std. Error t value
    # (Intercept) -0.000906   0.568493  -0.002
    # Z_Length     0.422270   0.092170   4.581

Cette partie présente l'estimation des effets fixes. Une valeur de la statistique T [(test de Student)](https://en.wikipedia.org/wiki/T-statistic) est retournée **sans p-value** (c'est un choix des auteurs du package, voir pourquoi dans [cette discussion](https://stats.stackexchange.com/questions/185360/t-value-associated-with-nlme-lme4)).

Cette statistique peut être utilisée telle quelle. Vous pouvez aussi calculer
l’intervalle de confiance (IC) à 95% avec cette table en utilisant

$$ IC = Estimate \pm 1.96*Std.Error $$
Si 0 est dans cet interval, alors le paramètre n’est pas significativement
différente de zéro au seuil `\(\alpha\)` = 0.05.

---
# Étape 4 - interprétation et visualisation

##### Quelques fonctions utiles

- `coef(M8)` et `ranef(M8)` retournent les effets aléatoires du modèle M8

- `coef(summary(M8))` retourne les effets fixes

- `sigma(M8)` retourne l’écart type des résidus

- `fitted(M8)` retourne les valeurs prédites par le modèle

- `residuals(M8)` retourne les résidus

---
# Défi 6 ![:cube]()

1. Quelle est la pente et son intervalle de confiance de la variable Z_Length dans le modèle M8?

2. Est-ce que la pente de Z_Length est significativement différente de 0 ?


---
# Solution ![:cube]()

1. Quelle est la pente et son intervalle de confiance de la variable Z_Length dans le modèle M8?

  - pente = 0.422;

  - limite supérieure de l’IC = 0.4223 + 0.09*1.96 = 0.5987

  - limite inférieure de l’IC = 0.4223 - 0.09*1.96 = 0.2459

2. Est-ce que la pente de Z_Length est significativement différente de 0 ?

  - Oui, car l'IC [0.2459, 0.5987] n'inclut pas 0


---
# Défi 7 ![:cube]()

Il est possible de visualiser graphiquement les différentes intercepts et pentes du modèle pour mieux interpréter les résultats

Prenez 2 minutes pour réfléchir aux différentes façons pour représenter les résultats de M8.

*Indice: considérez les différents "niveaux" du modèle*


---
# Solution ![:cube]()

a) Figure avec toutes les données regroupées

b) Figure par espèce

c) Figure par lac

---
# Solution ![:cube]()

Pour faire ces figures, il nous faut:

- Les coefficients du modèle complet qui sont dans le résumé du modèle


```r
summ_M8$coefficients
#                  Estimate Std. Error      t value
# (Intercept) -0.0009058974 0.56877327 -0.001592722
# Z_Length     0.4222697238 0.09221166  4.579352788
```

- Intercept = `\(-9.0589745\times 10^{-4}\)`
- Pente = `\(0.4222697\)`


---
# Solution ![:cube]()

Pour faire ces figures, il nous faut:

- Les coefficients pour chaque niveau du modèle qu'on obtient avec la fonction `coef`


```r
coef(M8)
# $Lake
#     (Intercept)  Z_Length
# L1 -0.085984071 0.4222697
# L2  0.002205209 0.4222697
# L3 -0.301816557 0.4222697
# L4 -0.574039728 0.4222697
# L5  0.218650140 0.4222697
# L6  0.735549622 0.4222697
# 
# $Fish_Species
#    (Intercept)  Z_Length
# S1  -1.0752985 0.2410746
# S2   0.5597871 0.5168300
# S3   0.5127938 0.5089046
# 
# attr(,"class")
# [1] "coef.mer"
```

---
# Solution ![:cube]()

a) Figure avec toutes les données regroupées

```r
library(ggplot2)

# Thème ggplot simplifié
fig &lt;- theme_bw() +
        theme(panel.grid.minor=element_blank(), 
              panel.grid.major=element_blank(),
              panel.background=element_blank()) +
        theme(strip.background=element_blank(), 
              strip.text.y = element_text()) +
        theme(legend.background=element_blank()) +
        theme(legend.key=element_blank()) +
        theme(panel.border = element_rect(colour = "black", fill=NA))

plot &lt;- ggplot(aes(Z_Length, Z_TP), data = fish.data)
Plot_AllData &lt;- plot + geom_point() +
                  xlab("Longueur (mm)") + 
                  ylab("Position trophique") +
                  labs(title = "Toutes les données") + fig

Plot_AllData + geom_abline(intercept = summ_M8$coefficients[1,1], 
                           slope     = summ_M8$coefficients[2,1])
```

---
# Solution ![:cube]()

a) Figure avec toutes les données regroupées
&lt;img src="workshop07-pres-fr_files/figure-html/unnamed-chunk-37-1.png" width="432" style="display: block; margin: auto;" /&gt;

---
# Solution ![:cube]()

b) Figure par espèce


```r
# mettre les coefs dans un tableau pour les rendre plus faciles à manipuler
Lake.coef              &lt;- coef(M8)$Lake
colnames(Lake.coef)    &lt;- c("Intercept", "Slope")
Species.coef           &lt;- coef(M8)$Fish_Species
colnames(Species.coef) &lt;- c("Intercept", "Slope")

Plot_BySpecies &lt;- plot + 
                    geom_point(aes(colour = factor(Fish_Species)), size = 4) +
                    xlab("Longueur (mm)") + ylab("Position trophique") +
                    labs(title = "Par espèce") + fig

# Ajoutez les lignes de régression pour chaque espèce
Plot_BySpecies +
  geom_abline(intercept = Species.coef[1,1], 
              slope     = Species.coef[1,2], col = "coral2") +
  geom_abline(intercept = Species.coef[2,1], 
              slope     = Species.coef[2,2], col = "green4") +
  geom_abline(intercept = Species.coef[3,1], 
              slope     = Species.coef[3,2], col = "blue1")

```

---
# Solution ![:cube]()

b) Figure par espèce

&lt;img src="workshop07-pres-fr_files/figure-html/unnamed-chunk-39-1.png" width="576" style="display: block; margin: auto;" /&gt;

---
# Solution ![:cube]()

c) Figure par lac

```r

Plot_ByLake &lt;- plot + 
                geom_point(aes(colour = factor(Lake)), size = 4) +
                xlab("Length (mm)") + ylab("Trophic Position") +
                labs(title = "By Lake") + fig

# Ajouter les lignes de régression avec les intercepts spécifiques à chaque lac
Plot_ByLake +
  geom_abline(intercept = Lake.coef[1,1], 
              slope     = Lake.coef[1,2], col = "coral2") +
  geom_abline(intercept = Lake.coef[2,1], 
              slope     = Lake.coef[2,2], col = "khaki4") +
  geom_abline(intercept = Lake.coef[3,1], 
              slope     = Lake.coef[3,2], col = "green4") +
  geom_abline(intercept = Lake.coef[4,1], 
              slope     = Lake.coef[4,2], col = "darkgoldenrod") +
  geom_abline(intercept = Lake.coef[5,1], 
              slope     = Lake.coef[5,2], col = "royalblue1") +
  geom_abline(intercept = Lake.coef[6,1], 
              slope     = Lake.coef[6,2], col = "magenta3")

```

---
# Solution ![:cube]()

c) Figure par lac
&lt;img src="workshop07-pres-fr_files/figure-html/unnamed-chunk-41-1.png" width="576" style="display: block; margin: auto;" /&gt;


---
# Modèle mixtes et données en écologie

Les modèles mixtes sont très utiles pour prendre en compte la structure complexe des données en écologie tout en permettant de ne pas perdre beaucoup de degrés de liberté

.center[
![](images/fig_1_qcbs_wiki.png)
]


---
# Défi 8 ![:cube]()

**Situation:**

* Vous avez inventorié la richesse **dans 1000 quadrats** qui sont dans **10 sites différents** qui sont également dans **10 forêts différentes**.

* Vous avez de plus **mesuré la productivité** dans chaque **quadrat**.

* Vous désirez savoir si la productivité est un bon prédicteur de biodiversité

.alert[Quel modèle mixte pourriez-vous utiliser pour ce jeu de données?]

---
# Solution! ![:cube]()


```r
lmer(Biodiv ~ Productivite + (1 | Foret / Site))
```

Ici les effets aléatoires sont imbriqués (i.e. Sites dans forêt) et non croisés.

Pourquoi utiliser `(1 | Foret / Site)` plutôt que `(1 | Foret) + (1 | Site)` ? Regardez [cette réponse sur ![:faic](stack-exchange)](https://stats.stackexchange.com/questions/228800/crossed-vs-nested-random-effects-how-do-they-differ-and-how-are-they-specified)!


---
exclude: true

# Défi 9 ![:cube]()

**Situation:**

* Vous avez récolté **200 poissons** dans **12 sites différents** distribués également dans **4 habitats** différents qui se retrouvent dans **un même lac**.

* Vous avez mesuré la **longueur de chaque poisson** et la **quantité de mercure dans ses tissus**.

* Vous désirez savoir si l'habitat est un bon prédicteur de la concentration en mercure.

.alert[Quel modèle mixte pourriez-vous utiliser pour ce jeu de données?]

---
exclude: true

# Solution!![:cube]()


```r
lmer(Mercure ~ Longueur * Habitat + (1 | Site))
```

---
exclude: true

# Défi 10![:cube]()

* Discutez du jeu de données sur lequel vous travaillez avec votre voisin et déterminez si un modèle mixte serait approprié.

* Si oui, travaillez ensemble pour écrire le code que vous utiliseriez pour faire ce modèle dans R.

* Si non, imaginez un jeu de données fictif pour lequel un modèle mixte serait approprié et codez ce modèle.

---
# Modèles Linéaires Généralisés Mixtes (GLMMs)

Extension des GLMs tenant compte de structures supplémentaires dans les données

Suivre les étapes similaires à celles introduites lors de l'atelier sur les LMMs:

1. LMMs incorporent les effets aléatoires
2. GLMs peuvent gérer des données non-normales (en laissant les erreurs prendre différentes familles de distribution - e.g Poisson ou binomial négatif)

---
# Comment modéliser un GLM sous R

Chargez les données `Arabidopsis` `banta_totalfruits.csv` dans R.



```r
dat.tf &lt;- read.csv("banta_totalfruits.csv")
```
```r
# popu facteur avec un niveau pour chaque population
# gen facteur avec un niveau pour chaque génotype
# nutrient facteur avec niveau bas (valeur = 1) ou haut (valeur = 8)
# amd facteur précisant l'absence ou la présence d'herbivorie
# total.fruits nombre entier indiquant le nombre de fruits par plante
```

L'effet de la disponibilité de nutriments et d'herbivorie (**effets fixes**) sur la production de fruits d'*Arabidopsis thaliana* (arabette des dames) a été évalué en mesurant 625 plantes à travers neuf populations différentes, constituées chacune de 2 à 3 génotypes (**effets aléatoires**)


---
# Choisir la distribution des erreurs

La variable réponse constitue des données d'abondance, donc nous devons choisir une **distribution de Poisson** (i.e variance égale à la moyenne)

&lt;img src="workshop07-pres-fr_files/figure-html/unnamed-chunk-45-1.png" width="432" style="display: block; margin: auto;" /&gt;
Cependant, comme nous le verrons, la variance de chaque groupe augmente beaucoup plus rapidement que prévu...

---
# Exploration de la variance

Pour illustrer l'hétérogénéité de la variance, nous allons d'abord créer des boîtes à moustaches (boxplots) de la variable réponse par rapport aux différents facteurs environnementaux

Créons de nouvelles variables qui représentent toutes les combinaisons de **nutriments** x **herbivorie** x **facteur aléatoire**


```r
dat.tf &lt;- within(dat.tf,
{
  # génotype x nutriment x herbivorie
  gna &lt;- interaction(gen,nutrient,amd)
  gna &lt;- reorder(gna, total.fruits, mean)
  # population x nutriment x herbivorie
  pna &lt;- interaction(popu,nutrient,amd)
  pna &lt;- reorder(pna, total.fruits, mean)
})
```

---
# Exploration de la variance

.small[

```r
# Boxplot du total des fruits vs interaction génotype x nutriment x herbivorie
library(ggplot2)
ggplot(data = dat.tf, aes(factor(x = gna),y = log(total.fruits + 1))) +
  geom_boxplot(colour = "skyblue2", outlier.shape = 21,
  outlier.colour = "skyblue2") +
  theme_bw() + theme(axis.text.x=element_blank()) +
  stat_summary(fun.y=mean, geom="point", colour = "red")
```

&lt;img src="workshop07-pres-fr_files/figure-html/unnamed-chunk-47-1.png" width="576" style="display: block; margin: auto;" /&gt;
]

.comment[De même, la boîte à moustaches total des fruits vs population x nutriments x herbivorie montre une grande quantité d'hétérogénéité entre les populations.]


---
# Choisir la distribution des erreurs

Comme nous venons de le voir, il existe une importante hétérogénéité parmi la variance de chaque groupe, même lorsque la variable réponse est transformée

Si nous représentons graphiquement les **écarts vs moyennes par groupes** (génotypes x nutriment x herbivorie), on voit que la distribution de Poisson est la moins appropriée (i.e. écart augmentent beaucoup plus vite que la moyenne)

.small[.pull-left[
![](images/errDist.png)
]
.pull-right[

&lt;font color="blue"&gt;NB = negative binomial&lt;/font&gt;

&lt;br&gt;

&lt;font color="red"&gt;QP = quasi-Poisson&lt;/font&gt;

&lt;br&gt;
&lt;font color="LightBlue"&gt;loess = Locally weighted regression smoothing&lt;/font&gt;
]]


---
# GLMM Poisson

Compte tenu de la relation moyenne-variance, nous avons besoin d'un modèle avec surdispersion.

- Mais commençons avec un modèle de Poisson :

Pour lancer un GLMM dans R, nous faisons appel à la fonction `glmer()`, du paquet lme4


```r
library(lme4)
mp1 &lt;- glmer(total.fruits ~ nutrient*amd + rack + status +
             (1|popu)+
             (1|gen),
             data = dat.tf, family = "poisson")
```

**Effets aléatoires** : `(1|popu)` contient un intercept aléatoire partagé par les mesures qui ont la même valeur pour `popu`

---
# Vérification de la surdispersion

Nous pouvons vérifier la surdispersion en utilisant la fonction `overdisp_fun()` (Bolker *et al*. 2011) qui divise la déviance des résidus (résidus de Pearson) par les degrés de liberté des résidus et teste si le rapport est plus grand que 1


```r
# Téléchargez le code glmm_funs.R de la page wiki et sourcez le pour exécuter la fonction dans R
source(file="data/glmm_funs.R")
# Surdispersion?
overdisp_fun(mp1)
#       chisq       ratio           p        logp 
# 15755.86833    25.57771     0.00000 -6578.47027
```

- Ratio est significativement `\(&gt;&gt;\)` 1
- Comme on s'y attendait, nous devons modéliser une distribution différente où la variance augmente plus rapidement que la moyenne

---
# GLMM binomiale negative .small[(Poisson-gamma)]

La distribution binomiale négative satisfait la supposition que la **variance est proportionnelle au carré de la moyenne**


```r
mnb1 &lt;- glmer.nb(total.fruits ~ nutrient*amd + rack + status +
                 (1|popu)+
                 (1|gen),
                 data=dat.tf, control=glmerControl(optimizer="bobyqa"))
# Control spécifie la façon dont nous optimisons les valeurs des paramètres
```

.pull-left[
```r
# Surdispersion?
overdisp_fun(mnb1)
```
]
.pull-right[
![:faic](arrow-left).small[.alert[Le rapport est maintenant beaucoup plus près de 1 mais la valeur de p &lt; 0.05]]
]

---
# GLMM Poisson-lognormal

- Un autre option est la distribution **Poisson-lognormal**.
- Cela peut être réalisé simplement en plaçant un effet aléatoire de niveau d'observation dans la formule.
.small[

```r
mpl1 &lt;- glmer(total.fruits ~ nutrient*amd + rack + status +
              (1|X) +
              (1|popu)+
              (1|gen),
data=dat.tf, family="poisson",
control = glmerControl(optimizer = "bobyqa"))
```

`(1|X)` traite de la surdispersion en ajoutant des **effets aléatoires au niveau de l'observation**


```r
overdisp_fun(mpl1)
#         chisq         ratio             p          logp 
#  1.775362e+02  2.886767e-01  1.000000e+00 -3.755507e-73
```

.alert[Rapport maintenant conforme avec notre critère]
]

---
# GLMM Poisson-lognormal

**Représentation graphique des paramètres du modèle**: Une représentation graphique des paramètres du modèle peut être obtenue en utilisant la fonction `coefplot2()`du paquet `coefplot2`:

--

.alert[![:faic](warning) Ce paquet n'est pas sur le CRAN! On utilise le package remotes pour l'installer depuis GitHub]


```r
if (!require("coefplot2"))
  remotes::install_github("palday/coefplot2", subdir = "pkg")
library(coefplot2)
```

---
# GLMM Poisson-lognormal


.pull-left[

```r
# Paramètres de la variance
coefplot2(mpl1, ptype = "vcov", intercept = TRUE)
```

&lt;img src="workshop07-pres-fr_files/figure-html/unnamed-chunk-53-1.png" width="432" style="display: block; margin: auto;" /&gt;
]
.pull-right[

```r
# Effets fixes
coefplot2(mpl1, intercept = TRUE)
```

&lt;img src="workshop07-pres-fr_files/figure-html/unnamed-chunk-54-1.png" width="432" style="display: block; margin: auto;" /&gt;
]

.alert[Note]: barres d'erreur visibles seulement pour les effets fixes parce que glmer ne nous donne pas d'informations sur l'incertitude des effets aléatoires.

---
# Visualisation des effets aléatoires

Vous pouvez aussi extraire les effets aléatoires en utilisant la fonction `ranef()` et les tracer en utilisant un `dotplot()` du paquet `lattice`

Il y a une variabilité régionale parmi les populations :

- Les populations espagnoles (SP) ont des valeurs plus élevées que les populations suédoises (SW) et néerlandaises (NL)

La différence entre les génotypes semble largement induite par génotype 34

```r
library(gridExtra)
library(lattice)
# dotplot code
pp &lt;- list(layout.widths=list(left.padding=0, right.padding=0),
           layout.heights=list(top.padding=0, bottom.padding=0))
r2 &lt;- ranef(mpl1, condVar = TRUE)
d2 &lt;- dotplot(r2, par.settings = pp)
grid.arrange(d2$gen, d2$popu, nrow = 1)
```

---
# Visualisation des effets aléatoires

&lt;br&gt;

&lt;img src="workshop07-pres-fr_files/figure-html/unnamed-chunk-55-1.png" width="648" style="display: block; margin: auto;" /&gt;


---
# Sélection du modèle

Les même méthodes peuvent être utilisées avec un glmm ou lmm pour choisir entre des modèles avec différents intercepts aléatoires et/ou des pentes aléatoires et pour choisir les effets fixes à conserver dans le modèle final.

- une **approche de la théorie de l'information** (e.g., AICc - Atelier 5)
- une **approche fréquentiste** (où l'importance de chaque terme est évaluée en utilisant `anova()` et le test de rapport de vraisemblance; LRT)


---
# Sélection du modèle

Nous dérivons d'abord les modèles potentiels et les comparons en utilisant AICc.comment[*]:


```r
mpl2 &lt;- update(mpl1, . ~ . - rack) # modèle sans rack
mpl3 &lt;- update(mpl1, . ~ . - status) # modèle sans status
mpl4 &lt;- update(mpl1, . ~ . - amd:nutrient) # modèle sans interaction amd:nutrient
bbmle::ICtab(mpl1, mpl2, mpl3, mpl4, type = c("AICc"))
#      dAICc df
# mpl1  0.0  10
# mpl4  1.4  9 
# mpl3  1.5  8 
# mpl2 55.0  9
```

.comment[*NB: Nous ne couvrons pas tous les modèles possibles ci-dessus, cependant, l'interaction `amd:nutriments` ne peut être évaluée que si amd et nutriments sont présents dans le modèle.
]


---
# Sélection du modèle

Nous pouvons aussi utiliser les fonctions `drop1()` et `dfun()` pour évaluer nos effets fixes (`dfun()` convertit les valeurs AIC retournées par `drop1()` en valeurs `\(\Delta\)`AIC)

.small[

```r
dd_LRT &lt;- drop1(mpl1,test="Chisq")
(dd_AIC &lt;- dfun(drop1(mpl1)))
# Single term deletions
# 
# Model:
# total.fruits ~ nutrient * amd + rack + status + (1 | X) + (1 | 
#     popu) + (1 | gen)
#              npar   dAIC
# &lt;none&gt;             0.000
# rack            1 55.083
# status          2  1.612
# nutrient:amd    1  1.444
```
]

---
# Sélection du modèle
.small[

```r
dd_LRT &lt;- drop1(mpl1,test="Chisq")
(dd_AIC &lt;- dfun(drop1(mpl1)))
# Single term deletions
# 
# Model:
# total.fruits ~ nutrient * amd + rack + status + (1 | X) + (1 | 
#     popu) + (1 | gen)
#              npar   dAIC
# &lt;none&gt;             0.000
# rack            1 55.083
# status          2  1.612
# nutrient:amd    1  1.444
```
]

- Fort effet de **rack** (dAIC = 55.08 si on enlève cette variable)
- Effets de **status** et de l'**interaction** sont faibles (dAIC &lt; 2)
- Commençons par **enlever l'interaction non significative** afin de tester les effets principaux de nutriments et d'herbivorie

---
# Sélection du modèle

&lt;br&gt;

.pull-left2[

```r
mpl2 &lt;- update(mpl1, . ~ . - and:nutrient)
# Utiliser AIC
mpl3 &lt;- update(mpl2, . ~ . - rack) # pas de rack ou interaction
mpl4 &lt;- update(mpl2, . ~ . - status) # pas de status ou interaction
mpl5 &lt;- update(mpl2, . ~ . - nutrient) # pas de nutrient ou interaction
mpl6 &lt;- update(mpl2, . ~ . - amd) # pas d'herbivorie ou interaction
# bbmle::ICtab(mpl2, mpl3, mpl4, mpl5, mpl6,
#              type = c("AICc"))

# Ou utiliser drop1
dd_LRT2 &lt;- drop1(mpl2,test="Chisq")
dd_AIC2 &lt;- dfun(drop1(mpl2))
```
]
.pull-right2[

```r
library(bbmle)
ICtab(mpl2, mpl3 ,mpl4,
      mpl5, mpl6,
      type = c("AICc"))
#      dAICc df
# mpl2  0.0  10
# mpl5  0.0  10
# mpl4  1.5  8 
# mpl6 10.6  9 
# mpl3 55.0  9
```
]


---
# Sélection du modèle
&lt;br&gt;

- Fort effets de **nutriments** et d'**herbivorie** (grand changement d'AIC de `\(135.6\)` (`mpl5`) et `\(10.2\)` (`mpl6`) si l'un ou l'autre sont supprimés, respectivement).
- Notre modèle final inclut l'effet fixe de nutriments, d'herbivorie, la variable nuisance de rack, l'effet aléatoire au niveau de l'observation `(1|X)` et la variation de fruits par populations et génotypes.


---
# Prêt pour un défi? ![:cube]()

En utilisant l'ensemble de données `inverts` (temps de développement larvaire (`PLD`) de 74 espèces d'invertébrés et vertébrés marins élevés à différentes températures et temps), répondez aux questions suivantes:

- Quel est l'effet du type d'alimentation et du climat (**effets fixes**) sur `PLD`?
- Est-ce que cette relation varie selon les taxons (**effets aléatoires**)?
- Quelle est la **meilleure famille de distributions** pour ces données?
- Finalement, une fois que vous avez déterminé la meilleure famille de distribution, re-évaluez vos effets fixes et aléatoires.


---
# Solution


```r
# inverts &lt;- read.csv('data/inverts.csv', header = TRUE)
# head(inverts)
# table(inverts$temp, inverts$feeding.type)
#
# mod.glm &lt;- glm(PLD ~ temp + feeding.type, family = poisson(), data = inverts)
# summary(mod.glm)
# drop1(mod.glm, test = "Chisq")
#
# boxplot(PLD ~ temp,  data = inverts)
# boxplot(PLD ~ feeding.type ,  data = inverts)
#
# boxplot(predict(mod.glm, type = "response")~inverts$temp)
#
# plot()
#
# modglm &lt;- glm(PLD ~ temp + feeding.type, family = poisson(), data = inverts)


#
# r2 &lt;- ranef(mpl1, condVar = TRUE)
# d2 &lt;- dotplot(r2, par.settings = pp)
#
#
# plot(aggregate(PLD ~ taxon, FUN=mean, data = inverts)[,2],aggregate(PLD ~ taxon, FUN=var, data = inverts)[,2], pch = 19)
# abline(a=0, b = 1, lty =2)
#
# mod.glmer &lt;- glmer.nb(PLD ~ temp + feeding.type + (1|taxon), data = inverts)
# mod.glm &lt;- glm.nb(PLD ~ temp + feeding.type, family = poisson(), data = inverts)

```

plot(aggregate(PLD ~ taxon, FUN=var, data = inverts)[,2],aggregate(PLD ~ taxon, FUN=mean, data = inverts)[,2])
abline(a=0, b =1, lty =2 )



---
# Ressources additionnelles

* Différences entre `nlme` et `lme4`

.center[
![:scale 25%](images/book1.jpg) ![:scale 28%](images/book2.jpg)
]

* [Harrison et al. (2018), PeerJ, DOI 10.7717/peerj.4794
](http://dx.doi.org/10.7717/peerj.4794)


---
class: inverse, center, bottom

# Merci de votre participation à cet atelier!

![:scale 50%](images/qcbs_logo.png)


&lt;!-- https://stats.stackexchange.com/questions/64226/lme-and-lmer-comparison --&gt;
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="qcbsR-macros.js"></script>
<script>var slideshow = remark.create({
"highlightLines": true,
"highlightStyle": "github"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
