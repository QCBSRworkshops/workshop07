[["index.html", "Workshop 7: Linear and generalized linear mixed models (LMM and GLMM) QCBS R Workshop Series Preface 0.1 Code of conduct 0.2 Contributors 0.3 Contributing", " Workshop 7: Linear and generalized linear mixed models (LMM and GLMM) QCBS R Workshop Series Developed and maintained by the contributors of the QCBS R Workshop Series1 2021-03-17 14:09:46 Preface The QCBS R Workshop Series is a series of 10 workshops that walks participants through the steps required to use R for a wide array of statistical analyses relevant to research in biology and ecology. These open-access workshops were created by members of the QCBS both for members of the QCBS and the larger community. The content of this workshop has been peer-reviewed by several QCBS members. If you would like to suggest modifications, please contact the current series coordinators, listed on the main Github page. 0.1 Code of conduct The QCBS R Workshop Series and the QCBS R Symposium are venues dedicated to providing a welcoming and supportive environment for all people, regardless of background or identity. Participants, presenters and organizers of the workshop series and other related activities accept this Code of Conduct when being present at any workshop-related activities. We do not tolerate behaviour that is disrespectful or that excludes, intimidates, or causes discomfort to others. We do not tolerate discrimination or harassment based on characteristics that include, but are not limited to, gender identity and expression, sexual orientation, disability, physical appearance, body size, citizenship, nationality, ethnic or social origin, pregnancy, familial status, genetic information, religion or belief (or lack thereof), membership of a national minority, property, age, education, socio-economic status, technical choices, and experience level. It applies to all spaces managed by or affiliated with the workshop, including, but not limited to, workshops, email lists, and online forums such as GitHub, Slack and Twitter. 0.1.1 Expected behaviour All participants are expected to show respect and courtesy to others. All interactions should be professional regardless of platform: either online or in-person. In order to foster a positive and professional learning environment we encourage the following kinds of behaviours in all workshop events and platforms: Use welcoming and inclusive language Be respectful of different viewpoints and experiences Gracefully accept constructive criticism Focus on what is best for the community Show courtesy and respect towards other community members 0.1.2 Unacceptable behaviour Examples of unacceptable behaviour by participants at any workshop event/platform include: written or verbal comments which have the effect of excluding people on the - basis of membership of any specific group; causing someone to fear for their safety, such as through stalking or intimidation; violent threats or language directed against another person; the display of sexual or violent images; unwelcome sexual attention; nonconsensual or unwelcome physical contact; insults or put-downs; sexist, racist, homophobic, transphobic, ableist, or exclusionary jokes; incitement to violence, suicide, or self-harm; continuing to initiate interaction (including photography or recording) with - someone after being asked to stop; publication of private communication without consent. 0.2 Contributors Originally developed by: Contributed with changes to the presentation: Contributed with changes to the written material: Contributed by reporting issues and suggesting modifications: 0.3 Contributing Under construction. The QCBS R Workshop Series is part of the Québec Centre for Biodiversity Science, and is maintained by the series coordinators and graduent student, postdoctoral, and research professional members. The contributors for this workshop can be accessed here.↩︎ "],["learning-objectives.html", "Chapter 1 Learning objectives", " Chapter 1 Learning objectives Mixed effects models allow ecologists to overcome a number of limitations associated with traditional linear models. In this workshop, you will learn when it is important to use a mixed effects model to analyze your data. Specifically, we will: 1. Describe what are (generalized) mixed effects models 2. Identify situations in which the use of mixed effects is appropriate 3. Implement basic linear mixed models (LMM) with R 4. Execute basic generalized linear mixed models (GLMM) with R 5. Validate, interpret and visualize mixed models with R "],["preparing-for-the-workshop.html", "Chapter 2 Preparing for the workshop", " Chapter 2 Preparing for the workshop To prepare for this workshop, you must download and install the earliest RStudio and R versions. You must also download the data we will use during this workshop: R Script Fish data Arabidopsis data Inverts data glmm_funs (code for use in the GLMM section) This workshop requires the following R packages: ggplot2 lm4 AICcmodavg MASS vcdExtra bbmle DescTools To install them from CRAN, run: install.packages(&quot;ggplot2&quot;) install.packages(&quot;lme4&quot;) install.packages(&quot;AICcmodavg&quot;) install.packages(&quot;MASS&quot;) install.packages(&quot;vcdExtra&quot;) install.packages(&quot;bbmle&quot;) install.packages(&quot;DescTools&quot;) install.packages(&quot;MuMIn&quot;) To load these packages, run: library(ggplot2) library(lme4) library(AICcmodavg) library(MASS) library(vcdExtra) library(bbmle) library(DescTools) library(MuMIn) "],["why-choose-mixed-models.html", "Chapter 3 Why choose mixed models?", " Chapter 3 Why choose mixed models? Biological and ecological data are often messy. Most of the time there is an inherent structure to data (i.e. single observations are not always independent), relationships between variables of interest might differ depending on grouping factors like species, and more often than not sample sizes are low, making it difficult to fit models that require many parameters to be estimated. Linear mixed effects models (LMM) were developed to deal with these issues. They can be applied to a great number of ecological questions and take many different forms. In this workshop we will use a simple question-based approach to learn the basics of how LMM operate and how to fit them. "],["starting-with-a-question.html", "Chapter 4 Starting with a question 4.1 Challenge 1", " Chapter 4 Starting with a question Before we dive in, let’s start by considering an example dataset and proposing a research question. The dataset we will be using looks at fish trophic positions. In this dataset, data was collected for 3 different fish species (S1-3) with 10 individuals sampled per species across 6 different lakes (L1-6). Individuals from each species were measured and exhibit variation in their body length and trophic position. Here is a visual representation to help wrap your head around all of this! Note: Only three sizes of fish are shown within each species but in reality there are 10 individuals per species. A simple question you could answer with this dataset is does fish trophic position increase with fish size? This will be our motivating question for this workshop. 4.1 Challenge 1 For our first challenge, we are going to start looking deeper at our dataset. Reproduce plots 1-3 using the script below and the fish dataset. Observe each plot and try to get a sense of what is occurring. A few key questions to ask yourself are: 1. Do we expect an increase in trophic position with length in the exact same way for all species? 2. Do we expect an increase in trophic position with length in the exact same way for all lakes? 3. How might these relationships differ? library(ggplot2) # Load dataset into R fish.data &lt;- read.csv(&quot;data/qcbs_w7_data.csv&quot;, stringsAsFactors = TRUE) # simple theme fig &lt;- theme_bw() + theme(panel.grid.minor = element_blank(), panel.grid.major = element_blank(), panel.background = element_blank()) + theme(strip.background = element_blank(), strip.text.y = element_text()) + theme(legend.background = element_blank()) + theme(legend.key = element_blank()) + theme(panel.border = element_rect(colour = &quot;black&quot;, fill = NA)) plot &lt;- ggplot(aes(Fish_Length, Trophic_Pos), data = fish.data) # Plot 1 - All data plot + geom_point() + xlab(&quot;Length (mm)&quot;) + ylab(&quot;Trophic Position&quot;) + labs(title = &quot;All Data&quot;) + fig # Plot 2 - By species plot + geom_point() + facet_wrap(~Fish_Species) + xlab(&quot;Length (mm)&quot;) + ylab(&quot;Trophic Position&quot;) + labs(title = &quot;By Species&quot;) + fig # Plot 3 – By lake plot + geom_point() + facet_wrap(~Lake) + xlab(&quot;Length (mm)&quot;) + ylab(&quot;Trophic Position&quot;) + labs(title = &quot;By Lake&quot;) + fig Challenge 1 Solution: Based on these plots we can draw two initial observations: 1. All species appear to increase in trophic position with length, but the slope might be different across species. 2 Some parameters specific to each particular lake (ex. the primary productivity of the system) may change the observed relationship. "],["analyzing-the-data.html", "Chapter 5 Analyzing the data 5.1 Separate 5.2 Lump 5.3 Is there a third option?", " Chapter 5 Analyzing the data We know that ecological and biological data are often complex. Many datasets will include: Hierarchical structure in the data Many covariates and grouping factors Unbalanced study/experimental design So how can we analyze our data? Option 1: Separate - Run separate analyses for each species in each lake Option 2: Lump - Run one analysis ignoring lake and species Option 3: ? Let’s look a little closer at these options using our fish dataset! 5.1 Separate One way to analyze this data is to fit linear regressions for each species in each lake. What would it look like it we ran separate analyses for each species? Notice you would have to estimate a slope and intercept parameter for each regression (2 parameters x 3 species X 6 lakes = 36 parameter estimates) and the sample size for each analysis would be 10. There is a decreased chance of finding an effect due to low sample size and increased familywise error rate due to multiple comparisons. 5.2 Lump Another way to analyze this data is to fit a single linear regression ignoring species and lake. What would it look like it we put all of our data together for all lakes? Notice you now have a huge sample size and far fewer parameters to estimate! But what about pseudoreplication? Fish within a lake and within a species might be correlated. Also, look at all that noise in the data, some of it might be due to differences among species and lakes 5.3 Is there a third option? For our question, we only want to know if there is a general effect of body length on the trophic position. However, this relationship might differ slightly among species due to unmeasured biological processes (e.g. growth rate) or among lakes due to unmeasured environmental variables. But we are not interested in this variation, so we need to find a way to control for these potential effects while still maximizing the use of our data. This is why both separating and lumping alone are unsatisfactory options. This brings us to mixed models! Linear mixed models enable us to lump and separate the analysis. Linear mixed models: Estimate slope and intercept parameters for each species and lake (separating) but estimate fewer parameters than classical regression. Use all the data available (lumping) while accounting for pseudoreplication by controlling for differences among lakes and species. In doing so, they: allow you to use all the data you have instead of using means of non-independent sample; account for structure in your data (for example, quadrates nested in sites nested in forests); allow relationships to vary by different grouping factors (also known as random effects); they require less parameter estimates than classical regression which saves you degrees of freedom. But how do they do all of this? Let’s get into it! "],["fixed-vs-random-effects.html", "Chapter 6 Fixed vs. random effects 6.1 Fixed effects: deterministic processes 6.2 Random effects: stochastic processes", " Chapter 6 Fixed vs. random effects We frequently encounter the terms ‘fixed’ and ‘random’ effects in the LMM literature. There are also many possible definitions, and we chose to present those we think are easier to apply when doing your analyses. 6.1 Fixed effects: deterministic processes Data comes from: all possible levels of a factor (qualitative variable) a predictor (quantitative variable) We wish to make conclusions about the levels of the factor or about the relationship between the response variable and the predictor. Example: If you are comparing mercury concentration in fish from three different habitats. Habitat has a fixed effect as we sampled in each 3 habitats and we are interested in making conclusions about these specific habitats. 6.2 Random effects: stochastic processes Variables with a random effect are also called random factors, as they are only qualitative variables (categorical, not continous). A random effect is observed when the data only includes a random sample of the factor’s many possible levels, which are all of interest. They usually are grouping factors for which you want to control the effect in your model, but are not interested in their specific effect on the response variable. Therefore they enable us to structure the error process. Example: If you are studying mercury contamination in fish in Ugandan crater lakes. For logistical reasons, you can’t sample all the crater lakes, so you sample only 8 of them. However, fish from a given lake might have some sort of correlation between themselves (auto-correlation) since they experience the same environmental conditions. Even though you’re not interested in the effect of each lake specifically, you should account for this potential correlation with a random factor (crater lake) in order to make conclusions about crater lakes in general. "],["how-do-lmms-work.html", "Chapter 7 How do LMMs work? 7.1 Parameters are varied 7.2 Data structure is taken into account 7.3 Challenge 2", " Chapter 7 How do LMMs work? 7.1 Parameters are varied In linear mixed models, intercepts and/or slopes are allowed to vary according to a given factor (random effect; e.g. by lake and/or species). Allowing intercepts and/or slopes to vary by random effects means that you assume they come from a normal distribution. A mean and standard deviation of that distribution are estimated based on your data. The most likely intercepts and slopes from that distribution are then fit by optimization (ex. maximum likelihood or restricted maximum likelihood). Intercepts: If we consider species as a random effect first, we can estimate a mean and standard deviation for the combined distribution of species intercepts rather than separate intercepts for each species. The mean of this distribution is the ‘species level model’. In this example, we only have three species. In general, the more levels you have for a given factor, the more accurately the parameters of the distribution can be estimated (three may be a little low for estimating a mean and standard deviation but it makes simpler graphs!). Note that when you implement LMM’s in R, the intercept in the summary is the species level intercept (i.e. the mean of all random intercepts). Likewise, if we consider lake as a random effect then only mean and standard deviation of the combined lake intercept are estimated. This saves you the need to estimate 6 different lake intercept parameters, ultimately saving degrees of freedom as less parameter estimates are needed given the amount of data. Slopes: The same concept is used for allowing slope to vary by a given factor (random effect). This is a little harder to visualize than the intercepts. In the case of species, the mean and standard deviation of slope parameters are estimated instead of three separate slopes. Note that when you implement LMM’s in R, the slope in the summary is the species level slope. 7.2 Data structure is taken into account In linear mixed models, intercepts, slopes and their confidence intervals are adjusted to take the data structure into account. What happens if the sample size for a specific factor level is small? (e.g. low \\(n\\) for a specific species) If a certain species or lake is poorly represented in the data, the model will give more weight to the pooled model to estimate the intercept and/or slope of that species or lake (i.e. shrinkage). Ideally, you should have a minimum of \\(n\\) =3 for any specific factor level. How do we assess the impact of a random effect on the model? The confidence intervals for the general intercepts and slopes are adjusted to account for pseudoreplication based on the intraclass correlation coefficient (ICC) The ICC is calculated as the ratio of variance between the random effect and the total variance. Thus, the ICC describes the proportion of variance in the response variable that is attributed to a specific random effect: \\[ICC = \\frac{\\sigma_{\\alpha}^2}{\\sigma_{\\alpha}^2 + \\sigma_{\\varepsilon}^2}\\] Note: The specific mathematical notation may vary according to the article/book and according to how the model equation was written. In our fish example, the ICC informs us of the extent to which the average trophic position (i.e. intercepts) varies among species or lakes. High ICC The % of variance (ICC) is high because species differ strongly in their average trophic position. The confidence intervals for the general intercept and slope are high. Low ICC The % of variance (ICC) is low because species differ poorly in their average trophic position. The confidence intervals for the general intercept and slope are small. 7.3 Challenge 2 For your second challenge, think about these two questions. How will the ICC and confidence intervals be affected in these two scenarios: 1. Fish trophic positions are not variable among lakes? 2. Fish trophic positions are similar within lakes but variable among lakes? Challenge 1 Solution: 1. Low ICC, smaller confidence intervals 2. High ICC, larger confidence intervals "],["mixed-model-protocol.html", "Chapter 8 Mixed model protocol Step 1. A priori model building Step 2. Code potential models and model selection", " Chapter 8 Mixed model protocol Step 1. A priori model building and data exploration Step 2. Code potential models and model selection Step 3. Model validation Step 4. Model interpretation and visualization Step 1. A priori model building What we know a priori: We want to determine if the trophic position can be predicted by body length, while taking into account the variation between species and lakes. So we want a model that looks like this: \\[PT_{ijk} \\sim Length_i + Lake_j + Species_k + \\epsilon_{ijk}\\] Check data structure Does the data have the right structure? Look at the data structure: # Look at data structure str(fish.data) ## &#39;data.frame&#39;: 180 obs. of 4 variables: ## $ Lake : chr &quot;L1&quot; &quot;L1&quot; &quot;L1&quot; &quot;L1&quot; ... ## $ Fish_Species: chr &quot;S1&quot; &quot;S1&quot; &quot;S1&quot; &quot;S1&quot; ... ## $ Fish_Length : num 105 195 294 414 237 ... ## $ Trophic_Pos : num 2.6 2.7 2.74 2.74 2.79 ... Now look at the distribution of samples for each factor: # Look at the distribution of samples for each factor table(fish.data[, c(&quot;Lake&quot;, &quot;Fish_Species&quot;)]) ## Fish_Species ## Lake S1 S2 S3 ## L1 10 10 10 ## L2 10 10 10 ## L3 10 10 10 ## L4 10 10 10 ## L5 10 10 10 ## L6 10 10 10 This dataset is perfectly balanced, but mixed models can be used to analyze unbalanced experimental plans, as it is often the case in ecology! Let’s also look at the distribution of continuous variables: # Look at the distribution of continuous variables: par(mfrow = c(1, 2), mar = c(4, 4, 1, 1)) hist(fish.data$Fish_Length, xlab = &quot;Length (mm)&quot;, main = &quot;&quot;) hist(fish.data$Trophic_Pos, xlab = &quot;Trophic position&quot;, main = &quot;&quot;) Major deviations could cause heteroscedasticity problems. If necessary, make transformations. In this case, the data seems OK. Check collinearity Check for collinearity between your explanatory variables The problem with collinear predictors is simply that they explain the same thing, so their effect on the response variable will be confounded in the model. In this example, there is no risk of collinearity with only one continuous variable. If you had another continuous variable (var2), one simple way to check for collinearity is cor(var1, var2) Here an example of collinearity. Challenge 3 This is a thinking problem! Given our data, What additional measures could we have taken in the field that could have been strongly correlated with body length? Challenge 3 Solution: There are multiple potential answers here. One example is fish body mass - this variable is strongly correlated with fish length. Therefore, we do not want to include these two variables in the same model. Consider scale Consider the scale of your data If two variables in the same model have very different scales, the mixed model will likely return a convergence error when trying to compute the parameters. The Z-correction standardizes the variables and solve this problem (use function scale() in R): \\[z = \\frac{x-mean(x)}{standard.deviation(x)}\\] Consider the scale of the variables within our dataset: Body length -&gt; Long scale Trophic position -&gt; Short scale Because our data have very different scales of variation, we apply the Z-correction # Standardized length, &#39;by hand&#39; fish.data$Z_Length &lt;- (fish.data$Fish_Length - mean(fish.data$Fish_Length))/sd(fish.data$Fish_Length) # Standardized trophic position, with the function scale fish.data$Z_TP &lt;- scale(fish.data$Trophic_Pos) Do you need a LMM? Determine if you need a mixed model To find out if a mixed model is needed for your data, you need to determine whether it is important to consider the random effects that might influence the relationship you are interested in (in our case, lake and species). We can do this by: Creating a linear model without random effect Calculating the residuals of this linear model Plot the residuals against the levels of the potential random factors Create a linear model without random effects lm.test &lt;- lm(Z_TP ~ Z_Length, data = fish.data) Calculate residuals of this linear model lm.test.resid &lt;- rstandard(lm.test) Plot the residuals against the levels of the potential random factors par(mfrow = c(1, 2)) plot(lm.test.resid ~ as.factor(fish.data$Fish_Species), xlab = &quot;Species&quot;, ylab = &quot;Standardized residuals&quot;) abline(0, 0, lty = 2) plot(lm.test.resid ~ as.factor(fish.data$Lake), xlab = &quot;Lake&quot;, ylab = &quot;Standardized residuals&quot;) abline(0, 0, lty = 2) These results suggest that there is residual variance that could be explained by these factors, so they should be included in a mixed effect model! Step 2. Code potential models and model selection 8.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.1 LINLEY STOPPED HERE 2021-03-17 Translate this model… \\[PT_{ijk} \\sim Length_i + Lake_j + Species_k + \\epsilon_{ijk}\\] … in R code lmer(Z_TP ~ Z_Length + (1 | Lake) + (1 | Fish_Species), data = fish.data, REML = TRUE) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: Z_TP ~ Z_Length + (1 | Lake) + (1 | Fish_Species) ## Data: fish.data ## REML criterion at convergence: 72.4662 ## Random effects: ## Groups Name Std.Dev. ## Lake (Intercept) 0.4516 ## Fish_Species (Intercept) 0.9301 ## Residual 0.2605 ## Number of obs: 180, groups: Lake, 6; Fish_Species, 3 ## Fixed Effects: ## (Intercept) Z_Length ## 9.752e-14 4.198e-01 – lmer “linear mixed model” function from lme4 package (1 | Lake) indicate varying intercepts among lakes REML = TRUE estimation method "],["note-on-estimation-methods.html", "Chapter 9 Note on estimation methods", " Chapter 9 Note on estimation methods Remember that you should use : REML to compare models with nested random effects and the same fixed effect structure ML to compare models with nested fixed effects and the same random effect structure ML to compare models with and without random effects "],["step-2-code-potential-models.html", "Chapter 10 Step 2. Code potential models", " Chapter 10 Step 2. Code potential models Different structures for the model : (1 | Lake) random effect by lake at the intrecept (1 + Z_Length | Lake) random effect by lake at the intercept and slope in response to the body length (NB: (Z_Length | Lake) gives the same random structure) (-1 + Z_Length | Lake) to have only the random effect at the slope (1 | Lake) + (1 | Species) for crossed random effects (1 | Lake:Fish_Species) for the interaction between 2 random effects If your dataset includes nested random effects, you could use / to specify them, e.g. (1 | factor1 / factor2) if factor2 is nested in factor1 (see ) "],["solution-cube.html", "Chapter 11 Solution ", " Chapter 11 Solution lmer(Z_TP ~ Z_Length + (1 + Z_Length | Lake) + (1 + Z_Length | Fish_Species), data = fish.data, REML = TRUE) ## boundary (singular) fit: see ?isSingular ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: ## Z_TP ~ Z_Length + (1 + Z_Length | Lake) + (1 + Z_Length | Fish_Species) ## Data: fish.data ## REML criterion at convergence: 20.5786 ## Random effects: ## Groups Name Std.Dev. Corr ## Lake (Intercept) 0.45279 ## Z_Length 0.02378 -0.82 ## Fish_Species (Intercept) 0.93103 ## Z_Length 0.15728 1.00 ## Residual 0.22341 ## Number of obs: 180, groups: Lake, 6; Fish_Species, 3 ## Fixed Effects: ## (Intercept) Z_Length ## -0.0009025 0.4223738 ## optimizer (nloptwrap) convergence code: 0 (OK) ; 0 optimizer warnings; 1 lme4 warnings "],["challenge-5-cube.html", "Chapter 12 Challenge 5 ", " Chapter 12 Challenge 5 Make a list of 7 alternative models that could be compared to this one: lmer(Z_TP ~ Z_Length + (1 | Lake) + (1 | Fish_Species), data = fish.data, REML = TRUE) .comment[Note: If we had different fixed effects between the models or a model without random effects, we would have to specify REML = FALSE to compare with likelihood methods like AIC.] "],["solution-cube-1.html", "Chapter 13 Solution ", " Chapter 13 Solution # Linear model with no random effects M0 &lt;- lm(Z_TP ~ Z_Length, data = fish.data) # Full model with varying intercepts M1 &lt;- lmer(Z_TP ~ Z_Length + (1 | Fish_Species) + (1 | Lake), data = fish.data, REML = FALSE) # Full model with varying intercepts and slopes M2 &lt;- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Fish_Species) + (1 + Z_Length | Lake), data = fish.data, REML = FALSE) ## boundary (singular) fit: see ?isSingular # No Lake, varying intercepts only M3 &lt;- lmer(Z_TP ~ Z_Length + (1 | Fish_Species), data = fish.data, REML = FALSE) # No Species, varying intercepts only M4 &lt;- lmer(Z_TP ~ Z_Length + (1 | Lake), data = fish.data, REML = FALSE) # No Lake, varying intercepts and slopes M5 &lt;- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Fish_Species), data = fish.data, REML = FALSE) ## boundary (singular) fit: see ?isSingular # No Species, varying intercepts and slopes M6 &lt;- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Lake), data = fish.data, REML = FALSE) ## boundary (singular) fit: see ?isSingular # Full model with varying intercepts and slopes only varying # by lake M7 &lt;- lmer(Z_TP ~ Z_Length + (1 | Fish_Species) + (1 + Z_Length | Lake), data = fish.data, REML = FALSE) ## boundary (singular) fit: see ?isSingular # Full model with varying intercepts and slopes only varying # by species M8 &lt;- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Fish_Species) + (1 | Lake), data = fish.data, REML = FALSE) ## boundary (singular) fit: see ?isSingular "],["step-2-model-selection.html", "Chapter 14 Step 2. Model selection", " Chapter 14 Step 2. Model selection Now that we have a list of potential models, we want to compare them to each other to select the one(s) with the highest predictive power given the data. Models can be compared by using the AICc function from theMuMIn package. The Akaike Information Criterion (AIC) is a measure of model quality that can be used to compare models. AICc corrects for bias created by small sample sizes. "],["step-2-model-selection-1.html", "Chapter 15 Step 2. Model selection", " Chapter 15 Step 2. Model selection To group all AICc values into a single table, use: AIC.table &lt;- MuMIn::model.sel(M0, M1, M2, M3, M4, M5, M6, M7, M8) (AIC.table &lt;- AIC.table[, c(&quot;df&quot;, &quot;logLik&quot;, &quot;AICc&quot;, &quot;delta&quot;)]) ## df logLik AICc delta ## M8 7 -8.597929 31.84702 0.000000 ## M2 9 -8.216019 35.49086 3.643839 ## M1 5 -33.480080 77.30499 45.457965 ## M7 7 -33.186374 81.02391 49.176890 ## M5 6 -128.310995 269.10754 237.260517 ## M3 4 -134.532965 277.29450 245.447480 ## M4 4 -224.715763 457.66010 425.813076 ## M6 6 -224.671201 461.82795 429.980930 ## M0 3 -236.861362 479.85909 448.012065 df is the degree of freedom logLik is the loglikelihood delta is the AICc difference with the lowest value We only displayed part of the results returned by the function model.sel(), see ?model.sel for more information. "],["step-2-model-selection-2.html", "Chapter 16 Step 2. Model selection", " Chapter 16 Step 2. Model selection M8 &lt;- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Fish_Species) + (1 | Lake), data = fish.data, REML = TRUE) ## boundary (singular) fit: see ?isSingular M2 &lt;- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Fish_Species) + (1 + Z_Length | Lake), data = fish.data, REML = TRUE) ## boundary (singular) fit: see ?isSingular MuMIn::model.sel(M2, M8)[, c(&quot;df&quot;, &quot;logLik&quot;, &quot;AICc&quot;, &quot;delta&quot;)] ## df logLik AICc delta ## M8 7 -10.84011 36.33137 0.000000 ## M2 9 -10.28932 39.63747 3.306098 Model M8 seems to be the best among all models that we tested. Note that we use now REML (i.e. REML = TRUE) as we are comparing two models with nested random effects and the same fixed effect structure. "],["step-2-model-selection-3.html", "Chapter 17 Step 2. Model selection", " Chapter 17 Step 2. Model selection Once the best model is selected, the estimation method must be reset to REML = TRUE. M8 &lt;- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Fish_Species) + (1 | Lake), data = fish.data, REML = TRUE) ## boundary (singular) fit: see ?isSingular exclude: true "],["solution.html", "Chapter 18 Solution", " Chapter 18 Solution Group discussion… – exclude: true .alert[M2] The trophic position is a function of length and both the intercept and the effect of length on trophic position can vary by fish species and lake. .small[the intrinsic factors of species and lakes cause the relationship between trophic position and length to differ (i.e. both slopes and intercepts) (i.e. slopes and intercepts)] .alert[M8] The trophic position is a function of length and both the intercept and the effect of length on trophic position can vary by fish species but only the intercept can vary by lake (not the slope of trophic position on length). .small[intrinsic factors of species alone cause this relationship to differ (i.e. slopes) and that on average trophic positions might be higher or lower in one lake versus another (i.e. intercepts).] Intro Implementing -etc "],["generalized-linear-mixed-models-glmms.html", "Chapter 19 Generalized linear mixed models (GLMMs)", " Chapter 19 Generalized linear mixed models (GLMMs) As seen above, heterogeneous response distributions can be accurately modelled by relaxing the assumptions of normally distributed errors and letting the errors take on different distribution families (e.g., Poisson or negative binomial). What happens if there is a structure in the dataset such that observations sampled in certain sites are more similar (correlated) than observations sampled in different sites? As we saw in Workshop 6, we can account for this lack of independence by adding random effects in the model. Recall that intercepts and/or slopes are allowed to vary among grouping factors (random effects) and the variability in slopes/ intercepts among groups is assumed to follow a normal distribution. Random effects are also referred to as shrinkage estimates because they represent a weighted average of the group-level and the overall fit (fixed effect). The amount of shrinking towards the overall fit is more severe if the within-group variability is large compared to the among-group variability (i.e., when we have less confidence in the random estimate due to low sample size or high within-group variability, the estimate is ‘pulled’ towards the fixed effect). The properties of Linear Mixed Models (Workshop 5) which incorporate random effects and those of Generalized Linear Models (seen above) which handle non-normal data can be combined to effectively model such instances in a Generalized Linear Mixed Model framework. The extension of GLMs to account for this additional structure follows similar steps introduced in the mixed modelling workshop. To provide a brief overview of GLMMs, we will visit a case study presented by Bolker et al. (2009) and later by Bolker et al. (2011) where the structure (or lack of independence) in the dataset was due to observations being measured across different populations. The authors evaluated the extent to which the response of Arabidopsis thaliana (mouse-ear cress) to its environmental drivers (nutrient availability and herbivory) varied as a result of the population and/or genotype they belonged to. Using the Arabidopsis dataset and detailed analysis presented by Bolker and colleagues, we will explore the eff ects of nutrient levels, herbivory and their interaction ( fixed effects) on the production Arabidopsis thaliana and the across-population and/or across-genotype variability in these relationships (random eff ects). # First load and view the dataset dat.tf &lt;- read.csv(&quot;Banta_TotalFruits.csv&quot;) str(dat.tf) # X observation number reg factor for one of three regions; # Netherlands, Spain or Sweden popu factor with a level for # each population (random effect) gen factor with a level for # each genotype (random effect) rack nuisance factor for one # of two greenhouse racks nutrient factor with levels for low # (value = 1) or high (value = 8) nutrients (fixed effect) # amd factor with levels for no damage or simulated herbivory # (apical meristem damage) (fixed effect) status nuisance # factor for germination method total.fruits the response # variable; an integer indicating the number of fruits per # plant # 2-3 genotypes nested within each of the 9 populations table(dat.tf$popu, dat.tf$gen) # Housekeeping: make integers into factors, relevel clipping # (amd) and rename nutrient levels dat.tf &lt;- transform(dat.tf, X = factor(X), gen = factor(gen), rack = factor(rack), amd = factor(amd, levels = c(&quot;unclipped&quot;, &quot;clipped&quot;)), nutrient = factor(nutrient, label = c(&quot;Low&quot;, &quot;High&quot;))) # Install/load packages if (!require(lme4)) { install.packages(&quot;lme4&quot;) } require(lme4) if (!require(coefplot2)) { install.packages(&quot;coefplot2&quot;, repos = &quot;http://www.math.mcmaster.ca/bolker/R&quot;, type = &quot;source&quot;) } require(coefplot2) if (!require(reshape)) { install.packages(&quot;reshape&quot;) } require(reshape) if (!require(ggplot2)) { install.packages(&quot;ggplot2&quot;) } require(ggplot2) if (!require(plyr)) { install.packages(&quot;plyr&quot;) } require(plyr) if (!require(gridExtra)) { install.packages(&quot;gridExtra&quot;) } require(gridExtra) if (!require(emdbook)) { install.packages(&quot;emdbook&quot;) } require(emdbook) source(&quot;glmm_funs.R&quot;) "],["structure-in-dataset.html", "Chapter 20 Structure in dataset 20.1 Poisson GLMM 20.2 Negative binomial (Poisson-gamma) GLMM 20.3 Poisson-lognormal GLMM", " Chapter 20 Structure in dataset When we look at the interaction between nutrient and clipping across the 9 different populations, we note that there is a consistent nutrient e ffect (higher baseline under the High nutrient treatment). The effect of clipping is weaker, but in some populations we note a negative slope. ggplot(dat.tf,aes(x=amd,y=log(total.fruits+1),colour=nutrient)) + geom_point() + stat_summary(aes(x= as.numeric(amd)),fun.y=mean,geom=&quot;line&quot;) + theme_bw() + theme(panel.margin=unit(0,&quot;lines&quot;)) + scale_color_manual(values=c(&quot;#3B9AB2&quot;,&quot;#F21A00&quot;)) + # from Wes Anderson Zissou palette facet_wrap(~popu) A similar plot can be made for the 24 different genotypes (changing facet_wrap(~gen)). ==== Choosing an error distribution ==== The response variable is count data which suggests that a Poisson distribution should be used. Recall that an important property of the Poisson distribution is that the variance is equal to the mean. However, as we will see below, the group variances increase with the mean much more rapidly than expected under the Poisson distribution. # Create new variables that represents every combination # nutrient x clipping x random factor dat.tf &lt;- within(dat.tf, { # genotype x nutrient x clipping gna &lt;- interaction(gen, nutrient, amd) gna &lt;- reorder(gna, total.fruits, mean) # population x nutrient x clipping pna &lt;- interaction(popu, nutrient, amd) pna &lt;- reorder(pna, total.fruits, mean) }) # Boxplot of total fruits vs new variable (genotype x # nutrient x clipping) ggplot(data = dat.tf, aes(factor(x = gna), y = log(total.fruits + 1))) + geom_boxplot(colour = &quot;skyblue2&quot;, outlier.shape = 21, outlier.colour = &quot;skyblue2&quot;) + theme_bw() + theme(axis.text.x = element_text(angle = 90)) + stat_summary(fun.y = mean, geom = &quot;point&quot;, colour = &quot;red&quot;) # Boxplot of total fruits vs new variable (population x # nutrient x clipping) ggplot(data = dat.tf, aes(factor(x = pna), y = log(total.fruits + 1))) + geom_boxplot(colour = &quot;skyblue2&quot;, outlier.shape = 21, outlier.colour = &quot;skyblue2&quot;) + theme_bw() + theme(axis.text.x = element_text(angle = 90)) + stat_summary(fun.y = mean, geom = &quot;point&quot;, colour = &quot;red&quot;) As illustrated above, there is a large amount of heterogeneity among the group variances even when the response variable is transformed. We also note that some groups have a mean and variance of zero. To determine which distribution family to use, we can run a diagnostic plot of the group variances vs their respective means. We provide an example below for the genotype x nutrient x clipping grouping. If we observe a linear relationship between the variance and the mean with a slope = 1, then the Poisson family is appropriate, If we observe a linear mean-variance relationship with a slope &gt; 1 (i.e. Var = φµ where φ &gt; 1), then the quasi-Poisson family (as introduced above) should be applied, Finally, a quadratic relationship between the variance and the mean (i.e. Var = µ(1 + α ) or µ(1 + µ/k)), is characteristic of overdispersed data that is driven by an underlying heterogeneity among samples. In this case, the negative binomial (Poisson-gamma) would be more appropriate. From the plot above we note that a linear quasi-Poisson may be better than the negative binomial, but additional modelling is needed. 20.1 Poisson GLMM Let’s build a GLMM using the glmer function of the lme4 package. This model has a random intercept for all genotype and population treatments. We include the nuisance variables (rack and germination method) as fixed effects. Given the mean-variance relationship from above, we most likely will need a model with overdispersion, but let’s start with a Poisson model. mp1 &lt;- glmer(total.fruits ~ nutrient * amd + rack + status + (1 | popu) + (1 | gen), data = dat.tf, family = &quot;poisson&quot;) We can check for overdispersion using a function overdisp_fun provided by Bolker et al. (2011) which divides the Pearson residuals by the residual degrees of freedom and tests whether these values differ significantly (i.e., whether the ratio of residual deviance to residual df is significantly different from 1). A low p-value indicates that the data are over dispersed (i.e., ratio is significantly different from 1). # Overdispersion? overdisp_fun(mp1) # Or as above, we can approximate this by dividing the # residual deviance by the residual df summary(mp1) # residual deviance = 18253.7 and resid df = 616 The ratio is significantly greater than unity, so as expected, we need to try a different distribution where the variance increases more rapidly than the mean, such as the negative binomial. 20.2 Negative binomial (Poisson-gamma) GLMM Recall that the negative binomial (or Poisson-gamma) distribution meets the assumption that the variance is proportional to the square of the mean. # Note: This model converges well if you are running R # version 3.0.2, but may not converge with later versions. If # you are having convergence issues, please try with version # 3.0.2. mnb1 &lt;- glmer.nb(total.fruits ~ nutrient * amd + rack + status + (1 | popu) + (1 | gen), data = dat.tf, control = glmerControl(optimizer = &quot;bobyqa&quot;)) # Although beyond the scope of this workshop, the new # &#39;control&#39; argument specifies the way we optimize the # parameter values (i.e. by taking the derivative of a # function or proceeding by iteration). When taking the # derivative is not possible, an iterative algorithm such as # bobyqa (Bound Optimization BY Quadratic Approximation) is # used. # Overdispersion? overdisp_fun(mnb1) The ratio is now much closer to unity (although the p-value is still less than 0.05). 20.3 Poisson-lognormal GLMM Another option that we have not yet seen is to use a Poisson-lognormal distribution. This approach deals with overdispersion by implementing an observation-level random effects (OLRE; see Harrison (2014)), which model the extra-Poisson variation in the response variable using a random effect with a unique level for every data point. A Poisson-lognormal model effectively places a lognormal prior on εi. A Poisson-lognormal distribution with mean µ and lognormal prior variance σ2 has variance: var(y) = µ + µ2 \\[exp(σ^2^) - 1\\] In contrast, for the negative binomial, we saw that the distribution was given by: var(y) = µ + µ2/k More generally, the variance term σ2 in the Poisson-lognormal distribution will depend on the grouping level we select (e.g., at the individual, genotype or population level). That is, the Poisson-lognormal model can allow for a more flexible approach to assigning the observed aggregation to different sources of heterogeneity. Here, to implement the observation-level random effect, we will evaluate it at the individual level. mpl1 &lt;- glmer(total.fruits ~ nutrient * amd + rack + status + (1 | X) + (1 | popu) + (1 | gen), data = dat.tf, family = &quot;poisson&quot;, control = glmerControl(optimizer = &quot;bobyqa&quot;)) overdisp_fun(mpl1) We did it! The ratio between residual deviance and residual df now meets our criterion (in fact, it is even smaller 1). "],["random-intercepts.html", "Chapter 21 Random intercepts 21.1 Parameter plots 21.2 Random intercept plots 21.3 Random slopes", " Chapter 21 Random intercepts Now that we have the appropriate error distribution, we can test the importance of the random intercepts (for population and genotype) by comparing nested models with and without the random effects of interest using either: an information theoretic approach (such as, Akaike Information Criterion; AIC), which as we saw in Workshop 6 examines several competing hypotheses (models) simultaneously to identify the model with the highest predictive power given the data. As before, we will use the AICc to correct for small sample sizes. Or, a frequentist approach (traditional null hypothesis testing or drop1 approach), where the significance of each term is evaluated in turn (by comparing nested models together using the anova() function and the significance of the likelihood ratio test; LRT). It’s important to keep in mind that with this approach we are testing a null hypothesis of zero variance for the random effects, but given that we cannot have negative variance, we are testing the parameter on the boundary of its feasible region. Therefore, the reported p value is approximately twice what it should be (i.e., we’ve truncated half of the possible values that fall below 0). summary(mpl1)$varcor # popu only mpl1.popu &lt;- glmer(total.fruits ~ nutrient*amd + rack + status + (1|X) + (1|popu), data=dat.tf, family=&quot;poisson&quot;, control=glmerControl(optimizer=&quot;bobyqa&quot;)) # gen only mpl1.gen &lt;-glmer(total.fruits ~ nutrient*amd + rack + status + (1|X) + (1|gen), data=dat.tf, family=&quot;poisson&quot;, control=glmerControl(optimizer=&quot;bobyqa&quot;)) # IC approach using AICc ICtab(mpl1, mpl1.popu, mpl1.gen, type = c(&quot;AICc&quot;)) # dAICc df # mpl1 0.0 10 # mpl1.popu 2.0 9 # mpl1.gen 16.1 9 # Frequentist approach using LRT anova(mpl1,mpl1.popu) # Data: dat.tf # Df AIC BIC logLik deviance Chisq Chi Df Pr(&gt;Chisq) # mpl1.popu 9 5017.4 5057.4 -2499.7 4999.4 # mpl1 10 5015.4 5059.8 -2497.7 4995.4 4.0639 1 0.04381 * # --- # Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 anova(mpl1,mpl1.gen) # Df AIC BIC logLik deviance Chisq Chi Df Pr(&gt;Chisq) # mpl1.gen 9 5031.5 5071.5 -2506.8 5013.5 # mpl1 10 5015.4 5059.8 -2497.7 4995.4 18.177 1 2.014e-05 *** # --- # Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 The model without the random intercept for genotype is within 2 AICc units of the full model, which indicates that they are equally plausible (i.e., little evidence for including a random intercept for genotype). However, when using the Likelihood approach, and keeping in mind the boundary effect (p-values are inflated by a factor of 2), we note that p &lt;&lt; 0.05 in both anova tests. Thus the model with both random terms (mpl1) is selected. 21.1 Parameter plots A graphical representation of the model parameters can be obtained using the coefplot2 function. For example, to view the variance terms of our three random intercepts: # Variance terms coefplot2(mpl1,ptype=&quot;vcov&quot;,intercept=TRUE,main=&quot;Random effect variance&quot;) # Fixed effects coefplot2(mpl1,intercept=TRUE,main=&quot;Fixed effect coefficient&quot;) Note that the error bars are only shown for the fixed effects because glmer doesn’t give us information on the uncertainty of the variance terms. 21.2 Random intercept plots We can also extract the random effect (or group-level) deviations from the fixed intercept using the ranef function. This will tell us how much the intercept is shifted up or down in particular populations or genotypes relative to the fixed intercept. The deviations can then be plotted using dotplot, which will return a two-facetted plot for each random effect (i.e., popu and gen). Note: the grid.arrange function was used to omit the observation-level random effect (i.e. (1|X)). pp &lt;- list(layout.widths=list(left.padding=0, right.padding=0), layout.heights=list(top.padding=0, bottom.padding=0)) r2 &lt;- ranef(mpl1,condVar=TRUE) d2 &lt;- dotplot(r2, par.settings=pp) grid.arrange(d2$gen,d2$popu,nrow=1) From this plot we can see a hint of regional variability among populations where the Spanish populations (SP) have larger values than Swedish (SW) and Dutch (NL) populations. The difference among genotypes seems to be largely driven by genotype 34. As seen in Workshop 5, we could have also used the coef() function to plot the random effect predictions or \"estimates\", where the sum of random intercept deviation (obtained from ranef()) and the fixed effect (obtained from fixef()) is equal to the parameter estimate obtained from coef(). 21.3 Random slopes ++++ Bonus Section: Random slopes| NB: We cannot test for random slopes in this dataset because whenever random slopes for the fixed effects are included in the model, we obtain a strong correlation between the random intercepts and slopes. These perfect correlations may result from our model being over-parametrized. Thus, while there could very well be some variation in the nutrient or clipping e ffect at the genotype or population levels, and while this variation may be what we are most interested in, there is simply not enough data to test these e ffects with confidence. Let’s have a look at an example of this by testing the random slope terms for clipping: # Poisson-lognormal with random slopes for popu and amd mpl2 &lt;- glmer(total.fruits ~ nutrient * amd + rack + status + (1 | X) + (amd | popu) + (amd | gen), data = dat.tf, family = &quot;poisson&quot;, control = glmerControl(optimizer = &quot;bobyqa&quot;)) We can examine the variance components using the model summary. Alternatively, we could examine the correlation matrix among the random clipping intercepts and slopes. A third option is to use the printvc function that prints the variance-covariance matrices along with an equals sign ( = ) next to any covariance component with a nearly perfect correlation. summary(mpl2) # option 1 attr(VarCorr(mpl2)$gen, &quot;correlation&quot;) # option 2 printvc(mpl2) # option 3 Notice the perfect correlation between (Intercept) and amdclipped (slope). ++++ "],["final-model.html", "Chapter 22 Final model", " Chapter 22 Final model We end this section on GLMM with the evaluation of the fixed effects. We first code potential models and compare them using AICc. mpl2 &lt;- update(mpl1, . ~ . - rack) # model without rack mpl3 &lt;- update(mpl1, . ~ . - status) # model without status mpl4 &lt;- update(mpl1, . ~ . - amd:nutrient) # without amd:nutrient interaction ICtab(mpl1,mpl2,mpl3,mpl4, type = c(&quot;AICc&quot;)) # dAICc df # mpl1 0.0 10 # mpl4 1.4 9 # mpl3 1.5 8 # mpl2 55.0 9 Alternatively, we can use the functions drop1 and dfun, where dfun converts the AIC values returned by the drop1 into ΔAIC values (producing a similar table to ICtab above). (dd_LRT &lt;- drop1(mpl1,test=&quot;Chisq&quot;)) # Model: # total.fruits ~ nutrient * amd + rack + status + (1 | X) + (1 | popu) + (1 | gen) # Df AIC LRT Pr(Chi) # &lt;none&gt; 5015.4 # rack 1 5070.5 57.083 4.179e-14 *** # status 2 5017.0 5.612 0.06044 . # nutrient:amd 1 5016.8 3.444 0.06349 . # --- # Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 (dd_AIC &lt;- dfun(drop1(mpl1))) # Df dAIC # &lt;none&gt; 0.000 # rack 1 55.083 # status 2 1.612 # nutrient:amd 1 1.444 There is a strong effect of rack (a change in AIC of 55 if we remove this variable), whereas the effects of status and of the interaction term are weak (change in AIC when either is dropped is less than 2). We can thus start by removing the non-signifi cant interaction term so that we can test the main e ffects of nutrient and clipping. mpl2 &lt;- update(mpl1, . ~ . - and:nutrient) # Use AICc: mpl3 &lt;- update(mpl2, . ~ . - rack) # model without rack or interaction mpl4 &lt;- update(mpl2, . ~ . - status) # model without status or interaction mpl5 &lt;- update(mpl2, . ~ . - nutrient) # without nutrient or interaction mpl6 &lt;- update(mpl2, . ~ . - amd) # without clipping or interaction ICtab(mpl2,mpl3,mpl4,mpl5,mpl6, type = c(&quot;AICc&quot;)) # dAICc df # mpl2 0.0 9 # mpl4 1.2 7 # mpl6 10.2 8 # mpl3 54.2 8 # mpl5 135.6 8 # Or use drop1: (dd_LRT2 &lt;- drop1(mpl2,test=&quot;Chisq&quot;)) # Model: # total.fruits ~ nutrient + amd + rack + status + (1 | X) + (1 | popu) + (1 | gen) # Df AIC LRT Pr(Chi) # &lt;none&gt; 5016.8 # nutrient 1 5152.5 137.688 &lt; 2.2e-16 *** # amd 1 5027.0 12.218 0.0004734 *** # rack 1 5071.0 56.231 6.443e-14 *** # status 2 5018.1 5.286 0.0711639 . # --- # Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 (dd_AIC2 &lt;- dfun(drop1(mpl2))) # Df dAIC # &lt;none&gt; 0.000 # nutrient 1 135.688 # amd 1 10.218 # rack 1 54.231 # status 2 1.286 summary(mpl2) Both the main effects of nutrient and clipping are strong (large change in AIC of 135.6 (mpl5) and 10.2 (mpl6) if either nutrient or clipping are dropped, respectively). Our fi nal model includes the fixed nutrient (strong positive) and clipping (negative) effects, the nuisance variables rack, the observation-level random e ffects (1 | X) to account for over-dispersion and the variation in overall fruit set at the population and genotype levels. ** CHALLENGE 10 ** Using the inverts dataset (larval development times (PLD) of 74 marine invertebrate and vertebrate species reared at different temperatures and time), answer the following questions: What is the effect of feeding type and climate (fixed effects) on PLD? Does this relationship vary among taxa (random effects)? What is the best distribution family for this count data? Finally, once you determined the best distribution family, re-evaluate your random and fixed effects. ++++ Challenge: Solution 1| # Load data inverts &lt;- read.csv(&quot;inverts.csv&quot;) str(inverts) mlm1 &lt;- lm(PLD ~ temp * feeding.type, data = inverts) anova(mlm1) # all variables are significant ++++ ++++ Challenge: Solution 2| # Response vs fixed effects ggplot(inverts,aes(x=temp,y=log(PLD+1),colour=feeding.type)) + geom_point() + stat_summary(aes(x=as.numeric(temp)),fun.y=mean,geom=&quot;line&quot;) + theme_bw() + scale_color_manual(values=c(&quot;#3B9AB2&quot;,&quot;#F21A00&quot;)) + # from Wes Anderson Zissou palette facet_wrap(~taxon) # Create new variables that represents every combination feeding type x temp x taxa (random effect) inverts &lt;- within(inverts, { # taxon x feeding.type tft &lt;- interaction(taxon,feeding.type,temp) tft &lt;- reorder(tft, PLD, mean) }) # Boxplot of total fruits vs new variable (feeding type x temp x taxa) ggplot(data = inverts, aes(factor(x = tft),y = log(PLD))) + geom_boxplot(colour = &quot;skyblue2&quot;, outlier.shape = 21, outlier.colour = &quot;skyblue2&quot;) + theme_bw() + theme(axis.text.x=element_text(angle=90)) + stat_summary(fun.y=mean, geom=&quot;point&quot;, colour = &quot;red&quot;) ++++ ++++ Challenge: Solution 3| grpVars &lt;- tapply(inverts$PLD, inverts$tft, var) summary(grpVars) grpMeans &lt;- tapply(inverts$PLD, inverts$tft, mean) summary(grpMeans) # Quasi-Poisson lm1 &lt;- lm(grpVars ~ grpMeans - 1) phi.fit &lt;- coef(lm1) # The -1 specifies a model with the intercept set to zero # Negative binomial lm2 &lt;- lm(grpVars ~ I(grpMeans^2) + offset(grpMeans) - 1) k.fit &lt;- 1/coef(lm2) # Offset() used to specify that we want group means added as # a term with its coefficient fixed to 1 # Non-parametric loess fit Lfit &lt;- loess(grpVars ~ grpMeans) plot(grpVars ~ grpMeans, xlab = &quot;group means&quot;, ylab = &quot;group variances&quot;) abline(a = 0, b = 1, lty = 2) text(60, 200, &quot;Poisson&quot;) curve(phi.fit * x, col = 2, add = TRUE) # bquote() is used to substitute numeric values in equations # with symbols text(60, 800, bquote(paste(&quot;QP: &quot;, sigma^2 == .(round(phi.fit, 1)) * mu)), col = 2) curve(x * (1 + x/k.fit), col = 4, add = TRUE) text(60, 1600, paste(&quot;NB: k=&quot;, round(k.fit, 1), sep = &quot;&quot;), col = 4) mvec &lt;- 0:120 lines(mvec, predict(Lfit, mvec), col = 5) text(50, 1300, &quot;loess&quot;, col = 5) # Poisson GLMM mp1 &lt;- glmer(PLD ~ temp * feeding.type + (1 | taxon), data = inverts, family = &quot;poisson&quot;) overdisp_fun(mp1) # ratio is significantly &gt;1 # NB GLMM mnb1 &lt;- glmer.nb(PLD ~ temp * feeding.type + (1 | taxon), data = inverts) overdisp_fun(mnb1) # Looks good! ++++ ++++ Challenge: Solution 4| # Re-evaluating random intercepts summary(mnb1)$varcor mnb1.taxless &lt;- glm.nb(PLD ~ temp * feeding.type, data = inverts) # Here, because we are comparing a glmer with a glm, we must # do something different than calling anova() to test # importance of random intercept. We will compare the # likelihood of each model: NL1 &lt;- -logLik(mnb1) NL0 &lt;- -logLik(mnb1.taxless) devdiff &lt;- 2 * (NL0 - NL1) dfdiff &lt;- attr(NL1, &quot;df&quot;) - attr(NL0, &quot;df&quot;) pchisq(devdiff, dfdiff, lower.tail = FALSE) # Could also look at dAIC to compare model with (mnb1) and # without (mnb1.taxless) random effects Using AICtab() # function AICtab(mnb1, mnb1.taxless) # Large change in AIC if drop random intercept. Therefore, # worth keeping this in. # Diagnostic plots locscaleplot(mnb1) # Plotting variance terms coefplot2(mnb1, ptype = &quot;vcov&quot;, intercept = TRUE, main = &quot;Random effect variance&quot;) # Plot of fixed effects coefplot2(mnb1, intercept = TRUE, main = &quot;Fixed effect coefficient&quot;) # Plotting random intercepts pp &lt;- list(layout.widths = list(left.padding = 0, right.padding = 0)) r2 &lt;- ranef(mnb1, condVar = TRUE) d2 &lt;- dotplot(r2, par.settings = pp) grid.arrange(d2$taxon, nrow = 1) # Evaluate random slopes mnb2 &lt;- glmer.nb(PLD ~ temp * feeding.type + (PLD | taxon), data = inverts) # View variance-covariance components summary(mnb2) # option 1 attr(VarCorr(mnb2)$taxon, &quot;correlation&quot;) # option 2 printvc(mnb2) # option 3 # Strong correlation between random effects -&gt; not enough # power to test random slopes # Re-evaluating fixed effects Note: to run the drop1 we need # to speficy the theta parameter and run the NB model with # glmer: theta.mnb1 &lt;- theta.md(inverts$PLD, fitted(mnb1), dfr = df.residual(mnb1)) mnb1 &lt;- glmer(PLD ~ temp * feeding.type + (1 | taxon), data = inverts, family = negative.binomial(theta = theta.mnb1)) (dd_LRT &lt;- drop1(mnb1, test = &quot;Chisq&quot;)) (dd_AIC &lt;- dfun(drop1(mnb1))) # dAIC when feeding.type x temp interaction is dropped is # greater than 2, suggest to keep interaction in model ++++ "],["summary.html", "Chapter 23 Summary", " Chapter 23 Summary -Add- "],["additional-resources.html", "Chapter 24 Additional resources 24.1 LMM Textbooks 24.2 GLMM resources", " Chapter 24 Additional resources 24.1 LMM Textbooks Gelman, A., and Hill, J. (2006). Data analysis using regression and multilevel/hierarchical models (Cambridge University Press). Zuur, A., Ieno, E.N., Walker, N., Saveliev, A.A., and Smith, G.M. (2009). Mixed effects models and extensions in ecology with R (Springer). 24.2 GLMM resources Books B. Bolker (2009) Ecological Models and Data in R. Princeton University Press. A. Zuur et al. (2009) Mixed Effects Models and Extensions in Ecology with R. Springer. **Articles ** Harrison, X. A., L. Donaldson, M. E. Correa-Cano, J. Evans, D. N. Fisher, C. E. D. Goodwin, B. S. Robinson, D. J. Hodgson, and R. Inger. 2018. A brief introduction to mixed effects modelling and multi-model inference in ecology. PeerJ 6:e4794–32. Websites GLMM for ecologists: A great website on GLMM with a Q&amp;A section! "],["references.html", "Chapter 25 References", " Chapter 25 References "]]
