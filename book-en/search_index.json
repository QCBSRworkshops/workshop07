[["index.html", "Workshop 7: Linear and generalized linear mixed models (LMM and GLMM) QCBS R Workshop Series Preface 0.1 Code of conduct 0.2 Contributors 0.3 Contributing", " Workshop 7: Linear and generalized linear mixed models (LMM and GLMM) QCBS R Workshop Series Developed and maintained by the contributors of the QCBS R Workshop Series1 2021-03-18 00:41:13 Preface The QCBS R Workshop Series is a series of 10 workshops that walks participants through the steps required to use R for a wide array of statistical analyses relevant to research in biology and ecology. These open-access workshops were created by members of the QCBS both for members of the QCBS and the larger community. The content of this workshop has been peer-reviewed by several QCBS members. If you would like to suggest modifications, please contact the current series coordinators, listed on the main Github page. 0.1 Code of conduct The QCBS R Workshop Series and the QCBS R Symposium are venues dedicated to providing a welcoming and supportive environment for all people, regardless of background or identity. Participants, presenters and organizers of the workshop series and other related activities accept this Code of Conduct when being present at any workshop-related activities. We do not tolerate behaviour that is disrespectful or that excludes, intimidates, or causes discomfort to others. We do not tolerate discrimination or harassment based on characteristics that include, but are not limited to, gender identity and expression, sexual orientation, disability, physical appearance, body size, citizenship, nationality, ethnic or social origin, pregnancy, familial status, genetic information, religion or belief (or lack thereof), membership of a national minority, property, age, education, socio-economic status, technical choices, and experience level. It applies to all spaces managed by or affiliated with the workshop, including, but not limited to, workshops, email lists, and online forums such as GitHub, Slack and Twitter. 0.1.1 Expected behaviour All participants are expected to show respect and courtesy to others. All interactions should be professional regardless of platform: either online or in-person. In order to foster a positive and professional learning environment we encourage the following kinds of behaviours in all workshop events and platforms: Use welcoming and inclusive language Be respectful of different viewpoints and experiences Gracefully accept constructive criticism Focus on what is best for the community Show courtesy and respect towards other community members 0.1.2 Unacceptable behaviour Examples of unacceptable behaviour by participants at any workshop event/platform include: written or verbal comments which have the effect of excluding people on the - basis of membership of any specific group; causing someone to fear for their safety, such as through stalking or intimidation; violent threats or language directed against another person; the display of sexual or violent images; unwelcome sexual attention; nonconsensual or unwelcome physical contact; insults or put-downs; sexist, racist, homophobic, transphobic, ableist, or exclusionary jokes; incitement to violence, suicide, or self-harm; continuing to initiate interaction (including photography or recording) with - someone after being asked to stop; publication of private communication without consent. 0.2 Contributors Originally developed by: Contributed with changes to the presentation: Contributed with changes to the written material: Contributed by reporting issues and suggesting modifications: 0.3 Contributing Under construction. The QCBS R Workshop Series is part of the Québec Centre for Biodiversity Science, and is maintained by the series coordinators and graduent student, postdoctoral, and research professional members. The contributors for this workshop can be accessed here.↩︎ "],["learning-objectives.html", "Chapter 1 Learning objectives", " Chapter 1 Learning objectives Mixed effects models allow ecologists to overcome a number of limitations associated with traditional linear models. In this workshop, you will learn when it is important to use a mixed effects model to analyze your data. Specifically, we will: 1. Describe what are (generalized) mixed effects models 2. Identify situations in which the use of mixed effects is appropriate 3. Implement basic linear mixed models (LMM) with R 4. Execute basic generalized linear mixed models (GLMM) with R 5. Validate, interpret and visualize mixed models with R "],["preparing-for-the-workshop.html", "Chapter 2 Preparing for the workshop", " Chapter 2 Preparing for the workshop To prepare for this workshop, you must download and install the earliest RStudio and R versions. You must also download the data we will use during this workshop: R Script Fish data Arabidopsis data Inverts data glmm_funs (code for use in the GLMM section) This workshop requires the following R packages: ggplot2 lm4 AICcmodavg MASS vcdExtra bbmle DescTools To install them from CRAN, run: install.packages(&quot;ggplot2&quot;) install.packages(&quot;lme4&quot;) install.packages(&quot;AICcmodavg&quot;) install.packages(&quot;MASS&quot;) install.packages(&quot;vcdExtra&quot;) install.packages(&quot;bbmle&quot;) install.packages(&quot;DescTools&quot;) install.packages(&quot;remotes&quot;) install.packages(&quot;gridExtra&quot;) install.packages(&quot;lattice&quot;) install.packages(&quot;MuMIn&quot;) To load these packages, run: library(ggplot2) library(lme4) library(AICcmodavg) library(MASS) library(vcdExtra) library(bbmle) library(DescTools) library(remotes) library(gridExtra) library(lattice) library(MuMIn) "],["why-choose-mixed-models.html", "Chapter 3 Why choose mixed models?", " Chapter 3 Why choose mixed models? Biological and ecological data are often messy. Most of the time there is an inherent structure to data (i.e. single observations are not always independent), relationships between variables of interest might differ depending on grouping factors like species, and more often than not sample sizes are low, making it difficult to fit models that require many parameters to be estimated. Linear mixed effects models (LMM) were developed to deal with these issues. They can be applied to a great number of ecological questions and take many different forms. In this workshop we will use a simple question-based approach to learn the basics of how LMM operate and how to fit them. "],["starting-with-a-question.html", "Chapter 4 Starting with a question 4.1 Challenge 1", " Chapter 4 Starting with a question Before we dive in, let’s start by considering an example dataset and proposing a research question. The dataset we will be using looks at fish trophic positions. In this dataset, data was collected for 3 different fish species (S1-3) with 10 individuals sampled per species across 6 different lakes (L1-6). Individuals from each species were measured and exhibit variation in their body length and trophic position. Here is a visual representation to help wrap your head around all of this! Note: Only three sizes of fish are shown within each species but in reality there are 10 individuals per species. A simple question you could answer with this dataset is does fish trophic position increase with fish size? This will be our motivating question for this workshop. 4.1 Challenge 1 For our first challenge, we are going to start looking deeper at our dataset. Reproduce plots 1-3 using the script below and the fish dataset. Observe each plot and try to get a sense of what is occurring. A few key questions to ask yourself are: 1. Do we expect an increase in trophic position with length in the exact same way for all species? 2. Do we expect an increase in trophic position with length in the exact same way for all lakes? 3. How might these relationships differ? library(ggplot2) # Load dataset into R fish.data &lt;- read.csv(&quot;data/qcbs_w7_data.csv&quot;, stringsAsFactors = TRUE) # This line will vary depending on where your data is saved # simple theme fig &lt;- theme_bw() + theme(panel.grid.minor = element_blank(), panel.grid.major = element_blank(), panel.background = element_blank()) + theme(strip.background = element_blank(), strip.text.y = element_text()) + theme(legend.background = element_blank()) + theme(legend.key = element_blank()) + theme(panel.border = element_rect(colour = &quot;black&quot;, fill = NA)) plot &lt;- ggplot(aes(Fish_Length, Trophic_Pos), data = fish.data) # Plot 1 - All data plot + geom_point() + xlab(&quot;Length (mm)&quot;) + ylab(&quot;Trophic Position&quot;) + labs(title = &quot;All Data&quot;) + fig # Plot 2 - By species plot + geom_point() + facet_wrap(~Fish_Species) + xlab(&quot;Length (mm)&quot;) + ylab(&quot;Trophic Position&quot;) + labs(title = &quot;By Species&quot;) + fig # Plot 3 – By lake plot + geom_point() + facet_wrap(~Lake) + xlab(&quot;Length (mm)&quot;) + ylab(&quot;Trophic Position&quot;) + labs(title = &quot;By Lake&quot;) + fig Challenge 1 Solution: Based on these plots we can draw two initial observations: 1. All species appear to increase in trophic position with length, but the slope might be different across species. 2 Some parameters specific to each particular lake (ex. the primary productivity of the system) may change the observed relationship. "],["analyzing-the-data.html", "Chapter 5 Analyzing the data 5.1 Separate 5.2 Lump 5.3 Is there a third option?", " Chapter 5 Analyzing the data We know that ecological and biological data are often complex. Many datasets will include: Hierarchical structure in the data Many covariates and grouping factors Unbalanced study/experimental design So how can we analyze our data? Option 1: Separate - Run separate analyses for each species in each lake Option 2: Lump - Run one analysis ignoring lake and species Option 3: ? Let’s look a little closer at these options using our fish dataset! 5.1 Separate One way to analyze this data is to fit linear regressions for each species in each lake. What would it look like it we ran separate analyses for each species? Notice you would have to estimate a slope and intercept parameter for each regression (2 parameters x 3 species X 6 lakes = 36 parameter estimates) and the sample size for each analysis would be 10. There is a decreased chance of finding an effect due to low sample size and increased familywise error rate due to multiple comparisons. 5.2 Lump Another way to analyze this data is to fit a single linear regression ignoring species and lake. What would it look like it we put all of our data together for all lakes? Notice you now have a huge sample size and far fewer parameters to estimate! But what about pseudoreplication? Fish within a lake and within a species might be correlated. Also, look at all that noise in the data, some of it might be due to differences among species and lakes 5.3 Is there a third option? For our question, we only want to know if there is a general effect of body length on the trophic position. However, this relationship might differ slightly among species due to unmeasured biological processes (e.g. growth rate) or among lakes due to unmeasured environmental variables. But we are not interested in this variation, so we need to find a way to control for these potential effects while still maximizing the use of our data. This is why both separating and lumping alone are unsatisfactory options. This brings us to mixed models! Linear mixed models enable us to lump and separate the analysis. Linear mixed models: Estimate slope and intercept parameters for each species and lake (separating) but estimate fewer parameters than classical regression. Use all the data available (lumping) while accounting for pseudoreplication by controlling for differences among lakes and species. In doing so, they: allow you to use all the data you have instead of using means of non-independent sample; account for structure in your data (for example, quadrates nested in sites nested in forests); allow relationships to vary by different grouping factors (also known as random effects); they require less parameter estimates than classical regression which saves you degrees of freedom. But how do they do all of this? Let’s get into it! "],["fixed-vs-random-effects.html", "Chapter 6 Fixed vs. random effects 6.1 Fixed effects: deterministic processes 6.2 Random effects: stochastic processes", " Chapter 6 Fixed vs. random effects We frequently encounter the terms ‘fixed’ and ‘random’ effects in the LMM literature. There are also many possible definitions, and we chose to present those we think are easier to apply when doing your analyses. 6.1 Fixed effects: deterministic processes Data comes from: all possible levels of a factor (qualitative variable) a predictor (quantitative variable) We wish to make conclusions about the levels of the factor or about the relationship between the response variable and the predictor. Example: If you are comparing mercury concentration in fish from three different habitats. Habitat has a fixed effect as we sampled in each 3 habitats and we are interested in making conclusions about these specific habitats. 6.2 Random effects: stochastic processes Variables with a random effect are also called random factors, as they are only qualitative variables (categorical, not continous). A random effect is observed when the data only includes a random sample of the factor’s many possible levels, which are all of interest. They usually are grouping factors for which you want to control the effect in your model, but are not interested in their specific effect on the response variable. Therefore they enable us to structure the error process. Example: If you are studying mercury contamination in fish in Ugandan crater lakes. For logistical reasons, you can’t sample all the crater lakes, so you sample only 8 of them. However, fish from a given lake might have some sort of correlation between themselves (auto-correlation) since they experience the same environmental conditions. Even though you’re not interested in the effect of each lake specifically, you should account for this potential correlation with a random factor (crater lake) in order to make conclusions about crater lakes in general. "],["how-do-lmms-work.html", "Chapter 7 How do LMMs work? 7.1 Parameters are varied 7.2 Data structure is taken into account 7.3 Challenge 2", " Chapter 7 How do LMMs work? 7.1 Parameters are varied In linear mixed models, intercepts and/or slopes are allowed to vary according to a given factor (random effect; e.g. by lake and/or species). Allowing intercepts and/or slopes to vary by random effects means that you assume they come from a normal distribution. A mean and standard deviation of that distribution are estimated based on your data. The most likely intercepts and slopes from that distribution are then fit by optimization (ex. maximum likelihood or restricted maximum likelihood). Intercepts: If we consider species as a random effect first, we can estimate a mean and standard deviation for the combined distribution of species intercepts rather than separate intercepts for each species. The mean of this distribution is the ‘species level model’. In this example, we only have three species. In general, the more levels you have for a given factor, the more accurately the parameters of the distribution can be estimated (three may be a little low for estimating a mean and standard deviation but it makes simpler graphs!). Note that when you implement LMM’s in R, the intercept in the summary is the species level intercept (i.e. the mean of all random intercepts). Likewise, if we consider lake as a random effect then only mean and standard deviation of the combined lake intercept are estimated. This saves you the need to estimate 6 different lake intercept parameters, ultimately saving degrees of freedom as less parameter estimates are needed given the amount of data. Slopes: The same concept is used for allowing slope to vary by a given factor (random effect). This is a little harder to visualize than the intercepts. In the case of species, the mean and standard deviation of slope parameters are estimated instead of three separate slopes. Note that when you implement LMM’s in R, the slope in the summary is the species level slope. 7.2 Data structure is taken into account In linear mixed models, intercepts, slopes and their confidence intervals are adjusted to take the data structure into account. What happens if the sample size for a specific factor level is small? (e.g. low \\(n\\) for a specific species) If a certain species or lake is poorly represented in the data, the model will give more weight to the pooled model to estimate the intercept and/or slope of that species or lake (i.e. shrinkage). Ideally, you should have a minimum of \\(n\\) =3 for any specific factor level. How do we assess the impact of a random effect on the model? The confidence intervals for the general intercepts and slopes are adjusted to account for pseudoreplication based on the intraclass correlation coefficient (ICC) The ICC is calculated as the ratio of variance between the random effect and the total variance. Thus, the ICC describes the proportion of variance in the response variable that is attributed to a specific random effect: \\[ICC = \\frac{\\sigma_{\\alpha}^2}{\\sigma_{\\alpha}^2 + \\sigma_{\\varepsilon}^2}\\] Note: The specific mathematical notation may vary according to the article/book and according to how the model equation was written. In our fish example, the ICC informs us of the extent to which the average trophic position (i.e. intercepts) varies among species or lakes. High ICC The % of variance (ICC) is high because species differ strongly in their average trophic position. The confidence intervals for the general intercept and slope are high. Low ICC The % of variance (ICC) is low because species differ poorly in their average trophic position. The confidence intervals for the general intercept and slope are small. 7.3 Challenge 2 For your second challenge, think about these two questions. How will the ICC and confidence intervals be affected in these two scenarios: 1. Fish trophic positions are not variable among lakes? 2. Fish trophic positions are similar within lakes but variable among lakes? Challenge 2 Solution: 1. Low ICC, smaller confidence intervals 2. High ICC, larger confidence intervals "],["mixed-model-protocol.html", "Chapter 8 Mixed model protocol", " Chapter 8 Mixed model protocol Step 1. A priori model building and data exploration Step 2. Code potential models and model selection Step 3. Model validation Step 4. Model interpretation and visualization "],["step-1-a-priori-model-building.html", "Chapter 9 Step 1. A priori model building 9.1 Check data structure 9.2 Check collinearity 9.3 Challenge 3 9.4 Consider scale 9.5 Do you need a LMM?", " Chapter 9 Step 1. A priori model building What we know a priori: We want to determine if the trophic position can be predicted by body length, while taking into account the variation between species and lakes. So we want a model that looks like this: \\[PT_{ijk} \\sim Length_i + Lake_j + Species_k + \\epsilon_{ijk}\\] 9.1 Check data structure Does the data have the right structure? Look at the data structure: # Look at data structure str(fish.data) ## &#39;data.frame&#39;: 180 obs. of 4 variables: ## $ Lake : chr &quot;L1&quot; &quot;L1&quot; &quot;L1&quot; &quot;L1&quot; ... ## $ Fish_Species: chr &quot;S1&quot; &quot;S1&quot; &quot;S1&quot; &quot;S1&quot; ... ## $ Fish_Length : num 105 195 294 414 237 ... ## $ Trophic_Pos : num 2.6 2.7 2.74 2.74 2.79 ... Now look at the distribution of samples for each factor: # Look at the distribution of samples for each factor table(fish.data[, c(&quot;Lake&quot;, &quot;Fish_Species&quot;)]) ## Fish_Species ## Lake S1 S2 S3 ## L1 10 10 10 ## L2 10 10 10 ## L3 10 10 10 ## L4 10 10 10 ## L5 10 10 10 ## L6 10 10 10 This dataset is perfectly balanced, but mixed models can be used to analyze unbalanced experimental plans, as it is often the case in ecology! Let’s also look at the distribution of continuous variables: # Look at the distribution of continuous variables: par(mfrow = c(1, 2), mar = c(4, 4, 1, 1)) hist(fish.data$Fish_Length, xlab = &quot;Length (mm)&quot;, main = &quot;&quot;) hist(fish.data$Trophic_Pos, xlab = &quot;Trophic position&quot;, main = &quot;&quot;) Major deviations could cause heteroscedasticity problems. If necessary, make transformations. In this case, the data seems OK. 9.2 Check collinearity Check for collinearity between your explanatory variables The problem with collinear predictors is simply that they explain the same thing, so their effect on the response variable will be confounded in the model. In this example, there is no risk of collinearity with only one continuous variable. If you had another continuous variable (var2), one simple way to check for collinearity is cor(var1, var2) Here an example of collinearity. 9.3 Challenge 3 This is a thinking problem! Given our data, What additional measures could we have taken in the field that could have been strongly correlated with body length? Challenge 3 Solution: There are multiple potential answers here. One example is fish body mass - this variable is strongly correlated with fish length. Therefore, we do not want to include these two variables in the same model. 9.4 Consider scale Consider the scale of your data If two variables in the same model have very different scales, the mixed model will likely return a convergence error when trying to compute the parameters. The Z-correction standardizes the variables and solve this problem (use function scale() in R): \\[z = \\frac{x-mean(x)}{standard.deviation(x)}\\] Consider the scale of the variables within our dataset: Body length -&gt; Long scale Trophic position -&gt; Short scale Because our data have very different scales of variation, we apply the Z-correction # Standardized length, &#39;by hand&#39; fish.data$Z_Length &lt;- (fish.data$Fish_Length - mean(fish.data$Fish_Length))/sd(fish.data$Fish_Length) # Standardized trophic position, with the function scale fish.data$Z_TP &lt;- scale(fish.data$Trophic_Pos) 9.5 Do you need a LMM? Determine if you need a mixed model To find out if a mixed model is needed for your data, you need to determine whether it is important to consider the random effects that might influence the relationship you are interested in (in our case, lake and species). We can do this by: Creating a linear model without random effect Calculating the residuals of this linear model Plot the residuals against the levels of the potential random factors Create a linear model without random effects lm.test &lt;- lm(Z_TP ~ Z_Length, data = fish.data) Calculate residuals of this linear model lm.test.resid &lt;- rstandard(lm.test) Plot the residuals against the levels of the potential random factors par(mfrow = c(1, 2)) plot(lm.test.resid ~ as.factor(fish.data$Fish_Species), xlab = &quot;Species&quot;, ylab = &quot;Standardized residuals&quot;) abline(0, 0, lty = 2) plot(lm.test.resid ~ as.factor(fish.data$Lake), xlab = &quot;Lake&quot;, ylab = &quot;Standardized residuals&quot;) abline(0, 0, lty = 2) These results suggest that there is residual variance that could be explained by these factors, so they should be included in a mixed effect model! "],["step-2-code-potential-models-and-model-selection.html", "Chapter 10 Step 2. Code potential models and model selection 10.1 Estimation methods 10.2 Different model structures 10.3 Challenge 4 10.4 Challenge 5", " Chapter 10 Step 2. Code potential models and model selection Translate this model… \\[PT_{ijk} \\sim Length_i + Lake_j + Species_k + \\epsilon_{ijk}\\] … into R code lmer(Z_TP ~ Z_Length + (1 | Lake) + (1 | Fish_Species), data = fish.data, REML = TRUE) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: Z_TP ~ Z_Length + (1 | Lake) + (1 | Fish_Species) ## Data: fish.data ## REML criterion at convergence: 72.4662 ## Random effects: ## Groups Name Std.Dev. ## Lake (Intercept) 0.4516 ## Fish_Species (Intercept) 0.9301 ## Residual 0.2605 ## Number of obs: 180, groups: Lake, 6; Fish_Species, 3 ## Fixed Effects: ## (Intercept) Z_Length ## 9.752e-14 4.198e-01 Where: lmer -&gt; “linear mixed model” function from lme4 package (1 | Lake) -&gt; indicate varying intercepts among lakes REML = TRUE -&gt; estimation method 10.1 Estimation methods REML (Restricted Maximum Likelihood) is the default method in lmer (see ?lmer). The Maximum Likelihood (ML) method underestimate model variances by a factor of \\((n-k)/n\\), where \\(k\\) is the number of fixed effects. The REML method corrects for this bias. REML estimates can be used when comparing models with the same fixed effects (i.e. nested models). However, if you are comparing models where the fixed effects differ among models then maximum likelihood should be used to fit parameters as this method is not dependent on the coefficients of the fixed effects. Fitting using maximum likelihood is done by setting REML=FALSE in the lmer command. See this article for more information on the difference between ML and REML. In summary: REML to compare models with nested random effects and the same fixed effect structure ML to compare models with nested fixed effects and the same random effect structure ML to compare models with and without random effects 10.2 Different model structures What if we want the slopes to vary? Let’s look at different model structures: (1 | Lake) random effect by lake at the intrecept (1 + Z_Length | Lake) random effect by lake at the intercept and slope in response to the body length (NB: (Z_Length | Lake) gives the same random structure) (-1 + Z_Length | Lake) to have only the random effect at the slope (1 | Lake) + (1 | Species) for crossed random effects (1 | Lake:Fish_Species) for the interaction between 2 random effects If your dataset includes nested random effects, you could use / to specify them, e.g. (1 | factor1 / factor2) if factor2 is nested in factor1 (see ) 10.3 Challenge 4 Re-write the following code so that the slopes of the relationship between trophic position and body length vary by lake and species: # Challenge 4: Can you re-write this code so that the slopes # between trophic position and body length vary by lake and # species? lmer(Z_TP ~ Z_Length + (1 | Lake) + (1 | Fish_Species), data = fish.data, REML = TRUE) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: Z_TP ~ Z_Length + (1 | Lake) + (1 | Fish_Species) ## Data: fish.data ## REML criterion at convergence: 72.4662 ## Random effects: ## Groups Name Std.Dev. ## Lake (Intercept) 0.4516 ## Fish_Species (Intercept) 0.9301 ## Residual 0.2605 ## Number of obs: 180, groups: Lake, 6; Fish_Species, 3 ## Fixed Effects: ## (Intercept) Z_Length ## 9.752e-14 4.198e-01 Challenge 4 Solution: # Challenge 4 solution: lmer(Z_TP ~ Z_Length + (1 + Z_Length | Lake) + (1 + Z_Length | Fish_Species), data = fish.data, REML = TRUE) ## boundary (singular) fit: see ?isSingular ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: ## Z_TP ~ Z_Length + (1 + Z_Length | Lake) + (1 + Z_Length | Fish_Species) ## Data: fish.data ## REML criterion at convergence: 20.5786 ## Random effects: ## Groups Name Std.Dev. Corr ## Lake (Intercept) 0.45279 ## Z_Length 0.02378 -0.82 ## Fish_Species (Intercept) 0.93103 ## Z_Length 0.15728 1.00 ## Residual 0.22341 ## Number of obs: 180, groups: Lake, 6; Fish_Species, 3 ## Fixed Effects: ## (Intercept) Z_Length ## -0.0009025 0.4223738 ## optimizer (nloptwrap) convergence code: 0 (OK) ; 0 optimizer warnings; 1 lme4 warnings 10.4 Challenge 5 To determine if you have built the best mixed model based on your prior knowledge, you should compare this a priori model to other alternative models. With the dataset you are working on, there are several alternative models that might better fit your data. For challenge 5, make a list of 7 alternative models that could be compared to this one: # Challenge 5: Make a list of 7 alternative models that could # be compared to this initial model: lmer(Z_TP ~ Z_Length + (1 | Lake) + (1 | Fish_Species), data = fish.data, REML = TRUE) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: Z_TP ~ Z_Length + (1 | Lake) + (1 | Fish_Species) ## Data: fish.data ## REML criterion at convergence: 72.4662 ## Random effects: ## Groups Name Std.Dev. ## Lake (Intercept) 0.4516 ## Fish_Species (Intercept) 0.9301 ## Residual 0.2605 ## Number of obs: 180, groups: Lake, 6; Fish_Species, 3 ## Fixed Effects: ## (Intercept) Z_Length ## 9.752e-14 4.198e-01 Note: If we had different fixed effects between the models or a model without random effects, we would have to specify REML = FALSE to compare with likelihood methods like AIC. Challenge 5 Solution: We first will also build the basic linear model lm() because it is always useful to see the variation in the AICc values (we will discuss these in more detail in the next section). # Challenge 5 solution: Basic linear model M0 &lt;- lm(Z_TP ~ Z_Length, data = fish.data) In order to compare this model to the LMMs, it is important to change the estimation method to ML (REML=FALSE) for all other models because lm() does not use the same estimation method as lmer(). Let’s look at the other models you could have written (note REML = FALSE): # Challenge 5 solution, other potential models Note that REML # = FALSE in order to compare with the basic linear model # where estimation method = ML # Basic linear model / Linear model with no random effects M0 &lt;- lm(Z_TP ~ Z_Length, data = fish.data) # Full model with varying intercepts M1 &lt;- lmer(Z_TP ~ Z_Length + (1 | Fish_Species) + (1 | Lake), data = fish.data, REML = FALSE) # Full model with varying intercepts and slopes M2 &lt;- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Fish_Species) + (1 + Z_Length | Lake), data = fish.data, REML = FALSE) ## boundary (singular) fit: see ?isSingular # No Lake, varying intercepts only M3 &lt;- lmer(Z_TP ~ Z_Length + (1 | Fish_Species), data = fish.data, REML = FALSE) # No Species, varying intercepts only M4 &lt;- lmer(Z_TP ~ Z_Length + (1 | Lake), data = fish.data, REML = FALSE) # No Lake, varying intercepts and slopes M5 &lt;- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Fish_Species), data = fish.data, REML = FALSE) ## boundary (singular) fit: see ?isSingular # No Species, varying intercepts and slopes M6 &lt;- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Lake), data = fish.data, REML = FALSE) ## boundary (singular) fit: see ?isSingular # Full model with varying intercepts and slopes only varying # by lake M7 &lt;- lmer(Z_TP ~ Z_Length + (1 | Fish_Species) + (1 + Z_Length | Lake), data = fish.data, REML = FALSE) ## boundary (singular) fit: see ?isSingular # Full model with varying intercepts and slopes only varying # by species M8 &lt;- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Fish_Species) + (1 | Lake), data = fish.data, REML = FALSE) ## boundary (singular) fit: see ?isSingular When fitting LMMs with lmer(), you may encounter some errors or warnings such as: boundary (singular) fit: see ?isSingular, see this discussion on stack-exchange Model failed to converge with max|grad| ..., see this discussion on stack-exchange Here a list of possible problems and how to troubleshoot them. What do these AICc values mean? The model with the smallest AICc has the highest predictive power. Some suggest that if models are within 2 AICc units of each other then they are equally plausible. Let’s take a closer look at M8 and M2. We can exclude other models because they have such higher AICc. Note that we use now REML (i.e. REML = TRUE) as we are comparing two models with nested random effects and the same fixed effect structure. # Let&#39;s take a closer look at M8 and M2. We can exclude other # model because they have such higher AICc Because we are # comparing two mixed effect models, we can set `REML = TRUE` # when generating M8 and M2 M8 &lt;- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Fish_Species) + (1 | Lake), data = fish.data, REML = TRUE) ## boundary (singular) fit: see ?isSingular M2 &lt;- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Fish_Species) + (1 + Z_Length | Lake), data = fish.data, REML = TRUE) ## boundary (singular) fit: see ?isSingular # Now let&#39;s print a table in order to compare M2 and M8 MuMIn::model.sel(M2, M8)[, c(&quot;df&quot;, &quot;logLik&quot;, &quot;AICc&quot;, &quot;delta&quot;)] ## df logLik AICc delta ## M8 7 -10.84011 36.33137 0.000000 ## M2 9 -10.28932 39.63747 3.306098 Model M8 seems to be the best among all models that we tested. What is the structure of the best model? # Let&#39;s take a look at the best model again, what is it&#39;s # structure? M8 &lt;- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Fish_Species) + (1 | Lake), data = fish.data, REML = FALSE) ## boundary (singular) fit: see ?isSingular # Both the intercepts and slopes of the relationship between # trophic position and length may vary by fish species, but # only the intercepts may vary by lake. Both the intercepts and slopes of the relationship between trophic position and length may vary by fish species, but only the intercepts may vary by lake. Once the best model is selected, the estimation method must be reset to REML = TRUE. # Once the best model is selected, the estimation method must # be reset to `REML = TRUE`. M8 &lt;- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Fish_Species) + (1 | Lake), data = fish.data, REML = TRUE) ## boundary (singular) fit: see ?isSingular "],["step-3-model-validation.html", "Chapter 11 Step 3. Model validation 11.1 1. Check the homogeneity of the variance 11.2 2. Check the independence of the model residuals with each covariate 11.3 3. Check the normality of the model residuals", " Chapter 11 Step 3. Model validation Now that we have our model, we must verify that the model follows all the basic assumptions: 1. Check the homogeneity of the variance: Plot predicted values vs residual values 2. Check the independence of the model residuals: Plot residuals vs each covariate of the model Plot residuals vs each covariate not included in the model 3. Check the normality of the model residuals: Histogram of residuals 11.1 1. Check the homogeneity of the variance In order to check the homgeneity of the variance, we can plot predicted values vs residual values. Homogeneous dispersion of the residuals means that the assumption is respected. Now let’s look at our data, is the dispersion homogenous? # Plot predicted values vs residual values par(mar = c(4, 4, 0.5, 0.5)) plot(resid(M8) ~ fitted(M8), xlab = &quot;Predicted values&quot;, ylab = &quot;Normalized residuals&quot;) abline(h = 0, lty = 2) # Homogeneous dispersion of the residuals means that the # assumption is respected. Yes! Homogeneous dispersion of the residuals means that the assumption is respected. 11.2 2. Check the independence of the model residuals with each covariate In order to check the independence of the model residuals with each covariate we will (1) plot residuals vs each covariate of the model and (2) plot residuals vs each covariate not included in the model. Let’s start by (1) plotting the residuals vs each covariate of the model. # In order to check the independence of the model residuals # we need to plot residuals vs each covariate of the model par(mfrow = c(1, 3), mar = c(4, 4, 0.5, 0.5)) plot(resid(M8) ~ fish.data$Z_Length, xlab = &quot;Length&quot;, ylab = &quot;Normalized residuals&quot;) abline(h = 0, lty = 2) boxplot(resid(M8) ~ Fish_Species, data = fish.data, xlab = &quot;Species&quot;, ylab = &quot;Normalized residuals&quot;) abline(h = 0, lty = 2) boxplot(resid(M8) ~ Lake, data = fish.data, xlab = &quot;Lakes&quot;, ylab = &quot;Normalized residuals&quot;) abline(h = 0, lty = 2) # Homogeneous dispersion of the residuals around 0 means no # pattern of residuals depending on the variable, therefore # the assumption is respected! Note: The clusters are due to # the data structure, where fish of only 5 size classes # (large, small, and three groups in between) were captured. Homogeneous dispersion of the residuals around 0 means no pattern of residuals depending on the variable, therefore the assumption is respected! Note: The clusters are due to the data structure, where fish of only 5 size classes (large, small, and three groups in between) were captured. Now, we should (2) plot residuals vs each covariate not included in the model. If you observe patterns in these plots, you will know that there is variation in your dataset that could be explained by these covariates and you should consider including them in your model. However because we have included all the measured variables in our model, we can not do this step with our data. 11.3 3. Check the normality of the model residuals Now we will check the normality of the model residuals as residuals following a normal distribution indicate that the model is not biased. # Check the normality of the model residuals as residuals # following a normal distribution indicate that the model is # not biased. hist(resid(M8)) # The residuals are normal! This means our model is not # biased. The residuals are normal! This means our model is not biased. "],["step-4-interpretation-and-visualization.html", "Chapter 12 Step 4. Interpretation and visualization 12.1 Interpreting our model 12.2 Challenge 6 12.3 Challenge 7 12.4 Challenge 8", " Chapter 12 Step 4. Interpretation and visualization 12.1 Interpreting our model Let’s take a closer look at our final model using the summary() function. How can we interpret this information? # Now we are ready for interpretation and visualization Let&#39;s # take a closer look at our final model using the `summary()` # function. (summ_M8 &lt;- summary(M8)) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: Z_TP ~ Z_Length + (1 + Z_Length | Fish_Species) + (1 | Lake) ## Data: fish.data ## ## REML criterion at convergence: 21.7 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.77187 -0.60166 0.05589 0.64239 2.27776 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## Lake (Intercept) 0.20504 0.4528 ## Fish_Species (Intercept) 0.86715 0.9312 ## Z_Length 0.02466 0.1570 1.00 ## Residual 0.05039 0.2245 ## Number of obs: 180, groups: Lake, 6; Fish_Species, 3 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) -0.0009059 0.5687733 -0.002 ## Z_Length 0.4222697 0.0922117 4.579 ## ## Correlation of Fixed Effects: ## (Intr) ## Z_Length 0.929 ## optimizer (nloptwrap) convergence code: 0 (OK) ## boundary (singular) fit: see ?isSingular Let’s go section by section and try to understand what we are looking at. Random effects: Groups: grouping factors Name: (Intercept) for the intercepts or the name of the variable on which the random slope is estimated (Z_length in this example) Variance the variance of the estimated effect (Std.Dev. is the standard deviation of this estimate) Corr the correlation between the random interpet and the random slope for a given grouping factor (see this dicussion). Fixed effects: This part presents the fixed effect estimates. The value of the t statistics (Student test) is shown without the p-value (it is a decision from the package authors, see why in this discussion). This statistics could be used as it is. You could also calculate the 95% confidence interval (CI) with this equation: \\[ CI = Estimate \\pm 1.96*Std.Error \\] If 0 is in the interval, then the parameter is not significantly different from zero at a threshold of \\(\\alpha\\) = 0.05. Some useful functions coef(M8) and ranef(M8) return random effects of model M8 coef(summary(M8)) returns fixed effects sigma(M8) returns standard deviation of residuals fitted(M8) returns predicted values by the model residuals(M8) returns residuals 12.2 Challenge 6 1. What is the slope and confidence interval of the Z_Length variable in the M8 model? 2. Is the slope of Z_Length significantly different from 0? Challenge 6 Solution: 1. What is the slope and confidence interval of the Z_Length variable in the M8 model? slope = 0.422; CI upper limit = 0.4223 + 0.09*1.96 = 0.5987 CI lower limit = 0.4223 - 0.09*1.96 = 0.2459 2. Is the slope of Z_Length significantly different from 0? Yes, because the CI [0.2459, 0.5987] does not include 0 12.3 Challenge 7 Is it possible to visualize graphically the different intercepts and slopes of the model to better interpret the results? Take 2 minutes to think about different ways to represent the results of M8. Hint: consider the different “levels” of the model Challenge 7 Solution: Is it possible to visualize graphically the different intercepts and slopes of the model to better interpret the results? Yes! We could do this by generating: A figure with all data grouped A figure by species A figure by lake To produce these figures, we need (1) the coefficients of the full model that are in the model summary, (2) The coefficients for each level of the model, which can be obtained with the coef function # Challenge 7: *Is it possible to visualize graphically the # different intercepts and slopes of the model to better # interpret the results? # Challenge 7 solution: Yes! We could do this by generating # the following figures. a) A figure with all data grouped # b) A figure by species c) A figure by lake # To produce these figures, first we need the coefficients of # the full model that are in the model summary. summ_M8$coefficients ## Estimate Std. Error t value ## (Intercept) -0.0009058974 0.56877327 -0.001592722 ## Z_Length 0.4222697238 0.09221166 4.579352788 # Intercept = Intercept = 9.0589745 × 10^4 Slope = 0.4222697 # We also need the coefficients for each level of the model, # which can be obtained with the `coef` function coef(M8) ## $Lake ## (Intercept) Z_Length ## L1 -0.085984071 0.4222697 ## L2 0.002205209 0.4222697 ## L3 -0.301816557 0.4222697 ## L4 -0.574039728 0.4222697 ## L5 0.218650140 0.4222697 ## L6 0.735549622 0.4222697 ## ## $Fish_Species ## (Intercept) Z_Length ## S1 -1.0752985 0.2410746 ## S2 0.5597871 0.5168300 ## S3 0.5127938 0.5089046 ## ## attr(,&quot;class&quot;) ## [1] &quot;coef.mer&quot; Now let’s make our figures! Figure with all data grouped # Now let&#39;s make our figures! library(ggplot2) # Load ggplot2 if you haven&#39;t already # a) Figure with all data grouped Create a simplified ggplot # theme fig &lt;- theme_bw() + theme(panel.grid.minor = element_blank(), panel.grid.major = element_blank(), panel.background = element_blank()) + theme(strip.background = element_blank(), strip.text.y = element_text()) + theme(legend.background = element_blank()) + theme(legend.key = element_blank()) + theme(panel.border = element_rect(colour = &quot;black&quot;, fill = NA)) plot &lt;- ggplot(aes(Z_Length, Z_TP), data = fish.data) Plot_AllData &lt;- plot + geom_point() + xlab(&quot;Length (mm)&quot;) + ylab(&quot;Trophic position&quot;) + labs(title = &quot;All data&quot;) + fig Plot_AllData + geom_abline(intercept = summ_M8$coefficients[1, 1], slope = summ_M8$coefficients[2, 1]) # You could also write out the numbers like this: # Plot_AllData + geom_abline(intercept = -0.0009059, slope = # 0.4222697) Figure by species # b) Figure by species Create a table with the coefs to # facilitate their manipulation Lake.coef &lt;- coef(M8)$Lake colnames(Lake.coef) &lt;- c(&quot;Intercept&quot;, &quot;Slope&quot;) Species.coef &lt;- coef(M8)$Fish_Species colnames(Species.coef) &lt;- c(&quot;Intercept&quot;, &quot;Slope&quot;) Plot_BySpecies &lt;- plot + geom_point(aes(colour = factor(Fish_Species)), size = 4) + xlab(&quot;Length (mm)&quot;) + ylab(&quot;Trophic position&quot;) + labs(title = &quot;By species&quot;) + fig # Add regression lines for each species Plot_BySpecies + geom_abline(intercept = Species.coef[1, 1], slope = Species.coef[1, 2], col = &quot;coral2&quot;) + geom_abline(intercept = Species.coef[2, 1], slope = Species.coef[2, 2], col = &quot;green4&quot;) + geom_abline(intercept = Species.coef[3, 1], slope = Species.coef[3, 2], col = &quot;blue1&quot;) Figure by lake # c) Figure by lake Plot_ByLake &lt;- plot + geom_point(aes(colour = factor(Lake)), size = 4) + xlab(&quot;Length (mm)&quot;) + ylab(&quot;Trophic Position&quot;) + labs(title = &quot;By Lake&quot;) + fig # Add in regression lines with the intercepts specific to # each lake Plot_ByLake + geom_abline(intercept = Lake.coef[1, 1], slope = Lake.coef[1, 2], col = &quot;coral2&quot;) + geom_abline(intercept = Lake.coef[2, 1], slope = Lake.coef[2, 2], col = &quot;khaki4&quot;) + geom_abline(intercept = Lake.coef[3, 1], slope = Lake.coef[3, 2], col = &quot;green4&quot;) + geom_abline(intercept = Lake.coef[4, 1], slope = Lake.coef[4, 2], col = &quot;darkgoldenrod&quot;) + geom_abline(intercept = Lake.coef[5, 1], slope = Lake.coef[5, 2], col = &quot;royalblue1&quot;) + geom_abline(intercept = Lake.coef[6, 1], slope = Lake.coef[6, 2], col = &quot;magenta3&quot;) 12.4 Challenge 8 Let’s test our knowledge by considering another scenario. Imagine that you have inventoried species richness in 1000 quadrats that are within 10 different sites which are also within 10 different forests. You also measured productivity in each quadrat. You want to know if productivity is a good predictor of biodiversity. What mixed model could you use for this dataset? Challenge 8 Solution: lmer(Biodiv ~ Productivity + (1 | Forest/Site)) Here the random effects are nested (i.e. Sites within forest) and not crossed. Why use (1 | Forest / Site) rather than (1 | Forest) + (1 | Site)? See the answer here! "],["introduction-to-glmm.html", "Chapter 13 Introduction to GLMM", " Chapter 13 Introduction to GLMM Generalized linear mixed models (GLMM) are an extension of generalized linear models (GLM) that account for additional structure in dataset. They follows similar steps to those we just introduced with linear mixed models (LMM): 1. Incorporate random effects (like LMMs) 2. Handle non-normal data, letting errors take on different distribution families - e.g. Poisson or negative binomial (like GLMs; Workshop 6) As with the LMM portion of this workshop, we are going to work through the GLMM material with a dataset in order to better understand how GLMMs work and how to implement them in R. In the Arabidopsis dataset, the effect of nutrient availability and herbivory (fixed effects) on the fruit production (response variable) of Arabidopsis thaliana was evaluated by measuring 625 plants across 9 different populations, each comprised of 2 to 3 different genotypes (random effects). Start by importing the Arabidopsis dataset banta_totalfruits.csv into R. dat.tf &lt;- read.csv(&quot;data/banta_totalfruits.csv&quot;) ## In this dataset, the column headers are defined as: popu ## factor with a level for each population gen factor with a ## level for each genotype nutrient factor with levels for low ## (value = 1) or high (value = 8) amd factor with levels for ## no damage or simulated herbivory total.fruits integer ## indicating the number of fruits per plant "],["choose-an-error-distribution.html", "Chapter 14 Choose an error distribution", " Chapter 14 Choose an error distribution Now we need to select an error distribution. This choice will be informed by the structure of our data. In the Arabidopsis dataset, the response variable is count data which suggests we need a Poisson distribution (i.e. the variance is equal to the mean). Let’s take a look: # Before we go any further, we need to select an error # distribution. This choice will be informed by the structure # of our data. Our response variable is count data which # suggests we need a Poisson distribution (i.e. the variance # is equal to the mean). hist(dat.tf$total.fruits, breaks = 50, col = &quot;blue&quot;, main = &quot;&quot;, xlab = &quot;Total fruits&quot;, ylab = &quot;Count&quot;) However, as we will soon see, the variance increases with the mean much more rapidly than expected under the Poisson distribution… Explore variance Let’s take a closer look at the variance within our data. To illustrate heterogeneity in variance we will first create boxplots of the log of total fruit production (response variable) versus different environmental factors. Let’s create new variables that represent every combination of nutrient x clipping x random factor # Let&#39;s explore the variance within our data Create new # variables that represent every combination of variables dat.tf &lt;- within(dat.tf, { # genotype x nutrient x clipping gna &lt;- interaction(gen, nutrient, amd) gna &lt;- reorder(gna, total.fruits, mean) # population x nutrient x clipping pna &lt;- interaction(popu, nutrient, amd) pna &lt;- reorder(pna, total.fruits, mean) }) Now let’s visualize: library(ggplot2) # Boxplot of total fruits vs genotype x nutrient x clipping interaction ggplot(data = dat.tf, aes(factor(x = gna), y = log(total.fruits + 1))) + geom_boxplot(colour = &quot;skyblue2&quot;, outlier.shape = 21, outlier.colour = &quot;skyblue2&quot;) + ylab(&quot;log (Total fruits)\\n&quot;) + # \\n creates a space after the title xlab(&quot;\\nGenotype x nutrient x clipping&quot;) + # space before the title theme_bw() + theme(axis.text.x = element_blank()) + stat_summary(fun = mean, geom = &quot;point&quot;, colour = &quot;red&quot;) From this plot, we see that the variance of total fruits shows a large amount of heterogeneity among populations (population x nutrient x clipping interaction). Back to choosing an error distribution As we just saw, there is a large amount of heterogeneity among group variances even when the response variable is transformed (i.e. log). To determine which distribution family to use, we can run a diagnostic plot of the group variances vs group means. We provide an example below for the genotype x nutrient x clipping grouping. If we observe a linear relationship between the variance and the mean with a slope = 1, then the Poisson family is appropriate, If we observe a linear mean-variance relationship with a slope &gt; 1 (i.e. Var = φµ where φ &gt; 1), then the quasi-Poisson family (as introduced above) should be applied, Finally, a quadratic relationship between the variance and the mean (i.e. \\(Var = µ(1 + α) or µ(1 + µ/k)\\)) is characteristic of overdispersed data that is driven by an underlying heterogeneity among samples. In this case, the negative binomial (Poisson-gamma) would be more appropriate. ## Run a diagnostic lot of the group variances vs group means ## (genotype x nutrient x clipping grouping). Code used to ## produce the plot : ## https://github.com/QCBSRworkshops/workshop07/blob/main/pres-fr/data/glmm_e.r ## Substantial variation among the sample variances on the ## transformed data For example, among genotypes: grpVars &lt;- tapply(dat.tf$total.fruits, dat.tf$gna, var) grpMeans &lt;- tapply(dat.tf$total.fruits, dat.tf$gna, mean) # Quasi-Poisson lm1 &lt;- lm(grpVars ~ grpMeans - 1) phi.fit &lt;- coef(lm1) # The -1 specifies a model with the intercept set to zero # Negative binomial lm2 &lt;- lm(grpVars ~ I(grpMeans^2) + offset(grpMeans) - 1) k.fit &lt;- 1/coef(lm2) # The offset() is used to specify that we want the group # means added as a term with its coefficient fixed to 1 # Non-parametric loess fit Lfit &lt;- loess(grpVars ~ grpMeans) # The plot plot(grpVars ~ grpMeans, xlab = &quot;Group means&quot;, ylab = &quot;Group variances&quot;) abline(a = 0, b = 1, lty = 2) text(105, 500, &quot;Poisson&quot;) curve(phi.fit * x, col = 2, add = TRUE) # bquote() is used to substitute numeric values in equations # with symbols text(110, 3900, bquote(paste(&quot;QP: &quot;, sigma^2 == .(round(phi.fit, 1)) * mu)), col = 2) curve(x * (1 + x/k.fit), col = 4, add = TRUE) text(104, 7200, paste(&quot;NB: k = &quot;, round(k.fit, 1), sep = &quot;&quot;), col = 4) mvec &lt;- 0:120 lines(mvec, predict(Lfit, mvec), col = 5) text(118, 2000, &quot;loess&quot;, col = 5) From the plot above we note that a linear quasi-Poisson may be better than the negative binomial, but additional modeling is needed. "],["poisson-glmm.html", "Chapter 15 Poisson GLMM", " Chapter 15 Poisson GLMM Given the mean-variance relationship, we will most likely need a model with over-dispersion. To understand why, let’s start with a Poisson model. To run a GLMM in R we will use the glmer() function from the lme4 package: ## Poisson GLMM Given the mean-variance relationship, we will ## most likely need a model with over-dispersion. To ## understand why, let&#39;s start with a Poisson model. library(lme4) # Load in lme4 pkg with glmer() command for running GLMM mp1 &lt;- glmer(total.fruits ~ nutrient * amd + rack + status + (1 | popu) + (1 | gen), data = dat.tf, family = &quot;poisson&quot;) Random effects: (1|popu) and (1|gen). We model random intercepts for both factors so that total fruit production can vary among populations (popu) and genotypes (gen). Over-dispersion check We can check for overdispersion using the overdisp_fun() function (Bolker et al. 2011) which divides the Pearson residuals by the residual degrees of freedom. The function tests whether the ratio is greater than 1. Let’s run the test: # Download the glmm_funs.R code from the wiki page and source # it to run the function source(file = &quot;data/glmm_funs.R&quot;) # This line will vary depending on where your data is saved # Over-dispersion check overdisp_fun(mp1) ## chisq ratio p logp ## 15755.86829 25.57771 0.00000 -6578.47025 # Ratio is significantly &gt; 1 Ratio is significantly &gt; 1 As expected, we need to model a different distribution where the variance increases more rapidly than the mean. "],["negative-binomial-glmm.html", "Chapter 16 Negative binomial GLMM", " Chapter 16 Negative binomial GLMM One option for a distribution where the variance increases more rapidly with the mean is the negative binomial (or Poisson-gamma) distribution. Recall that the negative binomial distribution meets the assumption that the variance is proportional to the square of the mean. We can model this distribution using the function glmer.nb(): ## Negative binomial GLMM using the function glmer.nb() mnb1 &lt;- glmer.nb(total.fruits ~ nutrient * amd + rack + status + (1 | popu) + (1 | gen), data = dat.tf, control = glmerControl(optimizer = &quot;bobyqa&quot;)) # Control argument specifies the way we optimize the # parameter values We test again for over-dispersion: # Over-dispersion check overdisp_fun(mnb1) ## chisq ratio p logp ## 721.034466390 1.170510497 0.002143424 -6.145350714 # Ratio is now much closer to 1 although p &lt; 0.05 Ratio is now much closer to 1 although p &lt; 0.05 "],["poisson-lognormal-glmm.html", "Chapter 17 Poisson-lognormal GLMM", " Chapter 17 Poisson-lognormal GLMM A second option for a distribution where the variance increases more rapidly with the mean is the Poisson-lognormal distribution. This can be achieved simply by placing an observation-level random effect in the model formula. See Harrison (2014) for further details https://doi.org/10.7717/peerj.616. To do this in R, we first create a variable named X: ## Poisson-lognormal GLMM # This variable is already in your data &#39;dat.tf&#39;, but here is # how we create it : dat.tf$X &lt;- 1:nrow(dat.tf) We take over-dispersion into account by adding the random effect (1|X) in the formula: # Account for over-dispersion mpl1 &lt;- glmer(total.fruits ~ nutrient * amd + rack + status + (1 | X) + (1 | popu) + (1 | gen), data = dat.tf, family = &quot;poisson&quot;, control = glmerControl(optimizer = &quot;bobyqa&quot;)) Finally, we test for over-dispersion: # Over-dispersion check overdisp_fun(mpl1) ## chisq ratio p logp ## 1.775360e+02 2.886764e-01 1.000000e+00 -3.754681e-73 # Ratio now meets our criterion, thus, &lt; 1 Ratio is not &lt;1 and meets our criterion! Now that we’ve chosen out error distribution, let’s visualize the model parameters. A graphical representation of the model parameters can be obtained using the coefplot2() function from the coefplot2 package : Note: This package is not on CRAN! We install it from GitHub using the remotes package. if (!require(&quot;coefplot2&quot;)) remotes::install_github(&quot;palday/coefplot2&quot;, subdir = &quot;pkg&quot;) ## Loading required package: coefplot2 ## Warning in library(package, lib.loc = lib.loc, character.only = TRUE, ## logical.return = TRUE, : there is no package called &#39;coefplot2&#39; ## Using bundled GitHub PAT. Please add your own PAT to the env var `GITHUB_PAT` ## Downloading GitHub repo palday/coefplot2@HEAD ## reshape (NA -&gt; 0.8.8 ) [CRAN] ## coda (NA -&gt; 0.19-4) [CRAN] ## Installing 2 packages: reshape, coda ## Installing packages into &#39;/home/runner/work/_temp/Library&#39; ## (as &#39;lib&#39; is unspecified) ## checking for file ‘/tmp/RtmpAv98fY/remotes34bc7feb6a52/palday-coefplot2-23b7dcb/pkg/DESCRIPTION’ ... ✔ checking for file ‘/tmp/RtmpAv98fY/remotes34bc7feb6a52/palday-coefplot2-23b7dcb/pkg/DESCRIPTION’ ## ─ preparing ‘coefplot2’: ## checking DESCRIPTION meta-information ... ✔ checking DESCRIPTION meta-information ## ─ checking for LF line-endings in source and make files and shell scripts ## ─ checking for empty or unneeded directories ## ─ building ‘coefplot2_0.1.3.3.tar.gz’ ## ## ## Installing package into &#39;/home/runner/work/_temp/Library&#39; ## (as &#39;lib&#39; is unspecified) library(coefplot2) ## Loading required package: coda # Variance terms coefplot2(mpl1, ptype = &quot;vcov&quot;, intercept = TRUE, main = &quot;Random effect variance&quot;) # Fixed effects coefplot2(mpl1, intercept = TRUE, main = &quot;Fixed effect coefficient&quot;) Note: error bars are only shown for the fixed effects because glmer() doesn’t model uncertainty for random effects. Now let’s visualize the random effects You can extract the random effect predictions using ranef() and plot them using a dotplot() from the lattice package. We observe differences among population: Spanish populations (SP) have larger values than Swedish (SW) or Dutch (NL) populations We observe mild differences among genotypes: Difference among genotypes largely driven by genotype 34 library(gridExtra) library(lattice) # dotplot code pp &lt;- list(layout.widths = list(left.padding = 0, right.padding = 0), layout.heights = list(top.padding = 0, bottom.padding = 0)) r2 &lt;- ranef(mpl1, condVar = TRUE) d2 &lt;- dotplot(r2, par.settings = pp) grid.arrange(d2$gen, d2$popu, nrow = 1) "],["selection-methods.html", "Chapter 18 Selection Methods", " Chapter 18 Selection Methods The same methods can be used with a GLMM or LMM to choose between models with various random intercepts and/or random slopes and to choose fixed effects to keep in final model. Here are two approaches : an information theoretic approach (e.g., AICc - Workshop 5) a frequentist approach (where the significance of each term is evaluated using a likelihood ratio test; LRT, with the anova() function) We first code potential models and compare them using AICc: library(lme4) mpl1 &lt;- glmer(total.fruits ~ nutrient * amd + rack + status + (1 | X) + (1 | popu) + (1 | gen), data = dat.tf, family = &quot;poisson&quot;, control = glmerControl(optimizer = &quot;bobyqa&quot;)) mpl2 &lt;- update(mpl1, . ~ . - rack) # model without rack mpl3 &lt;- update(mpl1, . ~ . - status) # model without status mpl4 &lt;- update(mpl1, . ~ . - amd:nutrient) # without amd:nutrient interaction aic_tab &lt;- MuMIn::model.sel(mpl1, mpl2, mpl3, mpl4) (round(aic_table &lt;- aic_tab[, c(&quot;AICc&quot;, &quot;delta&quot;, &quot;df&quot;)], digits = 2)) ## AICc delta df ## mpl1 5015.73 0.00 10 ## mpl4 5017.11 1.38 9 ## mpl3 5017.22 1.49 8 ## mpl2 5070.75 55.02 9 Note: We do not cover all possible models above, however, the interaction amd:nutrient can only be evaluated if both amd and nutrient (i.e., the main effects) are included in the model. Alternatively, we can use drop1() and dfun() functions to evaluate our fixed effects (dfun() converts the AIC values returned by the drop1() into \\(\\Delta\\)AIC values) dd_LRT &lt;- drop1(mpl1, test = &quot;Chisq&quot;) (dd_AIC &lt;- dfun(drop1(mpl1))) ## Single term deletions ## ## Model: ## total.fruits ~ nutrient * amd + rack + status + (1 | X) + (1 | ## popu) + (1 | gen) ## npar dAIC ## &lt;none&gt; 0.000 ## rack 1 55.083 ## status 2 1.612 ## nutrient:amd 1 1.444 Strong rack effect (dAIC = 55.08 if we remove this variable) Effects of status and interaction term are weak (dAIC &lt; 2) Let’s start by removing the non-significant interaction term to test main effects of nutrient and clipping mpl2 &lt;- update(mpl1, . ~ . - amd:nutrient) mpl3 &lt;- update(mpl2, . ~ . - rack) # pas de rack ou d&#39;interaction mpl4 &lt;- update(mpl2, . ~ . - status) # pas de status ou d&#39;interaction mpl5 &lt;- update(mpl2, . ~ . - nutrient) # pas de nutrient ou d&#39;interaction mpl6 &lt;- update(mpl2, . ~ . - amd) # pas d&#39;herbivorie ou d&#39;interaction Choose the method you want to select the best model: Method with AICc aic_tab2 &lt;- MuMIn::model.sel(mpl2, mpl3, mpl4, mpl5, mpl6) (round(aic_table2 &lt;- aic_tab2[, c(&quot;AICc&quot;, &quot;delta&quot;, &quot;df&quot;)], digits = 2)) ## AICc delta df ## mpl2 5017.11 0.00 9 ## mpl4 5018.28 1.17 7 ## mpl6 5027.27 10.16 8 ## mpl3 5071.28 54.17 8 ## mpl5 5152.74 135.63 8 Method with drop1() dd_LRT2 &lt;- drop1(mpl2, test = &quot;Chisq&quot;) dd_AIC2 &lt;- dfun(drop1(mpl2)) What are our conclusions ? Both the main effects of nutrient and clipping are strong (large change in AIC of \\(135.6\\) (mpl5) and \\(10.2\\) (mpl6) if either nutrient or clipping are dropped, respectively). Our final model includes : Fixed effects * nutrients * clipping * rack Random effects * observation-level random effect (1|X) * populations (1|popu) * genotypes (1|gen) "],["challenge-9.html", "Chapter 19 Challenge 9", " Chapter 19 Challenge 9 Use the inverts dataset (larval development times (PLD) of 74 marine invertebrate and vertebrate species reared at different temperatures and time), answer the following questions: What is the effect of feeding type and climate (fixed effects) on PLD? Does this relationship vary among taxa (random effects)? What is the best distribution family for this count data? Finally, once you determined the best distribution family, re-evaluate your random and fixed effects. Challenge 9 Solution: # inverts &lt;- read.csv(&#39;data/inverts.csv&#39;, header = TRUE) # head(inverts) table(inverts$temp, inverts$feeding.type) # mod.glm &lt;- glm(PLD ~ temp + feeding.type, family = # poisson(), data = inverts) summary(mod.glm) drop1(mod.glm, # test = &#39;Chisq&#39;) # boxplot(PLD ~ temp, data = inverts) boxplot(PLD ~ # feeding.type, data = inverts) # boxplot(predict(mod.glm, type = &#39;response&#39;)~inverts$temp) # plot() # modglm &lt;- glm(PLD ~ temp + feeding.type, family = # poisson(), data = inverts) # r2 &lt;- ranef(mpl1, condVar = TRUE) d2 &lt;- dotplot(r2, # par.settings = pp) # plot(aggregate(PLD ~ taxon, FUN = mean, data = # inverts)[,2], aggregate(PLD ~ taxon, FUN = var, data = # inverts)[,2], pch = 19) abline(a = 0, b = 1, lty = 2) # mod.glmer &lt;- glmer.nb(PLD ~ temp + feeding.type + # (1|taxon), data = inverts) mod.glm &lt;- glm.nb(PLD ~ temp + # feeding.type, family = poisson(), data = inverts) # plot(aggregate(PLD ~ taxon, FUN = var, data = inverts)[,2], # aggregate(PLD ~ taxon, FUN = mean, data = inverts)[,2]) # abline(a = 0, b = 1, lty = 2 ) "],["additional-resources.html", "Chapter 20 Additional resources", " Chapter 20 Additional resources Popular libraries for (G)LMMs Frequentist : nlme, lme4, glmmTMB Bayesian : brms, rstan, rstanarm, MCMCglmm Papers - Harrison et al. (2018), PeerJ, DOI 10.7717/peerj.4794 Silk et al. (2020), PeerJ, DOI 10.7717/peerj.9522 Schielzeth et al. (2020), Methods Ecol Evol., DOI: 10.1111/2041-210X.13434 Zuur &amp; Ieno (2016), Methods Ecol Evol., DOI: 10.1111/2041-210X.12577 Thank you for attending this workshop! "],["references.html", "Chapter 21 References", " Chapter 21 References "]]
