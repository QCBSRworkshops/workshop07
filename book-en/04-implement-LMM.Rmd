# (PART\*) Implementing LMM in `R` {-}

# Mixed model protocol

- **Step 1.** *A priori* model building and data exploration
- **Step 2.** Code potential models and model selection
- **Step 3.** Model validation
- **Step 4.** Model interpretation and visualization

# Step 1. *A priori* model building

**What we know *a priori*:**

We want to determine if the trophic position can be predicted by body length, while taking into account the variation between species and lakes. So we want a model that looks like this:

$$TP_{ijk} \sim Length_i + Lake_j + Species_k + \epsilon_{ijk}$$
where:
- `TP_ijk` is the trophic position of individual (i) from lake (j) of species (k)
- `ε` are the residuals of the model (i.e. the unexplained variation).

## Check data structure 

**Does the data have the right structure?**

```{r, echo = FALSE}
# Load data in again
fish.data <- read.csv('data/qcbs_w7_data.csv')
```

Look at the data structure:

```{r, echo = TRUE, eval = TRUE}
# Look at data structure
str(fish.data)
```

Now look at the distribution of samples for each factor:

```{r, echo = TRUE, eval = TRUE}
# Look at the distribution of samples for each factor
table(fish.data[ , c("Lake", "Fish_Species")])
```

This dataset is perfectly balanced, but **mixed models can be used to analyze unbalanced experimental plans**, as it is often the case in ecology!

Let's also look at the distribution of continuous variables:

```{r, echo = TRUE, eval = TRUE}
# Look at the distribution of continuous variables:
par(mfrow = c(1, 2), mar = c(4, 4, 1, 1))
hist(fish.data$Fish_Length, xlab = "Length (mm)", main = "")
hist(fish.data$Trophic_Pos, xlab = "Trophic position", main = "")
```

Major deviations could cause heteroscedasticity problems. If necessary, make transformations. In this case, **the data seems OK**.

---

## Check collinearity 

**Check for collinearity between your explanatory variables**

The problem with collinear predictors is simply that they explain the same thing, so their effect on the response variable will be confounded in the model.

In this example, there is no risk of collinearity with only one continuous variable. If you had another continuous variable (`var2`), one simple way to check for collinearity is `cor(var1, var2)`

Here an [example of collinearity](https://yetanotheriteration.netlify.app/2018/01/high-collinearity-effect-in-regressions/).

---

## Challenge 3

This is a thinking problem!

Given our data, What additional measures could we have taken in the field that could have been strongly correlated with body length?

---

#### **Challenge 3 Solution:** {-}

There are multiple potential answers here.

One example is fish body mass - this variable is strongly correlated with fish length. Therefore, we do not want to include these two variables in the same model.

---

## Consider scale

**Consider the scale of your data**

If two variables in the same model have very different scales, the mixed model will likely return a `convergence error` when trying to compute the parameters.

The <a href="https://fr.wikipedia.org/wiki/Cote_Z_(statistiques)">Z-correction</a> standardizes the variables and solve this problem (use function `scale()` in `R`):

$$z = \frac{x-mean(x)}{standard.deviation(x)}$$
Consider the scale of the variables within our dataset:

Body length -> Long scale
Trophic position -> Short scale

Because our data have very different scales of variation, we apply the **Z-correction**

```{r, echo = TRUE, eval = TRUE}
# Standardized length, "by hand"
fish.data$Z_Length <- (fish.data$Fish_Length - mean(fish.data$Fish_Length)) / 
                      sd(fish.data$Fish_Length)

# Standardized trophic position, with the function scale
fish.data$Z_TP     <- scale(fish.data$Trophic_Pos)

```

---

## Do you need a LMM?

**Determine if you need a mixed model** 

To find out if a mixed model is needed for your data, you need to determine whether it is important to consider the random effects that might influence the relationship you are interested in (in our case, lake and species).

We can do this by:

- 1. Creating a linear model without random effect
- 2. Calculating the residuals of this linear model
- 3. Plot the residuals against the levels of the potential random factors


Create a linear model without random effects

```{r, echo = TRUE, eval = TRUE}
lm.test <- lm(Z_TP ~ Z_Length, data = fish.data)
```

Calculate residuals of this linear model

```{r, echo = TRUE, eval = TRUE}
lm.test.resid <- rstandard(lm.test)
```


Plot the residuals against the levels of the potential random factors

```{r, echo = TRUE, eval = TRUE}
par(mfrow = c(1, 2))

plot(lm.test.resid ~ as.factor(fish.data$Fish_Species),
     xlab = "Species", ylab = "Standardized residuals")

abline(0, 0, lty = 2)

plot(lm.test.resid ~ as.factor(fish.data$Lake),
     xlab = "Lake", ylab = "Standardized residuals")

abline(0, 0, lty = 2)
```

These results suggest that there is residual variance that could be explained by these factors, so they should be included in a mixed effect model!

# Step 2. Code potential models and model selection


**Translate this model...**

$$TP_{ijk} \sim Length_i + Lake_j + Species_k + \epsilon_{ijk}$$

**... into R code**

```{r, echo = TRUE, eval = TRUE}
lmer(Z_TP ~ Z_Length + (1 | Lake) + (1 | Fish_Species),
     data = fish.data, REML = TRUE)
```

Where: 

- `lmer` -> "linear mixed model" function from `lme4` package
- `(1 | Lake)` -> indicate varying intercepts among lakes
- `REML = TRUE` -> estimation method

## Estimation methods 

REML (*Restricted Maximum Likelihood*) is the default method in `lmer` (see `?lmer`).

The *Maximum Likelihood* (ML) method underestimate model variances by a factor of $(n-k)/n$, where $k$ is the number of fixed effects. The *REML* method corrects for this bias.

REML estimates can be used when comparing models with the same fixed effects (i.e. nested models). However, if you are comparing models where the fixed effects differ among models then maximum likelihood should be used to fit parameters as this method is not dependent on the coefficients of the fixed effects. Fitting using maximum likelihood is done by setting `REML=FALSE` in the lmer command.

See this [article](https://towardsdatascience.com/maximum-likelihood-ml-vs-reml-78cf79bef2cf) for more information on the difference between ML and REML. 


**In summary:** 

* **REML** to compare models with **nested random effects** and the same fixed effect structure

* **ML** to compare models with **nested fixed effects** and the same random effect structure

* **ML** to compare models **with and without random effects**


## Different model structures

**What if we want the slopes to vary?**

![](images/fig_22_w5.png)

**Let's look at different model structures:**

- `(1 | Lake)` random effect by lake at the intrecept
- `(1 + Z_Length | Lake)` random effect by lake at the intercept and slope in response to the body length (NB: (`Z_Length | Lake)` gives the same random structure)
- `(-1 + Z_Length | Lake)` to have only the random effect at the slope
- `(1 | Lake) + (1 | Species)`  for crossed random effects
- `(1 | Lake:Fish_Species)` for the interaction between 2 random effects

- If your dataset includes nested random effects, you could use `/` to specify them, e.g. `(1 | factor1 / factor2)` if `factor2` is nested in `factor1` ([see stack-exchange](https://stats.stackexchange.com/questions/228800/crossed-vs-nested-random-effects-how-do-they-differ-and-how-are-they-specified))

## Challenge 4

Re-write the following code so that the **slopes** of the relationship between trophic position and body length **vary by lake and species**:

```{r, echo = TRUE, eval = TRUE}
# Challenge 4: Can you re-write this code so that the slopes between trophic position and body length vary by lake and species?
lmer(Z_TP ~ Z_Length + (1 | Lake) + (1 | Fish_Species),
     data = fish.data, REML = TRUE)
```

---

#### **Challenge 4 Solution:** {-}

```{r, echo = TRUE, eval = TRUE}
# Challenge 4 solution:
lmer(Z_TP ~ Z_Length + (1 + Z_Length | Lake) + (1 + Z_Length | Fish_Species),
     data = fish.data, REML = TRUE)
```


---

## Challenge 5 

To determine if you have built the best mixed model based on your prior knowledge, you should compare this *a priori* model to other alternative models.

With the dataset you are working on, there are several alternative models that might better fit your data. For challenge 5, make a list of 7 alternative models that could be compared to this one:

```{r, echo = TRUE, eval = TRUE}
# Challenge 5: Make a list of 7 alternative models that could be compared to this initial model:
lmer(Z_TP ~ Z_Length + (1 | Lake) + (1 | Fish_Species),
     data = fish.data, REML = TRUE)
```

*Note: If we had different fixed effects between the models or a model without random effects, we would have to specify `REML = FALSE` to compare with likelihood methods like AIC.*

---

#### **Challenge 5 Solution:** {-}

We first will also build the **basic linear model** `lm()` because it is always useful to see the variation in the AICc values (we will discuss these in more detail in the next section).

```{r, echo = TRUE, eval = TRUE}
# Challenge 5 solution: Basic linear model
M0 <- lm(Z_TP ~ Z_Length, data = fish.data)
```

In order to compare this model to the LMMs, it is important to **change the estimation method to ML (`REML=FALSE`)** for all other models because `lm()` does not use the same estimation method as `lmer()`. 

Let's look at the other models you could have written (note `REML = FALSE`):

```{r, echo = TRUE, eval = TRUE}
# Challenge 5 solution, other potential models
# Note that REML = FALSE in order to compare with the basic linear model where estimation method = ML

# Basic linear model / Linear model with no random effects
M0 <- lm(Z_TP ~ Z_Length, data = fish.data)
# Full model with varying intercepts
M1 <- lmer(Z_TP ~ Z_Length + (1 | Fish_Species) + (1 | Lake), 
           data = fish.data, REML = FALSE)
# Full model with varying intercepts and slopes
M2 <- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Fish_Species) + (1 + Z_Length | Lake),
           data = fish.data, REML = FALSE)
# No Lake, varying intercepts only
M3 <- lmer(Z_TP ~ Z_Length + (1 | Fish_Species), data = fish.data, REML = FALSE)
# No Species, varying intercepts only
M4 <- lmer(Z_TP ~ Z_Length + (1 | Lake), data = fish.data, REML = FALSE)
# No Lake, varying intercepts and slopes
M5 <- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Fish_Species), 
           data = fish.data, REML = FALSE)
# No Species, varying intercepts and slopes
M6 <- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Lake), data = fish.data, REML = FALSE)
# Full model with varying intercepts and slopes only varying by lake
M7 <- lmer(Z_TP ~ Z_Length + (1 | Fish_Species) + (1 + Z_Length | Lake),
           data = fish.data, REML = FALSE)
# Full model with varying intercepts and slopes only varying by species
M8 <- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Fish_Species) + (1 | Lake),
           data = fish.data, REML = FALSE)
```


**When fitting LMMs with `lmer()`, you may encounter some errors or warnings such as:**

- `boundary (singular) fit: see ?isSingular`, see [this discussion on stack-exchange](https://stats.stackexchange.com/questions/378939/dealing-with-singular-fit-in-mixed-models)

- `Model failed to converge with max|grad| ...`, see [this discussion on stack-exchange](https://stats.stackexchange.com/questions/242109/model-failed-to-converge-warning-in-lmer)

Here a [list](https://rdrr.io/cran/lme4/man/troubleshooting.html) of possible problems and how to troubleshoot them.

## Comparing models

Now that we have a list of potential models, we want to compare them to each other to select the one(s) with the highest predictive power given the data.

Models can be compared by using the `AICc` function from the` MuMIn` package. The Akaike Information Criterion (AIC) is a **measure of model quality** that can be used to compare models.

 `AICc` corrects for bias created by small sample sizes.

In order the find the AICc value of a model, use:

```{r, echo = TRUE, eval = TRUE}
# Find AICc value for our first model (Basic linear model) using the package MuMIn
MuMIn::AICc(M1)
```

To group all AICc values into a single table, use `MuMIn::model.sel()` to calculate AICc for each model (along with other outputs) and then select only the columns of interest to print in a table.

```{r, echo = TRUE, eval = TRUE}
# To group all AICc values into a single table, we can use MuMIn::model.sel() to calculate AICc for each model (along with other outputs)
AIC.table  <- MuMIn::model.sel(M0, M1, M2, M3, M4, M5, M6, M7, M8)

# Then we can select only the columns of interest to print into a table 
# `df` is the degree of freedom
# `logLik` is the loglikelihood
# `delta` is the AICc difference with the lowest value
(AIC.table <- AIC.table[ , c("df", "logLik", "AICc", "delta")])

# For more information on the other outputs/results returned by the function `model.sel()`, see `?model.sel`.
```

Where:

- `df` is the degree of freedom
- `logLik` is the loglikelihood
- `delta` is the AICc difference with the lowest value

We only displayed part of the results returned by the function `model.sel()`, see `?model.sel` for more information.

---

**What do these AICc values mean?**

- The model with the smallest AICc has the highest predictive power.
- Some suggest that if models are within 2 AICc units of each other then they are equally plausible.
- Let's take a closer look at M8 and M2. We can exclude other models because they have such higher AICc.

*Note that we use now REML (i.e. `REML = TRUE`) as we are comparing two models with nested random effects and the same fixed effect structure.*

```{r, echo = TRUE, eval = TRUE}
# Let's take a closer look at M8 and M2. We can exclude other model because they have such higher AICc
# Because we are comparing two mixed effect models, we can set `REML = TRUE` when generating M8 and M2
M8 <- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Fish_Species) + (1 | Lake),
           data = fish.data, REML = TRUE)

M2 <- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Fish_Species) + (1 + Z_Length | Lake),
           data = fish.data, REML = TRUE)
# Now let's print a table in order to compare M2 and M8 
MuMIn::model.sel(M2,M8)[ , c("df", "logLik", "AICc", "delta")]
```

Model `M8` seems to be the best among all models that we tested.

---

**What is the structure of the best model?**

```{r, echo = TRUE, eval = TRUE}
# Let's take a look at the best model again, what is it's structure?
M8 <- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Fish_Species) + (1 | Lake),
           data = fish.data, REML = FALSE)
# Both the intercepts and slopes of the relationship between trophic position and length may vary by fish species, but only the intercepts may vary by lake.
```

Both the intercepts and slopes of the relationship between trophic position and length may vary by fish species, but only the intercepts may vary by lake.

<div class = 'two-col'>

![](images/fig_9_w5.png)  
![](images/fig_8_w5.png)

</div>

Once the best model is selected, the estimation method must be reset to `REML = TRUE`.

```{r}
# Once the best model is selected, the estimation method must be reset to `REML = TRUE`.
M8 <- lmer(Z_TP ~ Z_Length + (1 + Z_Length | Fish_Species) + (1 | Lake),
           data = fish.data, REML = TRUE)
```


# Step 3. Model validation

Now that we have our model, we must verify that the model follows all the basic assumptions:

- **1. Check the homogeneity of the variance:**
  - Plot predicted values vs residual values

- **2. Check the independence of the model residuals:**
  - Plot residuals vs each covariate of the model
  - Plot residuals vs each covariate not included in the model

- **3. Check the normality of the model residuals:**
  - Histogram of residuals


## 1. Check the homogeneity of the variance 

In order to check the homgeneity of the variance, we can plot predicted values vs residual values.

Homogeneous dispersion of the residuals means that the assumption is respected.

![](images/resid-plots.gif)

Now let's look at our data, is the dispersion homogenous?

```{r, echo = TRUE, eval = TRUE}
# Plot predicted values vs residual values
par(mar=c(4,4,.5,.5))
plot(resid(M8) ~ fitted(M8), 
     xlab = 'Predicted values', 
     ylab = 'Normalized residuals')
abline(h = 0, lty = 2)
# Homogeneous dispersion of the residuals means that the assumption is respected.
```

**Yes! Homogeneous dispersion of the residuals means that the assumption is respected.**

## 2. Check the independence of the model residuals with each covariate 

In order to check the independence of the model residuals with each covariate we will (1) plot residuals vs each covariate of the model and (2) plot residuals vs each covariate not included in the model.

Let's start by (1) plotting the residuals vs each covariate of the model.

```{r, echo = TRUE, eval = TRUE}
# In order to check the independence of the model residuals we need to plot residuals vs each covariate of the model
par(mfrow = c(1,3), mar=c(4,4,.5,.5))

plot(resid(M8) ~ fish.data$Z_Length, 
     xlab = "Length", ylab = "Normalized residuals")
abline(h = 0, lty = 2)

boxplot(resid(M8) ~ Fish_Species, data = fish.data, 
        xlab = "Species", ylab = "Normalized residuals")
abline(h = 0, lty = 2)

boxplot(resid(M8) ~ Lake, data = fish.data, 
        xlab = "Lakes", ylab = "Normalized residuals")
abline(h = 0, lty = 2)
# Homogeneous dispersion of the residuals around 0 means no pattern of residuals depending on the variable, therefore the assumption is respected!
# Note: The clusters are due to the data structure, where fish of only 5 size classes (large, small, and three groups in between) were captured.
```


**Homogeneous dispersion of the residuals around 0 means no pattern of residuals depending on the variable, therefore the assumption is respected!**

*Note: The clusters are due to the data structure, where fish of only 5 size classes (large, small, and three groups in between) were captured.*

Now, we should (2) plot residuals vs each covariate not included in the model. 

If you observe patterns in these plots, you will know that there is variation in your dataset that could be explained by these covariates and you should consider including them in your model. **However because we have included all the measured variables in our model, we can not do this step with our data.**


## 3. Check the normality of the model residuals 

Now we will check the normality of the model residuals as residuals following a normal distribution indicate that the model is not biased.

```{r, echo = TRUE, eval = TRUE}
# Check the normality of the model residuals as residuals following a normal distribution indicate that the model is not biased.
hist(resid(M8))
# The residuals are normal! This means our model is not biased.
```

**The residuals are normal! This means our model is not biased.**


# Step 4. Interpretation and visualization 

## Interpreting our model

Let's take a closer look at our final model using the `summary()` function. How can we interpret this information?

```{r, echo = TRUE, eval = TRUE}
# Now we are ready for interpretation and visualization
# Let's take a closer look at our final model using the `summary()` function. 
(summ_M8 <- summary(M8))
```
**Let's go section by section and try to understand what we are looking at.**

<ins> Random effects: </ins>

- `Groups`: grouping factors

- `Name`: `(Intercept)` for the intercepts or the name of the variable on which the random slope is estimated (`Z_length` in this example)
  
- `Variance` the variance of the estimated effect (`Std.Dev.` is the standard deviation of this estimate)

- `Corr` the correlation between the random interpet and the random slope for a given grouping factor (see [this dicussion](https://stats.stackexchange.com/questions/320978/understanding-and-coding-random-intercept-correlation-lmer)).

---

<ins> Fixed effects: </ins>

This part presents the fixed effect estimates. The value of the t statistics [(Student test)](https://en.wikipedia.org/wiki/T-statistic) is shown **without the p-value** (it is a decision from the package authors, see why in [this discussion](https://stats.stackexchange.com/questions/185360/t-value-associated-with-nlme-lme4)).
  
This statistics could be used as it is. You could also calculate the 95% confidence interval (CI) with this equation:
    
$$ CI = Estimate \pm 1.96*Std.Error $$
    
If 0 is in the interval, then the parameter is not significantly different from zero at a threshold of $\alpha$ = 0.05.

---

**Some useful functions**

- `coef(M8)` and `ranef(M8)` return random effects of model M8

- `coef(summary(M8))` returns fixed effects

- `sigma(M8)` returns standard deviation of residuals

- `fitted(M8)` returns predicted values by the model

- `residuals(M8)` returns residuals
  
  
## Challenge 6

- **1.** What is the slope and confidence interval of the Z_Length variable in the M8 model?

- **2.** Is the slope of Z_Length significantly different from 0?

---

#### **Challenge 6 Solution:** {-}
  
**1.** What is the slope and confidence interval of the Z_Length variable in the M8 model?
    
- slope = 0.422;
  
- CI upper limit = 0.4223 + 0.09*1.96 = 0.5987

- CI lower limit = 0.4223 - 0.09*1.96 = 0.2459

**2.** Is the slope of Z_Length significantly different from 0?
  
  - Yes, because the CI [0.2459, 0.5987] does not include 0
  

## Challenge 7
    
**Is it possible to visualize graphically the different intercepts and slopes of the model to better interpret the results?**

Take 2 minutes to think about different ways to represent the results of M8.
  
*Hint: consider the different "levels" of the model*
    
---

#### **Challenge 7 Solution:** {-}

**Is it possible to visualize graphically the different intercepts and slopes of the model to better interpret the results?**

Yes! We could do this by generating:

a) A figure with all data grouped

b) A figure by species

c) A figure by lake

To produce these figures, we need (1) the coefficients of the full model that are in the model summary, (2) The coefficients for each level of the model, which can be obtained with the `coef` function

```{r, echo = TRUE, eval = TRUE}
# Challenge 7: *Is it possible to visualize graphically the different intercepts and slopes of the model to better interpret the results?

# Challenge 7 solution: Yes! We could do this by generating the following figures.
# a) A figure with all data grouped
# b) A figure by species
# c) A figure by lake

# To produce these figures, first we need the coefficients of the full model that are in the model summary.
summ_M8$coefficients
# Intercept = Intercept = 9.0589745 × 10^4
# Slope = 0.4222697

# We also need the coefficients for each level of the model, which can be obtained with the `coef` function
coef(M8)
```

**Now let's make our figures!**

a) Figure with all data grouped

```{r, echo = TRUE, eval = TRUE}
# Now let's make our figures!

# a) Figure with all data grouped
# Create a simplified ggplot theme
fig <- theme_bw() +
  theme(panel.grid.minor=element_blank(),
        panel.grid.major=element_blank(),
        panel.background=element_blank()) +
  theme(strip.background=element_blank(),
        strip.text.y = element_text()) +
  theme(legend.background=element_blank()) +
  theme(legend.key=element_blank()) +
  theme(panel.border = element_rect(colour="black", fill=NA))

plot <- ggplot(aes(Z_Length, Z_TP), data = fish.data)
Plot_AllData <- plot + geom_point() +
  xlab("Length (mm)") + 
  ylab("Trophic position") +
  labs(title = "All data") + fig

Plot_AllData + geom_abline(intercept = summ_M8$coefficients[1,1], 
                           slope     = summ_M8$coefficients[2,1])

# You could also write out the numbers like this:
# Plot_AllData + geom_abline(intercept = -0.0009059, slope = 0.4222697)
```


b) Figure by species

```{r, echo = TRUE, eval = TRUE}
# b) Figure by species
# Create a table with the coefs to facilitate their manipulation
Lake.coef              <- coef(M8)$Lake
colnames(Lake.coef)    <- c("Intercept", "Slope")
Species.coef           <- coef(M8)$Fish_Species
colnames(Species.coef) <- c("Intercept", "Slope")

Plot_BySpecies <- plot + 
  geom_point(aes(colour = factor(Fish_Species)), size = 4) +
  xlab("Length (mm)") + ylab("Trophic position") +
  labs(title = "By species") + fig

# Add regression lines for each species
Plot_BySpecies +
  geom_abline(intercept = Species.coef[1,1], 
              slope     = Species.coef[1,2], col = "coral2") +
  geom_abline(intercept = Species.coef[2,1], 
              slope     = Species.coef[2,2], col = "green4") +
  geom_abline(intercept = Species.coef[3,1], 
              slope     = Species.coef[3,2], col = "blue1")

```


c) Figure by lake

```{r, echo = TRUE, eval = TRUE}
# c) Figure by lake
Plot_ByLake <- plot + 
  geom_point(aes(colour = factor(Lake)), size = 4) +
  xlab("Length (mm)") + ylab("Trophic Position") +
  labs(title = "By Lake") + fig

# Add in regression lines with the intercepts specific to each lake
Plot_ByLake +
  geom_abline(intercept = Lake.coef[1,1], 
              slope     = Lake.coef[1,2], col = "coral2") +
  geom_abline(intercept = Lake.coef[2,1], 
              slope     = Lake.coef[2,2], col = "khaki4") +
  geom_abline(intercept = Lake.coef[3,1], 
              slope     = Lake.coef[3,2], col = "green4") +
  geom_abline(intercept = Lake.coef[4,1], 
              slope     = Lake.coef[4,2], col = "darkgoldenrod") +
  geom_abline(intercept = Lake.coef[5,1], 
              slope     = Lake.coef[5,2], col = "royalblue1") +
  geom_abline(intercept = Lake.coef[6,1], 
              slope     = Lake.coef[6,2], col = "magenta3")

```

## Challenge 8

Let's test our knowledge by considering another scenario.

Imagine that you have inventoried species richness **in 1000 quadrats** that are within **10 different sites** which are also within **10 different forests**. You also **measured productivity** in each **quadrat**. 

You want to know if productivity is a good predictor of biodiversity. **What mixed model could you use for this dataset?**
    
---

#### **Challenge 8 Solution:** {-}

```{r, echo = TRUE, eval = FALSE}
lmer(Biodiv ~ Productivity + (1 | Forest / Site))
```

Here the random effects are nested (i.e. Sites within forest) and not crossed.

Why use `(1 | Forest / Site)` rather than `(1 | Forest) + (1 | Site)`? 

See the answer [here](https://stats.stackexchange.com/questions/228800/crossed-vs-nested-random-effects-how-do-they-differ-and-how-are-they-specified)!
  